/* automatically generated by rust-bindgen 0.70.1 */

#[repr(C)]
#[derive(Copy, Clone, Debug, Default, Eq, Hash, Ord, PartialEq, PartialOrd)]
pub struct __BindgenBitfieldUnit<Storage> {
    storage: Storage,
}
impl<Storage> __BindgenBitfieldUnit<Storage> {
    #[inline]
    pub const fn new(storage: Storage) -> Self {
        Self { storage }
    }
}
impl<Storage> __BindgenBitfieldUnit<Storage>
where
    Storage: AsRef<[u8]> + AsMut<[u8]>,
{
    #[inline]
    pub fn get_bit(&self, index: usize) -> bool {
        debug_assert!(index / 8 < self.storage.as_ref().len());
        let byte_index = index / 8;
        let byte = self.storage.as_ref()[byte_index];
        let bit_index = if cfg!(target_endian = "big") {
            7 - (index % 8)
        } else {
            index % 8
        };
        let mask = 1 << bit_index;
        byte & mask == mask
    }
    #[inline]
    pub fn set_bit(&mut self, index: usize, val: bool) {
        debug_assert!(index / 8 < self.storage.as_ref().len());
        let byte_index = index / 8;
        let byte = &mut self.storage.as_mut()[byte_index];
        let bit_index = if cfg!(target_endian = "big") {
            7 - (index % 8)
        } else {
            index % 8
        };
        let mask = 1 << bit_index;
        if val {
            *byte |= mask;
        } else {
            *byte &= !mask;
        }
    }
    #[inline]
    pub fn get(&self, bit_offset: usize, bit_width: u8) -> u64 {
        debug_assert!(bit_width <= 64);
        debug_assert!(bit_offset / 8 < self.storage.as_ref().len());
        debug_assert!((bit_offset + (bit_width as usize)) / 8 <= self.storage.as_ref().len());
        let mut val = 0;
        for i in 0..(bit_width as usize) {
            if self.get_bit(i + bit_offset) {
                let index = if cfg!(target_endian = "big") {
                    bit_width as usize - 1 - i
                } else {
                    i
                };
                val |= 1 << index;
            }
        }
        val
    }
    #[inline]
    pub fn set(&mut self, bit_offset: usize, bit_width: u8, val: u64) {
        debug_assert!(bit_width <= 64);
        debug_assert!(bit_offset / 8 < self.storage.as_ref().len());
        debug_assert!((bit_offset + (bit_width as usize)) / 8 <= self.storage.as_ref().len());
        for i in 0..(bit_width as usize) {
            let mask = 1 << i;
            let val_bit_is_set = val & mask == mask;
            let index = if cfg!(target_endian = "big") {
                bit_width as usize - 1 - i
            } else {
                i
            };
            self.set_bit(index + bit_offset, val_bit_is_set);
        }
    }
}
pub type rte_vdev_scan_callback =
    ::std::option::Option<unsafe extern "C" fn(user_arg: *mut ::std::os::raw::c_void)>;
extern "C" {
    #[doc = " Add a callback to be called on vdev scan\n before reading the devargs list.\n\n This function cannot be called in a scan callback\n because of deadlock.\n\n @param callback\n   The function to be called which can update the devargs list.\n @param user_arg\n   An opaque pointer passed to callback.\n @return\n   0 on success, negative on error"]
    pub fn rte_vdev_add_custom_scan(
        callback: rte_vdev_scan_callback,
        user_arg: *mut ::std::os::raw::c_void,
    ) -> ::std::os::raw::c_int;
}
extern "C" {
    #[doc = " Remove a registered scan callback.\n\n This function cannot be called in a scan callback\n because of deadlock.\n\n @param callback\n   The registered function to be removed.\n @param user_arg\n   The associated opaque pointer or (void*)-1 for any.\n @return\n   0 on success"]
    pub fn rte_vdev_remove_custom_scan(
        callback: rte_vdev_scan_callback,
        user_arg: *mut ::std::os::raw::c_void,
    ) -> ::std::os::raw::c_int;
}
extern "C" {
    #[doc = " Initialize a driver specified by name.\n\n @param name\n   The pointer to a driver name to be initialized.\n @param args\n   The pointer to arguments used by driver initialization.\n @return\n  0 on success, negative on error"]
    pub fn rte_vdev_init(
        name: *const ::std::os::raw::c_char,
        args: *const ::std::os::raw::c_char,
    ) -> ::std::os::raw::c_int;
}
extern "C" {
    #[doc = " Uninitialize a driver specified by name.\n\n @param name\n   The pointer to a driver name to be uninitialized.\n @return\n  0 on success, negative on error"]
    pub fn rte_vdev_uninit(name: *const ::std::os::raw::c_char) -> ::std::os::raw::c_int;
}
pub type __off_t = ::std::os::raw::c_long;
pub type __off64_t = ::std::os::raw::c_long;
pub type __time_t = ::std::os::raw::c_long;
pub type __syscall_slong_t = ::std::os::raw::c_long;
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct timespec {
    pub tv_sec: __time_t,
    pub tv_nsec: __syscall_slong_t,
}
#[doc = " Physical address"]
pub type phys_addr_t = u64;
#[doc = " IO virtual address type.\n When the physical addressing mode (IOVA as PA) is in use,\n the translation from an IO virtual address (IOVA) to a physical address\n is a direct mapping, i.e. the same value.\n Otherwise, in virtual mode (IOVA as VA), an IOMMU may do the translation."]
pub type rte_iova_t = u64;
extern "C" {
    #[doc = " Converts a numeric string to the equivalent uint64_t value.\n As well as straight number conversion, also recognises the suffixes\n k, m and g for kilobytes, megabytes and gigabytes respectively.\n\n If a negative number is passed in  i.e. a string with the first non-black\n character being \"-\", zero is returned. Zero is also returned in the case of\n an error with the strtoull call in the function.\n\n @param str\n     String containing number to convert.\n @return\n     Number."]
    pub fn rte_str_to_size(str_: *const ::std::os::raw::c_char) -> u64;
}
extern "C" {
    #[doc = " Function to terminate the application immediately, printing an error\n message and returning the exit_code back to the shell.\n\n This function never returns\n\n @param exit_code\n     The exit code to be returned by the application\n @param format\n     The format string to be used for printing the message. This can include\n     printf format characters which will be expanded using any further parameters\n     to the function."]
    pub fn rte_exit(
        exit_code: ::std::os::raw::c_int,
        format: *const ::std::os::raw::c_char,
        ...
    ) -> !;
}
pub type va_list = __builtin_va_list;
pub type FILE = _IO_FILE;
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct _IO_marker {
    _unused: [u8; 0],
}
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct _IO_codecvt {
    _unused: [u8; 0],
}
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct _IO_wide_data {
    _unused: [u8; 0],
}
pub type _IO_lock_t = ::std::os::raw::c_void;
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct _IO_FILE {
    pub _flags: ::std::os::raw::c_int,
    pub _IO_read_ptr: *mut ::std::os::raw::c_char,
    pub _IO_read_end: *mut ::std::os::raw::c_char,
    pub _IO_read_base: *mut ::std::os::raw::c_char,
    pub _IO_write_base: *mut ::std::os::raw::c_char,
    pub _IO_write_ptr: *mut ::std::os::raw::c_char,
    pub _IO_write_end: *mut ::std::os::raw::c_char,
    pub _IO_buf_base: *mut ::std::os::raw::c_char,
    pub _IO_buf_end: *mut ::std::os::raw::c_char,
    pub _IO_save_base: *mut ::std::os::raw::c_char,
    pub _IO_backup_base: *mut ::std::os::raw::c_char,
    pub _IO_save_end: *mut ::std::os::raw::c_char,
    pub _markers: *mut _IO_marker,
    pub _chain: *mut _IO_FILE,
    pub _fileno: ::std::os::raw::c_int,
    pub _flags2: ::std::os::raw::c_int,
    pub _old_offset: __off_t,
    pub _cur_column: ::std::os::raw::c_ushort,
    pub _vtable_offset: ::std::os::raw::c_schar,
    pub _shortbuf: [::std::os::raw::c_char; 1usize],
    pub _lock: *mut _IO_lock_t,
    pub _offset: __off64_t,
    pub _codecvt: *mut _IO_codecvt,
    pub _wide_data: *mut _IO_wide_data,
    pub _freeres_list: *mut _IO_FILE,
    pub _freeres_buf: *mut ::std::os::raw::c_void,
    pub __pad5: usize,
    pub _mode: ::std::os::raw::c_int,
    pub _unused2: [::std::os::raw::c_char; 20usize],
}
extern "C" {
    #[doc = " Change the stream that will be used by the logging system.\n\n This can be done at any time. The f argument represents the stream\n to be used to send the logs. If f is NULL, the default output is\n used (stderr).\n\n @param f\n   Pointer to the stream.\n @return\n   - 0 on success.\n   - Negative on error."]
    pub fn rte_openlog_stream(f: *mut FILE) -> ::std::os::raw::c_int;
}
extern "C" {
    #[doc = " Retrieve the stream used by the logging system (see rte_openlog_stream()\n to change it).\n\n @return\n   Pointer to the stream."]
    pub fn rte_log_get_stream() -> *mut FILE;
}
extern "C" {
    #[doc = " Set the global log level.\n\n After this call, logs with a level lower or equal than the level\n passed as argument will be displayed.\n\n @param level\n   Log level. A value between RTE_LOG_EMERG (1) and RTE_LOG_DEBUG (8)."]
    pub fn rte_log_set_global_level(level: u32);
}
extern "C" {
    #[doc = " Get the global log level.\n\n @return\n   The current global log level."]
    pub fn rte_log_get_global_level() -> u32;
}
extern "C" {
    #[doc = " Get the log level for a given type.\n\n @param logtype\n   The log type identifier.\n @return\n   0 on success, a negative value if logtype is invalid."]
    pub fn rte_log_get_level(logtype: u32) -> ::std::os::raw::c_int;
}
extern "C" {
    #[doc = " For a given `logtype`, check if a log with `loglevel` can be printed.\n\n @param logtype\n   The log type identifier\n @param loglevel\n   Log level. A value between RTE_LOG_EMERG (1) and RTE_LOG_DEBUG (8).\n @return\n Returns 'true' if log can be printed and 'false' if it can't."]
    pub fn rte_log_can_log(logtype: u32, loglevel: u32) -> bool;
}
extern "C" {
    #[doc = " Set the log level for a given type based on globbing pattern.\n\n @param pattern\n   The globbing pattern identifying the log type.\n @param level\n   The level to be set.\n @return\n   0 on success, a negative value if level is invalid."]
    pub fn rte_log_set_level_pattern(
        pattern: *const ::std::os::raw::c_char,
        level: u32,
    ) -> ::std::os::raw::c_int;
}
extern "C" {
    #[doc = " Set the log level for a given type based on regular expression.\n\n @param regex\n   The regular expression identifying the log type.\n @param level\n   The level to be set.\n @return\n   0 on success, a negative value if level is invalid."]
    pub fn rte_log_set_level_regexp(
        regex: *const ::std::os::raw::c_char,
        level: u32,
    ) -> ::std::os::raw::c_int;
}
extern "C" {
    #[doc = " Set the log level for a given type.\n\n @param logtype\n   The log type identifier.\n @param level\n   The level to be set.\n @return\n   0 on success, a negative value if logtype or level is invalid."]
    pub fn rte_log_set_level(logtype: u32, level: u32) -> ::std::os::raw::c_int;
}
extern "C" {
    #[doc = " Get the current loglevel for the message being processed.\n\n Before calling the user-defined stream for logging, the log\n subsystem sets a per-lcore variable containing the loglevel and the\n logtype of the message being processed. This information can be\n accessed by the user-defined log output function through this\n function.\n\n @return\n   The loglevel of the message being processed."]
    pub fn rte_log_cur_msg_loglevel() -> ::std::os::raw::c_int;
}
extern "C" {
    #[doc = " Get the current logtype for the message being processed.\n\n Before calling the user-defined stream for logging, the log\n subsystem sets a per-lcore variable containing the loglevel and the\n logtype of the message being processed. This information can be\n accessed by the user-defined log output function through this\n function.\n\n @return\n   The logtype of the message being processed."]
    pub fn rte_log_cur_msg_logtype() -> ::std::os::raw::c_int;
}
extern "C" {
    #[doc = " Register a dynamic log type\n\n If a log is already registered with the same type, the returned value\n is the same than the previous one.\n\n @param name\n   The string identifying the log type.\n @return\n   - >0: success, the returned value is the log type identifier.\n   - (-ENOMEM): cannot allocate memory."]
    pub fn rte_log_register(name: *const ::std::os::raw::c_char) -> ::std::os::raw::c_int;
}
extern "C" {
    #[doc = " Register a dynamic log type and try to pick its level from EAL options\n\n rte_log_register() is called inside. If successful, the function tries\n to search for matching regexp in the list of EAL log level options and\n pick the level from the last matching entry. If nothing can be applied\n from the list, the level will be set to the user-defined default value.\n\n @param name\n    Name for the log type to be registered\n @param level_def\n    Fallback level to be set if the global list has no matching options\n @return\n    - >=0: the newly registered log type\n    - <0: rte_log_register() error value"]
    pub fn rte_log_register_type_and_pick_level(
        name: *const ::std::os::raw::c_char,
        level_def: u32,
    ) -> ::std::os::raw::c_int;
}
extern "C" {
    #[doc = " Dump name of each logtype, one per line.\n\n @param out\n   Stream where the list is sent.\n @param prefix\n   String preceding each logtype in the output."]
    pub fn rte_log_list_types(out: *mut FILE, prefix: *const ::std::os::raw::c_char);
}
extern "C" {
    #[doc = " Dump log information.\n\n Dump the global level and the registered log types.\n\n @param f\n   The output stream where the dump should be sent."]
    pub fn rte_log_dump(f: *mut FILE);
}
extern "C" {
    #[doc = " Generates a log message.\n\n The message will be sent in the stream defined by the previous call\n to rte_openlog_stream().\n\n The level argument determines if the log should be displayed or\n not, depending on the loglevel settings.\n\n The preferred alternative is the RTE_LOG() because it adds the\n level and type in the logged string.\n\n @param level\n   Log level. A value between RTE_LOG_EMERG (1) and RTE_LOG_DEBUG (8).\n @param logtype\n   The log type, for example, RTE_LOGTYPE_EAL.\n @param format\n   The format string, as in printf(3), followed by the variable arguments\n   required by the format.\n @return\n   - 0: Success.\n   - Negative on error."]
    pub fn rte_log(
        level: u32,
        logtype: u32,
        format: *const ::std::os::raw::c_char,
        ...
    ) -> ::std::os::raw::c_int;
}
extern "C" {
    #[doc = " Generates a log message.\n\n The message will be sent in the stream defined by the previous call\n to rte_openlog_stream().\n\n The level argument determines if the log should be displayed or\n not, depending on the loglevel settings. A trailing\n newline may be added if needed.\n\n The preferred alternative is the RTE_LOG() because it adds the\n level and type in the logged string.\n\n @param level\n   Log level. A value between RTE_LOG_EMERG (1) and RTE_LOG_DEBUG (8).\n @param logtype\n   The log type, for example, RTE_LOGTYPE_EAL.\n @param format\n   The format string, as in printf(3), followed by the variable arguments\n   required by the format.\n @param ap\n   The va_list of the variable arguments required by the format.\n @return\n   - 0: Success.\n   - Negative on error."]
    pub fn rte_vlog(
        level: u32,
        logtype: u32,
        format: *const ::std::os::raw::c_char,
        ap: *mut __va_list_tag,
    ) -> ::std::os::raw::c_int;
}
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct rte_bus {
    _unused: [u8; 0],
}
#[doc = "< device being added"]
pub const rte_dev_event_type_RTE_DEV_EVENT_ADD: rte_dev_event_type = 0;
#[doc = "< device being removed"]
pub const rte_dev_event_type_RTE_DEV_EVENT_REMOVE: rte_dev_event_type = 1;
#[doc = "< max value of this enum"]
pub const rte_dev_event_type_RTE_DEV_EVENT_MAX: rte_dev_event_type = 2;
#[doc = " The device event type."]
pub type rte_dev_event_type = ::std::os::raw::c_uint;
pub type rte_dev_event_cb_fn = ::std::option::Option<
    unsafe extern "C" fn(
        device_name: *const ::std::os::raw::c_char,
        event: rte_dev_event_type,
        cb_arg: *mut ::std::os::raw::c_void,
    ),
>;
pub const rte_dev_policy_RTE_DEV_ALLOWED: rte_dev_policy = 0;
pub const rte_dev_policy_RTE_DEV_BLOCKED: rte_dev_policy = 1;
#[doc = " Device policies."]
pub type rte_dev_policy = ::std::os::raw::c_uint;
#[doc = " A generic memory resource representation."]
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct rte_mem_resource {
    #[doc = "< Physical address, 0 if not resource."]
    pub phys_addr: u64,
    #[doc = "< Length of the resource."]
    pub len: u64,
    #[doc = "< Virtual address, NULL when not mapped."]
    pub addr: *mut ::std::os::raw::c_void,
}
extern "C" {
    #[doc = " Retrieve a driver name.\n\n @param driver\n   A pointer to a driver structure.\n @return\n   A pointer to the driver name string."]
    pub fn rte_driver_name(driver: *const rte_driver) -> *const ::std::os::raw::c_char;
}
extern "C" {
    #[doc = " Retrieve a device bus.\n\n @param dev\n   A pointer to a device structure.\n @return\n   A pointer to this device bus."]
    pub fn rte_dev_bus(dev: *const rte_device) -> *const rte_bus;
}
extern "C" {
    #[doc = " Retrieve bus specific information for a device.\n\n @param dev\n   A pointer to a device structure.\n @return\n   A string describing this device or NULL if none is available."]
    pub fn rte_dev_bus_info(dev: *const rte_device) -> *const ::std::os::raw::c_char;
}
extern "C" {
    #[doc = " Retrieve a device arguments.\n\n @param dev\n   A pointer to a device structure.\n @return\n   A pointer to this device devargs."]
    pub fn rte_dev_devargs(dev: *const rte_device) -> *const rte_devargs;
}
extern "C" {
    #[doc = " Retrieve a device driver.\n\n @param dev\n   A pointer to a device structure.\n @return\n   A pointer to this device driver."]
    pub fn rte_dev_driver(dev: *const rte_device) -> *const rte_driver;
}
extern "C" {
    #[doc = " Retrieve a device name.\n\n @param dev\n   A pointer to a device structure.\n @return\n   A pointer to this device name."]
    pub fn rte_dev_name(dev: *const rte_device) -> *const ::std::os::raw::c_char;
}
extern "C" {
    #[doc = " Retrieve a device numa node.\n\n @param dev\n   A pointer to a device structure.\n @return\n   A pointer to this device numa node."]
    pub fn rte_dev_numa_node(dev: *const rte_device) -> ::std::os::raw::c_int;
}
extern "C" {
    #[doc = " Query status of a device.\n\n @param dev\n   Generic device pointer.\n @return\n   (int)true if already probed successfully, 0 otherwise."]
    pub fn rte_dev_is_probed(dev: *const rte_device) -> ::std::os::raw::c_int;
}
extern "C" {
    #[doc = " Hotplug add a given device to a specific bus.\n\n In multi-process, it will request other processes to add the same device.\n A failure, in any process, will rollback the action\n\n @param busname\n   The bus name the device is added to.\n @param devname\n   The device name. Based on this device name, eal will identify a driver\n   capable of handling it and pass it to the driver probing function.\n @param drvargs\n   Device arguments to be passed to the driver.\n @return\n   0 on success, negative on error."]
    pub fn rte_eal_hotplug_add(
        busname: *const ::std::os::raw::c_char,
        devname: *const ::std::os::raw::c_char,
        drvargs: *const ::std::os::raw::c_char,
    ) -> ::std::os::raw::c_int;
}
extern "C" {
    #[doc = " Add matching devices.\n\n In multi-process, it will request other processes to add the same device.\n A failure, in any process, will rollback the action\n\n @param devargs\n   Device arguments including bus, class and driver properties.\n @return\n   0 on success, negative on error."]
    pub fn rte_dev_probe(devargs: *const ::std::os::raw::c_char) -> ::std::os::raw::c_int;
}
extern "C" {
    #[doc = " Hotplug remove a given device from a specific bus.\n\n In multi-process, it will request other processes to remove the same device.\n A failure, in any process, will rollback the action\n\n @param busname\n   The bus name the device is removed from.\n @param devname\n   The device name being removed.\n @return\n   0 on success, negative on error."]
    pub fn rte_eal_hotplug_remove(
        busname: *const ::std::os::raw::c_char,
        devname: *const ::std::os::raw::c_char,
    ) -> ::std::os::raw::c_int;
}
extern "C" {
    #[doc = " Remove one device.\n\n In multi-process, it will request other processes to remove the same device.\n A failure, in any process, will rollback the action\n\n @param dev\n   Data structure of the device to remove.\n @return\n   0 on success, negative on error."]
    pub fn rte_dev_remove(dev: *mut rte_device) -> ::std::os::raw::c_int;
}
#[doc = " Device comparison function.\n\n This type of function is used to compare an rte_device with arbitrary\n data.\n\n @param dev\n   Device handle.\n\n @param data\n   Data to compare against. The type of this parameter is determined by\n   the kind of comparison performed by the function.\n\n @return\n   0 if the device matches the data.\n   !0 if the device does not match.\n   <0 if ordering is possible and the device is lower than the data.\n   >0 if ordering is possible and the device is greater than the data."]
pub type rte_dev_cmp_t = ::std::option::Option<
    unsafe extern "C" fn(
        dev: *const rte_device,
        data: *const ::std::os::raw::c_void,
    ) -> ::std::os::raw::c_int,
>;
#[doc = " Iteration context.\n\n This context carries over the current iteration state."]
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct rte_dev_iterator {
    #[doc = "< device string."]
    pub dev_str: *const ::std::os::raw::c_char,
    #[doc = "< bus-related part of device string."]
    pub bus_str: *const ::std::os::raw::c_char,
    #[doc = "< class-related part of device string."]
    pub cls_str: *const ::std::os::raw::c_char,
    #[doc = "< bus handle."]
    pub bus: *mut rte_bus,
    #[doc = "< class handle."]
    pub cls: *mut rte_class,
    #[doc = "< current position."]
    pub device: *mut rte_device,
    #[doc = "< additional specialized context."]
    pub class_device: *mut ::std::os::raw::c_void,
}
#[doc = " Device iteration function.\n\n Find the next device matching properties passed in parameters.\n The function takes an additional ``start`` parameter, that is\n used as starting context when relevant.\n\n The function returns the current element in the iteration.\n This return value will potentially be used as a start parameter\n in subsequent calls to the function.\n\n The additional iterator parameter is only there if a specific\n implementation needs additional context. It must not be modified by\n the iteration function itself.\n\n @param start\n   Starting iteration context.\n\n @param devstr\n   Device description string.\n\n @param it\n   Device iterator.\n\n @return\n   The address of the current element matching the device description\n   string."]
pub type rte_dev_iterate_t = ::std::option::Option<
    unsafe extern "C" fn(
        start: *const ::std::os::raw::c_void,
        devstr: *const ::std::os::raw::c_char,
        it: *const rte_dev_iterator,
    ) -> *mut ::std::os::raw::c_void,
>;
extern "C" {
    #[doc = " Initializes a device iterator.\n\n This iterator allows accessing a list of devices matching a criteria.\n The device matching is made among all buses and classes currently registered,\n filtered by the device description given as parameter.\n\n This function will not allocate any memory. It is safe to stop the\n iteration at any moment and let the iterator go out of context.\n\n @param it\n   Device iterator handle.\n\n @param str\n   Device description string.\n\n @return\n   0 on successful initialization.\n   <0 on error."]
    pub fn rte_dev_iterator_init(
        it: *mut rte_dev_iterator,
        str_: *const ::std::os::raw::c_char,
    ) -> ::std::os::raw::c_int;
}
extern "C" {
    #[doc = " Iterates on a device iterator.\n\n Generates a new rte_device handle corresponding to the next element\n in the list described in comprehension by the iterator.\n\n The next object is returned, and the iterator is updated.\n\n @param it\n   Device iterator handle.\n\n @return\n   An rte_device handle if found.\n   NULL if an error occurred (rte_errno is set).\n   NULL if no device could be found (rte_errno is not set)."]
    pub fn rte_dev_iterator_next(it: *mut rte_dev_iterator) -> *mut rte_device;
}
extern "C" {
    #[doc = " It registers the callback for the specific device.\n Multiple callbacks can be registered at the same time.\n\n @param device_name\n  The device name, that is the param name of the struct rte_device,\n  null value means for all devices.\n @param cb_fn\n  callback address.\n @param cb_arg\n  address of parameter for callback.\n\n @return\n  - On success, zero.\n  - On failure, a negative value."]
    pub fn rte_dev_event_callback_register(
        device_name: *const ::std::os::raw::c_char,
        cb_fn: rte_dev_event_cb_fn,
        cb_arg: *mut ::std::os::raw::c_void,
    ) -> ::std::os::raw::c_int;
}
extern "C" {
    #[doc = " It unregisters the callback according to the specified device.\n\n @param device_name\n  The device name, that is the param name of the struct rte_device,\n  null value means for all devices and their callbacks.\n @param cb_fn\n  callback address.\n @param cb_arg\n  address of parameter for callback, (void *)-1 means to remove all\n  registered which has the same callback address.\n\n @return\n  - On success, return the number of callback entities removed.\n  - On failure, a negative value."]
    pub fn rte_dev_event_callback_unregister(
        device_name: *const ::std::os::raw::c_char,
        cb_fn: rte_dev_event_cb_fn,
        cb_arg: *mut ::std::os::raw::c_void,
    ) -> ::std::os::raw::c_int;
}
extern "C" {
    #[doc = " Executes all the user application registered callbacks for\n the specific device.\n\n @param device_name\n  The device name.\n @param event\n  the device event type."]
    pub fn rte_dev_event_callback_process(
        device_name: *const ::std::os::raw::c_char,
        event: rte_dev_event_type,
    );
}
extern "C" {
    #[doc = " Start the device event monitoring.\n\n @return\n   - On success, zero.\n   - On failure, a negative value."]
    pub fn rte_dev_event_monitor_start() -> ::std::os::raw::c_int;
}
extern "C" {
    #[doc = " Stop the device event monitoring.\n\n @return\n   - On success, zero.\n   - On failure, a negative value."]
    pub fn rte_dev_event_monitor_stop() -> ::std::os::raw::c_int;
}
extern "C" {
    #[doc = " Enable hotplug handling for devices.\n\n @return\n   - On success, zero.\n   - On failure, a negative value."]
    pub fn rte_dev_hotplug_handle_enable() -> ::std::os::raw::c_int;
}
extern "C" {
    #[doc = " Disable hotplug handling for devices.\n\n @return\n   - On success, zero.\n   - On failure, a negative value."]
    pub fn rte_dev_hotplug_handle_disable() -> ::std::os::raw::c_int;
}
extern "C" {
    #[doc = " Device level DMA map function.\n After a successful call, the memory segment will be mapped to the\n given device.\n\n @note: Memory must be registered in advance using rte_extmem_* APIs.\n\n @param dev\n\tDevice pointer.\n @param addr\n\tVirtual address to map.\n @param iova\n\tIOVA address to map.\n @param len\n\tLength of the memory segment being mapped.\n\n @return\n\t0 if mapping was successful.\n\tNegative value and rte_errno is set otherwise."]
    pub fn rte_dev_dma_map(
        dev: *mut rte_device,
        addr: *mut ::std::os::raw::c_void,
        iova: u64,
        len: usize,
    ) -> ::std::os::raw::c_int;
}
extern "C" {
    #[doc = " Device level DMA unmap function.\n After a successful call, the memory segment will no longer be\n accessible by the given device.\n\n @note: Memory must be registered in advance using rte_extmem_* APIs.\n\n @param dev\n\tDevice pointer.\n @param addr\n\tVirtual address to unmap.\n @param iova\n\tIOVA address to unmap.\n @param len\n\tLength of the memory segment being mapped.\n\n @return\n\t0 if un-mapping was successful.\n\tNegative value and rte_errno is set otherwise."]
    pub fn rte_dev_dma_unmap(
        dev: *mut rte_device,
        addr: *mut ::std::os::raw::c_void,
        iova: u64,
        len: usize,
    ) -> ::std::os::raw::c_int;
}
#[doc = " A structure describing a device driver."]
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct rte_driver {
    #[doc = "< Next in list."]
    pub next: rte_driver__bindgen_ty_1,
    #[doc = "< Driver name."]
    pub name: *const ::std::os::raw::c_char,
    #[doc = "< Driver alias."]
    pub alias: *const ::std::os::raw::c_char,
}
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct rte_driver__bindgen_ty_1 {
    pub tqe_next: *mut rte_driver,
    pub tqe_prev: *mut *mut rte_driver,
}
#[doc = " A structure describing a generic device."]
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct rte_device {
    #[doc = "< Next device"]
    pub next: rte_device__bindgen_ty_1,
    #[doc = "< Device name"]
    pub name: *const ::std::os::raw::c_char,
    #[doc = "< Device bus specific information"]
    pub bus_info: *const ::std::os::raw::c_char,
    #[doc = "< Driver assigned after probing"]
    pub driver: *const rte_driver,
    #[doc = "< Bus handle assigned on scan"]
    pub bus: *const rte_bus,
    #[doc = "< NUMA node connection"]
    pub numa_node: ::std::os::raw::c_int,
    #[doc = "< Arguments for latest probing"]
    pub devargs: *mut rte_devargs,
}
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct rte_device__bindgen_ty_1 {
    pub tqe_next: *mut rte_device,
    pub tqe_prev: *mut *mut rte_device,
}
pub const rte_devtype_RTE_DEVTYPE_ALLOWED: rte_devtype = 0;
pub const rte_devtype_RTE_DEVTYPE_BLOCKED: rte_devtype = 1;
pub const rte_devtype_RTE_DEVTYPE_VIRTUAL: rte_devtype = 2;
#[doc = " Type of generic device"]
pub type rte_devtype = ::std::os::raw::c_uint;
#[doc = " Structure that stores a device given by the user with its arguments\n\n A user device is a physical or a virtual device given by the user to\n the DPDK application at startup through command line arguments.\n\n The structure stores the configuration of the device, its PCI\n identifier if it's a PCI device or the driver name if it's a virtual\n device."]
#[repr(C)]
#[derive(Copy, Clone)]
pub struct rte_devargs {
    #[doc = " Next in list."]
    pub next: rte_devargs__bindgen_ty_1,
    #[doc = " Type of device."]
    pub type_: rte_devtype,
    #[doc = " Device policy."]
    pub policy: rte_dev_policy,
    #[doc = " Name of the device."]
    pub name: [::std::os::raw::c_char; 64usize],
    pub __bindgen_anon_1: rte_devargs__bindgen_ty_2,
    #[doc = "< bus handle."]
    pub bus: *mut rte_bus,
    #[doc = "< class handle."]
    pub cls: *mut rte_class,
    #[doc = "< bus-related part of device string."]
    pub bus_str: *const ::std::os::raw::c_char,
    #[doc = "< class-related part of device string."]
    pub cls_str: *const ::std::os::raw::c_char,
    #[doc = "< raw string including bus, class and driver parts."]
    pub data: *mut ::std::os::raw::c_char,
}
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct rte_devargs__bindgen_ty_1 {
    pub tqe_next: *mut rte_devargs,
    pub tqe_prev: *mut *mut rte_devargs,
}
#[repr(C)]
#[derive(Copy, Clone)]
pub union rte_devargs__bindgen_ty_2 {
    #[doc = "< legacy name."]
    pub args: *const ::std::os::raw::c_char,
    #[doc = "< driver-related part of device string."]
    pub drv_str: *const ::std::os::raw::c_char,
}
extern "C" {
    #[doc = " Parse a device string.\n\n Verify that a bus is capable of handling the device passed\n in argument. Store which bus will handle the device, its name\n and the eventual device parameters.\n\n The syntax is:\n\n     bus:device_identifier,arg1=val1,arg2=val2\n\n where \"bus:\" is the bus name followed by any character separator.\n The bus name is optional. If no bus name is specified, each bus\n will attempt to recognize the device identifier. The first one\n to succeed will be used.\n\n Examples:\n\n     pci:0000:05.00.0,arg=val\n     05.00.0,arg=val\n     vdev:net_ring0\n\n @param da\n   The devargs structure holding the device information.\n\n @param dev\n   String describing a device.\n\n @return\n   - 0 on success.\n   - Negative errno on error."]
    pub fn rte_devargs_parse(
        da: *mut rte_devargs,
        dev: *const ::std::os::raw::c_char,
    ) -> ::std::os::raw::c_int;
}
extern "C" {
    #[doc = " Parse a device string.\n\n Verify that a bus is capable of handling the device passed\n in argument. Store which bus will handle the device, its name\n and the eventual device parameters.\n\n The device string is built with a printf-like syntax.\n\n The syntax is:\n\n     bus:device_identifier,arg1=val1,arg2=val2\n\n where \"bus:\" is the bus name followed by any character separator.\n The bus name is optional. If no bus name is specified, each bus\n will attempt to recognize the device identifier. The first one\n to succeed will be used.\n\n Examples:\n\n     pci:0000:05.00.0,arg=val\n     05.00.0,arg=val\n     vdev:net_ring0\n\n @param da\n   The devargs structure holding the device information.\n @param format\n   Format string describing a device.\n\n @return\n   - 0 on success.\n   - Negative errno on error."]
    pub fn rte_devargs_parsef(
        da: *mut rte_devargs,
        format: *const ::std::os::raw::c_char,
        ...
    ) -> ::std::os::raw::c_int;
}
extern "C" {
    #[doc = " Free resources in devargs.\n\n @param da\n   The devargs structure holding the device information."]
    pub fn rte_devargs_reset(da: *mut rte_devargs);
}
extern "C" {
    #[doc = " Insert an rte_devargs in the global list.\n\n @param da\n  The devargs structure to insert.\n  If a devargs for the same device is already inserted,\n  it will be updated and returned. It means *da pointer can change.\n\n @return\n   - 0 on success\n   - Negative on error."]
    pub fn rte_devargs_insert(da: *mut *mut rte_devargs) -> ::std::os::raw::c_int;
}
extern "C" {
    #[doc = " Add a device to the user device list\n See rte_devargs_parse() for details.\n\n @param devtype\n   The type of the device.\n @param devargs_str\n   The arguments as given by the user.\n\n @return\n   - 0 on success\n   - A negative value on error"]
    pub fn rte_devargs_add(
        devtype: rte_devtype,
        devargs_str: *const ::std::os::raw::c_char,
    ) -> ::std::os::raw::c_int;
}
extern "C" {
    #[doc = " Remove a device from the user device list.\n Its resources are freed.\n If the devargs cannot be found, nothing happens.\n\n @param devargs\n   The instance or a copy of devargs to remove.\n\n @return\n   0 on success.\n   <0 on error.\n   >0 if the devargs was not within the user device list."]
    pub fn rte_devargs_remove(devargs: *mut rte_devargs) -> ::std::os::raw::c_int;
}
extern "C" {
    #[doc = " Count the number of user devices of a specified type\n\n @param devtype\n   The type of the devices to counted.\n\n @return\n   The number of devices."]
    pub fn rte_devargs_type_count(devtype: rte_devtype) -> ::std::os::raw::c_uint;
}
extern "C" {
    #[doc = " This function dumps the list of user device and their arguments.\n\n @param f\n   A pointer to a file for output"]
    pub fn rte_devargs_dump(f: *mut FILE);
}
extern "C" {
    #[doc = " Find next rte_devargs matching the provided bus name.\n\n @param busname\n   Limit the iteration to devargs related to buses\n   matching this name.\n   Will return any next rte_devargs if NULL.\n\n @param start\n   Starting iteration point. The iteration will start at\n   the first rte_devargs if NULL.\n\n @return\n   Next rte_devargs entry matching the requested bus,\n   NULL if there is none."]
    pub fn rte_devargs_next(
        busname: *const ::std::os::raw::c_char,
        start: *const rte_devargs,
    ) -> *mut rte_devargs;
}
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct rte_vdev_device {
    #[doc = "< Next attached vdev"]
    pub next: rte_vdev_device__bindgen_ty_1,
    #[doc = "< Inherit core device"]
    pub device: rte_device,
}
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct rte_vdev_device__bindgen_ty_1 {
    pub tqe_next: *mut rte_vdev_device,
    pub tqe_prev: *mut *mut rte_vdev_device,
}
#[doc = " Probe function called for each virtual device driver once."]
pub type rte_vdev_probe_t =
    ::std::option::Option<unsafe extern "C" fn(dev: *mut rte_vdev_device) -> ::std::os::raw::c_int>;
#[doc = " Remove function called for each virtual device driver once."]
pub type rte_vdev_remove_t =
    ::std::option::Option<unsafe extern "C" fn(dev: *mut rte_vdev_device) -> ::std::os::raw::c_int>;
#[doc = " Driver-specific DMA mapping. After a successful call the device\n will be able to read/write from/to this segment.\n\n @param dev\n   Pointer to the Virtual device.\n @param addr\n   Starting virtual address of memory to be mapped.\n @param iova\n   Starting IOVA address of memory to be mapped.\n @param len\n   Length of memory segment being mapped.\n @return\n   - 0 On success.\n   - Negative value and rte_errno is set otherwise."]
pub type rte_vdev_dma_map_t = ::std::option::Option<
    unsafe extern "C" fn(
        dev: *mut rte_vdev_device,
        addr: *mut ::std::os::raw::c_void,
        iova: u64,
        len: usize,
    ) -> ::std::os::raw::c_int,
>;
#[doc = " Driver-specific DMA un-mapping. After a successful call the device\n will not be able to read/write from/to this segment.\n\n @param dev\n   Pointer to the Virtual device.\n @param addr\n   Starting virtual address of memory to be unmapped.\n @param iova\n   Starting IOVA address of memory to be unmapped.\n @param len\n   Length of memory segment being unmapped.\n @return\n   - 0 On success.\n   - Negative value and rte_errno is set otherwise."]
pub type rte_vdev_dma_unmap_t = ::std::option::Option<
    unsafe extern "C" fn(
        dev: *mut rte_vdev_device,
        addr: *mut ::std::os::raw::c_void,
        iova: u64,
        len: usize,
    ) -> ::std::os::raw::c_int,
>;
#[doc = " A virtual device driver abstraction."]
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct rte_vdev_driver {
    #[doc = "< Next in list."]
    pub next: rte_vdev_driver__bindgen_ty_1,
    #[doc = "< Inherited general driver."]
    pub driver: rte_driver,
    #[doc = "< Virtual device probe function."]
    pub probe: rte_vdev_probe_t,
    #[doc = "< Virtual device remove function."]
    pub remove: rte_vdev_remove_t,
    #[doc = "< Virtual device DMA map function."]
    pub dma_map: rte_vdev_dma_map_t,
    #[doc = "< Virtual device DMA unmap function."]
    pub dma_unmap: rte_vdev_dma_unmap_t,
    #[doc = "< Flags RTE_VDEV_DRV_*."]
    pub drv_flags: u32,
}
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct rte_vdev_driver__bindgen_ty_1 {
    pub tqe_next: *mut rte_vdev_driver,
    pub tqe_prev: *mut *mut rte_vdev_driver,
}
extern "C" {
    #[doc = " Register a virtual device driver.\n\n @param driver\n   A pointer to a rte_vdev_driver structure describing the driver\n   to be registered."]
    pub fn rte_vdev_register(driver: *mut rte_vdev_driver);
}
extern "C" {
    #[doc = " Unregister a virtual device driver.\n\n @param driver\n   A pointer to a rte_vdev_driver structure describing the driver\n   to be unregistered."]
    pub fn rte_vdev_unregister(driver: *mut rte_vdev_driver);
}
extern "C" {
    pub fn rte_vdev_count() -> ::std::os::raw::c_uint;
}
extern "C" {
    #[doc = " Seed the pseudo-random generator.\n\n The generator is automatically seeded by the EAL init with a timer\n value. It may need to be re-seeded by the user with a real random\n value.\n\n This function is not multi-thread safe in regards to other\n rte_srand() calls, nor is it in relation to concurrent rte_rand(),\n rte_rand_max() or rte_drand() calls.\n\n @param seedval\n   The value of the seed."]
    pub fn rte_srand(seedval: u64);
}
extern "C" {
    #[doc = " Get a pseudo-random value.\n\n The generator is not cryptographically secure.\n\n rte_rand(), rte_rand_max() and rte_drand() are multi-thread safe,\n with the exception that they may not be called by multiple\n _unregistered_ non-EAL threads in parallel.\n\n @return\n   A pseudo-random value between 0 and (1<<64)-1."]
    pub fn rte_rand() -> u64;
}
extern "C" {
    #[doc = " Generates a pseudo-random number with an upper bound.\n\n This function returns an uniformly distributed (unbiased) random\n number less than a user-specified maximum value.\n\n rte_rand(), rte_rand_max() and rte_drand() are multi-thread safe,\n with the exception that they may not be called by multiple\n _unregistered_ non-EAL threads in parallel.\n\n @param upper_bound\n   The upper bound of the generated number.\n @return\n   A pseudo-random value between 0 and (upper_bound-1)."]
    pub fn rte_rand_max(upper_bound: u64) -> u64;
}
extern "C" {
    #[doc = " Generates a pseudo-random floating point number.\n\n This function returns a non-negative double-precision floating random\n number uniformly distributed over the interval [0.0, 1.0).\n\n The generator is not cryptographically secure.\n\n rte_rand(), rte_rand_max() and rte_drand() are multi-thread safe,\n with the exception that they may not be called by multiple\n _unregistered_ non-EAL threads in parallel.\n\n @return\n   A pseudo-random value between 0 and 1.0."]
    pub fn rte_drand() -> f64;
}
#[doc = " Struct describing a Universal Unique Identifier"]
pub type rte_uuid_t = [::std::os::raw::c_uchar; 16usize];
extern "C" {
    #[doc = " Test if UUID is all zeros.\n\n @param uu\n    The uuid to check.\n @return\n    true if uuid is NULL value, false otherwise"]
    pub fn rte_uuid_is_null(uu: *const ::std::os::raw::c_uchar) -> bool;
}
extern "C" {
    #[doc = " Compare two UUID's\n\n @param a\n    A UUID to compare\n @param b\n    A UUID to compare\n @return\n   returns an integer less than, equal to, or greater than zero if UUID a is\n   is less than, equal, or greater than UUID b."]
    pub fn rte_uuid_compare(
        a: *const ::std::os::raw::c_uchar,
        b: *const ::std::os::raw::c_uchar,
    ) -> ::std::os::raw::c_int;
}
extern "C" {
    #[doc = " Extract UUID from string\n\n @param in\n    Pointer to string of characters to convert\n @param uu\n    Destination UUID\n @return\n    Returns 0 on success, and -1 if string is not a valid UUID."]
    pub fn rte_uuid_parse(
        in_: *const ::std::os::raw::c_char,
        uu: *mut ::std::os::raw::c_uchar,
    ) -> ::std::os::raw::c_int;
}
extern "C" {
    #[doc = " Convert UUID to string\n\n @param uu\n    UUID to format\n @param out\n    Resulting string buffer\n @param len\n    Sizeof the available string buffer"]
    pub fn rte_uuid_unparse(
        uu: *const ::std::os::raw::c_uchar,
        out: *mut ::std::os::raw::c_char,
        len: usize,
    );
}
pub const rte_intr_mode_RTE_INTR_MODE_NONE: rte_intr_mode = 0;
pub const rte_intr_mode_RTE_INTR_MODE_LEGACY: rte_intr_mode = 1;
pub const rte_intr_mode_RTE_INTR_MODE_MSI: rte_intr_mode = 2;
pub const rte_intr_mode_RTE_INTR_MODE_MSIX: rte_intr_mode = 3;
pub type rte_intr_mode = ::std::os::raw::c_uint;
pub const rte_proc_type_t_RTE_PROC_AUTO: rte_proc_type_t = -1;
pub const rte_proc_type_t_RTE_PROC_PRIMARY: rte_proc_type_t = 0;
pub const rte_proc_type_t_RTE_PROC_SECONDARY: rte_proc_type_t = 1;
pub const rte_proc_type_t_RTE_PROC_INVALID: rte_proc_type_t = 2;
#[doc = " The type of process in a linux, multi-process setup"]
pub type rte_proc_type_t = ::std::os::raw::c_int;
extern "C" {
    #[doc = " Get the process type in a multi-process setup\n\n @return\n   The process type"]
    pub fn rte_eal_process_type() -> rte_proc_type_t;
}
extern "C" {
    #[doc = " Request iopl privilege for all RPL.\n\n This function should be called by pmds which need access to ioports.\n\n @return\n   - On success, returns 0.\n   - On failure, returns -1."]
    pub fn rte_eal_iopl_init() -> ::std::os::raw::c_int;
}
extern "C" {
    #[doc = " Initialize the Environment Abstraction Layer (EAL).\n\n This function is to be executed on the MAIN lcore only, as soon\n as possible in the application's main() function.\n It puts the WORKER lcores in the WAIT state.\n\n @param argc\n   A non-negative value.  If it is greater than 0, the array members\n   for argv[0] through argv[argc] (non-inclusive) shall contain pointers\n   to strings.\n @param argv\n   An array of strings.  The contents of the array, as well as the strings\n   which are pointed to by the array, may be modified by this function.\n   The program name pointer argv[0] is copied into the last parsed argv\n   so that argv[0] is still the same after deducing the parsed arguments.\n @return\n   - On success, the number of parsed arguments, which is greater or\n     equal to zero. After the call to rte_eal_init(),\n     all arguments argv[x] with x < ret may have been modified by this\n     function call and should not be further interpreted by the\n     application.  The EAL does not take any ownership of the memory used\n     for either the argv array, or its members.\n   - On failure, -1 and rte_errno is set to a value indicating the cause\n     for failure.  In some instances, the application will need to be\n     restarted as part of clearing the issue.\n\n   Error codes returned via rte_errno:\n     EACCES indicates a permissions issue.\n\n     EAGAIN indicates either a bus or system resource was not available,\n            setup may be attempted again.\n\n     EALREADY indicates that the rte_eal_init function has already been\n              called, and cannot be called again.\n\n     EFAULT indicates the tailq configuration name was not found in\n            memory configuration.\n\n     EINVAL indicates invalid parameters were passed as argv/argc.\n\n     ENOMEM indicates failure likely caused by an out-of-memory condition.\n\n     ENODEV indicates memory setup issues.\n\n     ENOTSUP indicates that the EAL cannot initialize on this system.\n\n     EPROTO indicates that the PCI bus is either not present, or is not\n            readable by the eal.\n\n     ENOEXEC indicates that a service core failed to launch successfully."]
    pub fn rte_eal_init(
        argc: ::std::os::raw::c_int,
        argv: *mut *mut ::std::os::raw::c_char,
    ) -> ::std::os::raw::c_int;
}
extern "C" {
    #[doc = " Clean up the Environment Abstraction Layer (EAL)\n\n This function must be called to release any internal resources that EAL has\n allocated during rte_eal_init(). After this call, no DPDK function calls may\n be made. It is expected that common usage of this function is to call it\n just before terminating the process.\n\n @return\n  - 0 Successfully released all internal EAL resources.\n  - -EFAULT There was an error in releasing all resources."]
    pub fn rte_eal_cleanup() -> ::std::os::raw::c_int;
}
extern "C" {
    #[doc = " Check if a primary process is currently alive\n\n This function returns true when a primary process is currently\n active.\n\n @param config_file_path\n   The config_file_path argument provided should point at the location\n   that the primary process will create its config file. If NULL, the default\n   config file path is used.\n\n @return\n  - If alive, returns 1.\n  - If dead, returns 0."]
    pub fn rte_eal_primary_proc_alive(
        config_file_path: *const ::std::os::raw::c_char,
    ) -> ::std::os::raw::c_int;
}
extern "C" {
    #[doc = " Disable multiprocess.\n\n This function can be called to indicate that multiprocess won't be used for\n the rest of the application life.\n\n @return\n   - true if called from a primary process that had no secondary processes\n     attached,\n   - false, otherwise."]
    pub fn rte_mp_disable() -> bool;
}
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct rte_mp_msg {
    pub name: [::std::os::raw::c_char; 64usize],
    pub len_param: ::std::os::raw::c_int,
    pub num_fds: ::std::os::raw::c_int,
    pub param: [u8; 256usize],
    pub fds: [::std::os::raw::c_int; 253usize],
}
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct rte_mp_reply {
    pub nb_sent: ::std::os::raw::c_int,
    pub nb_received: ::std::os::raw::c_int,
    pub msgs: *mut rte_mp_msg,
}
#[doc = " Action function typedef used by other components.\n\n As we create  socket channel for primary/secondary communication, use\n this function typedef to register action for coming messages.\n\n @note When handling IPC request callbacks, the reply must be sent even in\n   cases of error handling. Simply returning success or failure will *not*\n   send a response to the requestor.\n   Implementation of error signalling mechanism is up to the application.\n\n @note No memory allocations should take place inside the callback."]
pub type rte_mp_t = ::std::option::Option<
    unsafe extern "C" fn(
        msg: *const rte_mp_msg,
        peer: *const ::std::os::raw::c_void,
    ) -> ::std::os::raw::c_int,
>;
#[doc = " Asynchronous reply function typedef used by other components.\n\n As we create socket channel for primary/secondary communication, use\n this function typedef to register action for coming responses to asynchronous\n requests.\n\n @note When handling IPC request callbacks, the reply must be sent even in\n   cases of error handling. Simply returning success or failure will *not*\n   send a response to the requestor.\n   Implementation of error signalling mechanism is up to the application.\n\n @note No memory allocations should take place inside the callback."]
pub type rte_mp_async_reply_t = ::std::option::Option<
    unsafe extern "C" fn(
        request: *const rte_mp_msg,
        reply: *const rte_mp_reply,
    ) -> ::std::os::raw::c_int,
>;
extern "C" {
    #[doc = " Register an action function for primary/secondary communication.\n\n Call this function to register an action, if the calling component wants\n to response the messages from the corresponding component in its primary\n process or secondary processes.\n\n @note IPC may be unsupported in certain circumstances, so caller should check\n    for ENOTSUP error.\n\n @param name\n   The name argument plays as the nonredundant key to find the action.\n\n @param action\n   The action argument is the function pointer to the action function.\n\n @return\n  - 0 on success.\n  - (<0) on failure."]
    pub fn rte_mp_action_register(
        name: *const ::std::os::raw::c_char,
        action: rte_mp_t,
    ) -> ::std::os::raw::c_int;
}
extern "C" {
    #[doc = " Unregister an action function for primary/secondary communication.\n\n Call this function to unregister an action  if the calling component does\n not want to response the messages from the corresponding component in its\n primary process or secondary processes.\n\n @note IPC may be unsupported in certain circumstances, so caller should check\n    for ENOTSUP error.\n\n @param name\n   The name argument plays as the nonredundant key to find the action."]
    pub fn rte_mp_action_unregister(name: *const ::std::os::raw::c_char);
}
extern "C" {
    #[doc = " Send a message to the peer process.\n\n This function will send a message which will be responded by the action\n identified by name in the peer process.\n\n @param msg\n   The msg argument contains the customized message.\n\n @return\n  - On success, return 0.\n  - On failure, return -1, and the reason will be stored in rte_errno."]
    pub fn rte_mp_sendmsg(msg: *mut rte_mp_msg) -> ::std::os::raw::c_int;
}
extern "C" {
    #[doc = " Send a request to the peer process and expect a reply.\n\n This function sends a request message to the peer process, and will\n block until receiving reply message from the peer process.\n\n @note The caller is responsible to free reply->replies.\n\n @note This API must not be used inside memory-related or IPC callbacks, and\n   no memory allocations should take place inside such callback.\n\n @note IPC may be unsupported in certain circumstances, so caller should check\n    for ENOTSUP error.\n\n @param req\n   The req argument contains the customized request message.\n\n @param reply\n   The reply argument will be for storing all the replied messages;\n   the caller is responsible for free reply->msgs.\n\n @param ts\n   The ts argument specifies how long we can wait for the peer(s) to reply.\n\n @return\n  - On success, return 0.\n  - On failure, return -1, and the reason will be stored in rte_errno."]
    pub fn rte_mp_request_sync(
        req: *mut rte_mp_msg,
        reply: *mut rte_mp_reply,
        ts: *const timespec,
    ) -> ::std::os::raw::c_int;
}
extern "C" {
    #[doc = " Send a request to the peer process and expect a reply in a separate callback.\n\n This function sends a request message to the peer process, and will not\n block. Instead, reply will be received in a separate callback.\n\n @note IPC may be unsupported in certain circumstances, so caller should check\n    for ENOTSUP error.\n\n @param req\n   The req argument contains the customized request message.\n\n @param ts\n   The ts argument specifies how long we can wait for the peer(s) to reply.\n\n @param clb\n   The callback to trigger when all responses for this request have arrived.\n\n @return\n  - On success, return 0.\n  - On failure, return -1, and the reason will be stored in rte_errno."]
    pub fn rte_mp_request_async(
        req: *mut rte_mp_msg,
        ts: *const timespec,
        clb: rte_mp_async_reply_t,
    ) -> ::std::os::raw::c_int;
}
extern "C" {
    #[doc = " Send a reply to the peer process.\n\n This function will send a reply message in response to a request message\n received previously.\n\n @note When handling IPC request callbacks, the reply must be sent even in\n   cases of error handling. Simply returning success or failure will *not*\n   send a response to the requestor.\n   Implementation of error signalling mechanism is up to the application.\n\n @param msg\n   The msg argument contains the customized message.\n\n @param peer\n   The peer argument is the pointer to the peer socket path.\n\n @return\n  - On success, return 0.\n  - On failure, return -1, and the reason will be stored in rte_errno."]
    pub fn rte_mp_reply(
        msg: *mut rte_mp_msg,
        peer: *const ::std::os::raw::c_char,
    ) -> ::std::os::raw::c_int;
}
#[doc = " Usage function typedef used by the application usage function.\n\n Use this function typedef to define and call rte_set_application_usage_hook()\n routine."]
pub type rte_usage_hook_t =
    ::std::option::Option<unsafe extern "C" fn(prgname: *const ::std::os::raw::c_char)>;
extern "C" {
    #[doc = " Add application usage routine callout from the eal_usage() routine.\n\n This function allows the application to include its usage message\n in the EAL system usage message. The routine rte_set_application_usage_hook()\n needs to be called before the rte_eal_init() routine in the application.\n\n This routine is optional for the application and will behave as if the set\n routine was never called as the default behavior.\n\n @param usage_func\n   The func argument is a function pointer to the application usage routine.\n   Called function is defined using rte_usage_hook_t typedef, which is of\n   the form void rte_usage_func(const char * prgname).\n\n   Calling this routine with a NULL value will reset the usage hook routine and\n   return the current value, which could be NULL.\n @return\n   - Returns the current value of the rte_application_usage pointer to allow\n     the caller to daisy chain the usage routines if needing more then one."]
    pub fn rte_set_application_usage_hook(usage_func: rte_usage_hook_t) -> rte_usage_hook_t;
}
extern "C" {
    #[doc = " Whether EAL is using huge pages (disabled by --no-huge option).\n The no-huge mode is not compatible with all drivers or features.\n\n @return\n   Nonzero if hugepages are enabled."]
    pub fn rte_eal_has_hugepages() -> ::std::os::raw::c_int;
}
extern "C" {
    #[doc = " Whether EAL is using PCI bus.\n Disabled by --no-pci option.\n\n @return\n   Nonzero if the PCI bus is enabled."]
    pub fn rte_eal_has_pci() -> ::std::os::raw::c_int;
}
extern "C" {
    #[doc = " Whether the EAL was asked to create UIO device.\n\n @return\n   Nonzero if true."]
    pub fn rte_eal_create_uio_dev() -> ::std::os::raw::c_int;
}
extern "C" {
    #[doc = " The user-configured vfio interrupt mode.\n\n @return\n   Interrupt mode configured with the command line,\n   RTE_INTR_MODE_NONE by default."]
    pub fn rte_eal_vfio_intr_mode() -> rte_intr_mode;
}
extern "C" {
    #[doc = " Copy the user-configured vfio VF token.\n\n @param vf_token\n   vfio VF token configured with the command line is copied\n   into this parameter, zero uuid by default."]
    pub fn rte_eal_vfio_get_vf_token(vf_token: *mut ::std::os::raw::c_uchar);
}
extern "C" {
    #[doc = " A wrap API for syscall gettid.\n\n @return\n   On success, returns the thread ID of calling process.\n   It is always successful."]
    pub fn rte_sys_gettid() -> ::std::os::raw::c_int;
}
extern "C" {
    #[doc = " Get the OS-specific EAL base address.\n\n @return\n    The base address."]
    pub fn rte_eal_get_baseaddr() -> u64;
}
pub const rte_iova_mode_RTE_IOVA_DC: rte_iova_mode = 0;
pub const rte_iova_mode_RTE_IOVA_PA: rte_iova_mode = 1;
pub const rte_iova_mode_RTE_IOVA_VA: rte_iova_mode = 2;
#[doc = " IOVA mapping mode.\n\n IOVA mapping mode is iommu programming mode of a device.\n That device (for example: IOMMU backed DMA device) based\n on rte_iova_mode will generate physical or virtual address."]
pub type rte_iova_mode = ::std::os::raw::c_uint;
extern "C" {
    #[doc = " Get the iova mode\n\n @return\n   enum rte_iova_mode value."]
    pub fn rte_eal_iova_mode() -> rte_iova_mode;
}
extern "C" {
    #[doc = " Get user provided pool ops name for mbuf\n\n @return\n   returns user provided pool ops name."]
    pub fn rte_eal_mbuf_user_pool_ops() -> *const ::std::os::raw::c_char;
}
extern "C" {
    #[doc = " Get the runtime directory of DPDK\n\n @return\n  The runtime directory path of DPDK"]
    pub fn rte_eal_get_runtime_dir() -> *const ::std::os::raw::c_char;
}
extern "C" {
    #[doc = " Convert a string describing a mask of core ids into an array of core ids.\n\n On success, the passed array is filled with the orders of the core ids\n present in the mask (-1 indicating that a core id is absent).\n For example, passing a 0xa coremask results in cores[1] = 0, cores[3] = 1,\n and the rest of the array is set to -1.\n\n @param coremask\n   A string describing a mask of core ids.\n @param cores\n   An array where to store the core ids orders.\n   This array must be at least RTE_MAX_LCORE large.\n @return\n   0 on success, -1 if the string content was invalid."]
    pub fn rte_eal_parse_coremask(
        coremask: *const ::std::os::raw::c_char,
        cores: *mut ::std::os::raw::c_int,
    ) -> ::std::os::raw::c_int;
}
pub const rte_lcore_state_t_WAIT: rte_lcore_state_t = 0;
pub const rte_lcore_state_t_RUNNING: rte_lcore_state_t = 1;
#[doc = " State of an lcore."]
pub type rte_lcore_state_t = ::std::os::raw::c_uint;
#[doc = " Definition of a remote launch function."]
pub type lcore_function_t = ::std::option::Option<
    unsafe extern "C" fn(arg1: *mut ::std::os::raw::c_void) -> ::std::os::raw::c_int,
>;
extern "C" {
    #[doc = " Launch a function on another lcore.\n\n To be executed on the MAIN lcore only.\n\n Sends a message to a worker lcore (identified by the worker_id) that\n is in the WAIT state (this is true after the first call to\n rte_eal_init()). This can be checked by first calling\n rte_eal_wait_lcore(worker_id).\n\n When the remote lcore receives the message, it switches to\n the RUNNING state, then calls the function f with argument arg. Once the\n execution is done, the remote lcore switches to WAIT state and\n the return value of f is stored in a local variable to be read using\n rte_eal_wait_lcore().\n\n The MAIN lcore returns as soon as the message is sent and knows\n nothing about the completion of f.\n\n Note: This function is not designed to offer optimum\n performance. It is just a practical way to launch a function on\n another lcore at initialization time.\n\n @param f\n   The function to be called.\n @param arg\n   The argument for the function.\n @param worker_id\n   The identifier of the lcore on which the function should be executed.\n @return\n   - 0: Success. Execution of function f started on the remote lcore.\n   - (-EBUSY): The remote lcore is not in a WAIT state.\n   - (-EPIPE): Error reading or writing pipe to worker thread"]
    pub fn rte_eal_remote_launch(
        f: lcore_function_t,
        arg: *mut ::std::os::raw::c_void,
        worker_id: ::std::os::raw::c_uint,
    ) -> ::std::os::raw::c_int;
}
#[doc = "< lcore handler not executed by main core."]
pub const rte_rmt_call_main_t_SKIP_MAIN: rte_rmt_call_main_t = 0;
#[doc = "< lcore handler executed by main core."]
pub const rte_rmt_call_main_t_CALL_MAIN: rte_rmt_call_main_t = 1;
#[doc = " This enum indicates whether the main core must execute the handler\n launched on all logical cores."]
pub type rte_rmt_call_main_t = ::std::os::raw::c_uint;
extern "C" {
    #[doc = " Launch a function on all lcores.\n\n Check that each WORKER lcore is in a WAIT state, then call\n rte_eal_remote_launch() for each lcore.\n\n @param f\n   The function to be called.\n @param arg\n   The argument for the function.\n @param call_main\n   If call_main set to SKIP_MAIN, the MAIN lcore does not call\n   the function. If call_main is set to CALL_MAIN, the function\n   is also called on main before returning. In any case, the main\n   lcore returns as soon as it finished its job and knows nothing\n   about the completion of f on the other lcores.\n @return\n   - 0: Success. Execution of function f started on all remote lcores.\n   - (-EBUSY): At least one remote lcore is not in a WAIT state. In this\n     case, no message is sent to any of the lcores."]
    pub fn rte_eal_mp_remote_launch(
        f: lcore_function_t,
        arg: *mut ::std::os::raw::c_void,
        call_main: rte_rmt_call_main_t,
    ) -> ::std::os::raw::c_int;
}
extern "C" {
    #[doc = " Get the state of the lcore identified by worker_id.\n\n To be executed on the MAIN lcore only.\n\n @param worker_id\n   The identifier of the lcore.\n @return\n   The state of the lcore."]
    pub fn rte_eal_get_lcore_state(worker_id: ::std::os::raw::c_uint) -> rte_lcore_state_t;
}
extern "C" {
    #[doc = " Wait until an lcore finishes its job.\n\n To be executed on the MAIN lcore only.\n\n If the lcore identified by the worker_id is in RUNNING state, wait until\n the lcore finishes its job and moves to the WAIT state.\n\n @param worker_id\n   The identifier of the lcore.\n @return\n   - 0: If the remote launch function was never called on the lcore\n     identified by the worker_id.\n   - The value that was returned by the previous remote launch\n     function call."]
    pub fn rte_eal_wait_lcore(worker_id: ::std::os::raw::c_uint) -> ::std::os::raw::c_int;
}
extern "C" {
    #[doc = " Wait until all lcores finish their jobs.\n\n To be executed on the MAIN lcore only. Issue an\n rte_eal_wait_lcore() for every lcore. The return values are\n ignored.\n\n After a call to rte_eal_mp_wait_lcore(), the caller can assume\n that all worker lcores are in a WAIT state."]
    pub fn rte_eal_mp_wait_lcore();
}
#[doc = " Thread id descriptor."]
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct rte_thread_t {
    #[doc = "< thread identifier"]
    pub opaque_id: usize,
}
#[doc = " Thread function\n\n Function pointer to thread start routine.\n\n @param arg\n   Argument passed to rte_thread_create().\n @return\n   Thread function exit value."]
pub type rte_thread_func =
    ::std::option::Option<unsafe extern "C" fn(arg: *mut ::std::os::raw::c_void) -> u32>;
pub const rte_thread_priority_RTE_THREAD_PRIORITY_NORMAL: rte_thread_priority = 0;
pub const rte_thread_priority_RTE_THREAD_PRIORITY_REALTIME_CRITICAL: rte_thread_priority = 1;
#[doc = " Thread priority values."]
pub type rte_thread_priority = ::std::os::raw::c_uint;
#[doc = " Representation for thread attributes."]
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct rte_thread_attr_t {
    #[doc = "< thread priority"]
    pub priority: rte_thread_priority,
}
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct eal_tls_key {
    _unused: [u8; 0],
}
#[doc = " TLS key type, an opaque pointer."]
pub type rte_thread_key = *mut eal_tls_key;
extern "C" {
    #[doc = " Create a new thread that will invoke the 'thread_func' routine.\n\n @param thread_id\n    A pointer that will store the id of the newly created thread.\n\n @param thread_attr\n    Attributes that are used at the creation of the new thread.\n\n @param thread_func\n    The routine that the new thread will invoke when starting execution.\n\n @param arg\n    Argument to be passed to the 'thread_func' routine.\n\n @return\n   On success, return 0.\n   On failure, return a positive errno-style error number."]
    pub fn rte_thread_create(
        thread_id: *mut rte_thread_t,
        thread_attr: *const rte_thread_attr_t,
        thread_func: rte_thread_func,
        arg: *mut ::std::os::raw::c_void,
    ) -> ::std::os::raw::c_int;
}
extern "C" {
    #[doc = " Create a control thread.\n\n Creates a control thread with the given name and attributes. The\n affinity of the new thread is based on the CPU affinity retrieved\n at the time rte_eal_init() was called, the EAL threads are then\n excluded. If setting the name of the thread fails, the error is\n ignored and a debug message is logged.\n\n @param thread\n   Filled with the thread id of the new created thread.\n @param name\n   The name of the control thread\n   (max RTE_THREAD_NAME_SIZE characters including '\\0').\n @param thread_func\n   Function to be executed by the new thread.\n @param arg\n   Argument passed to thread_func.\n @return\n   On success, returns 0; on error, it returns a negative value\n   corresponding to the error number."]
    pub fn rte_thread_create_control(
        thread: *mut rte_thread_t,
        name: *const ::std::os::raw::c_char,
        thread_func: rte_thread_func,
        arg: *mut ::std::os::raw::c_void,
    ) -> ::std::os::raw::c_int;
}
extern "C" {
    #[doc = " Create an internal control thread.\n\n Creates a control thread with the given name prefixed.\n If setting the name of the thread fails, the error is ignored and logged.\n\n The affinity of the new thread is based on the CPU affinity retrieved\n at the time rte_eal_init() was called, the EAL threads are then excluded.\n\n @param id\n   Filled with the thread ID of the new created thread.\n @param name\n   The name of the control thread.\n   See RTE_THREAD_INTERNAL_NAME_SIZE for maximum length.\n   The name of the driver or library should be first,\n   then followed by a hyphen and more details.\n   It will be prefixed with RTE_THREAD_INTERNAL_PREFIX by this function.\n @param func\n   Function to be executed by the new thread.\n @param arg\n   Argument passed to func.\n @return\n   On success, returns 0; a negative value otherwise."]
    pub fn rte_thread_create_internal_control(
        id: *mut rte_thread_t,
        name: *const ::std::os::raw::c_char,
        func: rte_thread_func,
        arg: *mut ::std::os::raw::c_void,
    ) -> ::std::os::raw::c_int;
}
extern "C" {
    #[doc = " Waits for the thread identified by 'thread_id' to terminate\n\n @param thread_id\n    The identifier of the thread.\n\n @param value_ptr\n    Stores the exit status of the thread.\n\n @return\n   On success, return 0.\n   On failure, return a positive errno-style error number."]
    pub fn rte_thread_join(thread_id: rte_thread_t, value_ptr: *mut u32) -> ::std::os::raw::c_int;
}
extern "C" {
    #[doc = " Indicate that the return value of the thread is not needed and\n all thread resources should be release when the thread terminates.\n\n @param thread_id\n    The id of the thread to be detached.\n\n @return\n   On success, return 0.\n   On failure, return a positive errno-style error number."]
    pub fn rte_thread_detach(thread_id: rte_thread_t) -> ::std::os::raw::c_int;
}
extern "C" {
    #[doc = " Get the id of the calling thread.\n\n @return\n   Return the thread id of the calling thread."]
    pub fn rte_thread_self() -> rte_thread_t;
}
extern "C" {
    #[doc = " Set the name of the thread.\n\n This API is a noop if the underlying platform does not\n support setting the thread name or the platform-specific\n API used to set the thread name fails.\n\n @param thread_id\n    The id of the thread to set name.\n\n @param thread_name\n    The name to set. Truncated to RTE_THREAD_NAME_SIZE,\n    including terminating NUL if necessary."]
    pub fn rte_thread_set_name(thread_id: rte_thread_t, thread_name: *const ::std::os::raw::c_char);
}
extern "C" {
    #[doc = " Set the name of an internal thread with the common prefix.\n\n This API is a noop if the underlying platform does not support\n setting the thread name, or if it fails.\n\n @param id\n   The ID of the thread to set name.\n\n @param name\n   The name to set after being prefixed.\n   See RTE_THREAD_INTERNAL_NAME_SIZE for maximum length.\n   The name of the driver or library should be first,\n   then followed by a hyphen and more details.\n   It will be prefixed with RTE_THREAD_INTERNAL_PREFIX by this function."]
    pub fn rte_thread_set_prefixed_name(id: rte_thread_t, name: *const ::std::os::raw::c_char);
}
extern "C" {
    #[doc = " Check if 2 thread ids are equal.\n\n @param t1\n   First thread id.\n\n @param t2\n   Second thread id.\n\n @return\n   If the ids are equal, return nonzero.\n   Otherwise, return 0."]
    pub fn rte_thread_equal(t1: rte_thread_t, t2: rte_thread_t) -> ::std::os::raw::c_int;
}
extern "C" {
    #[doc = " Initialize the attributes of a thread.\n These attributes can be passed to the rte_thread_create() function\n that will create a new thread and set its attributes according to attr.\n\n @param attr\n   Thread attributes to initialize.\n\n @return\n   On success, return 0.\n   On failure, return a positive errno-style error number."]
    pub fn rte_thread_attr_init(attr: *mut rte_thread_attr_t) -> ::std::os::raw::c_int;
}
extern "C" {
    #[doc = " Set the thread priority value in the thread attributes pointed to\n by 'thread_attr'.\n\n @param thread_attr\n   Points to the thread attributes in which priority will be updated.\n\n @param priority\n   Points to the value of the priority to be set.\n\n @return\n   On success, return 0.\n   On failure, return a positive errno-style error number."]
    pub fn rte_thread_attr_set_priority(
        thread_attr: *mut rte_thread_attr_t,
        priority: rte_thread_priority,
    ) -> ::std::os::raw::c_int;
}
extern "C" {
    #[doc = " Get the priority of a thread.\n\n @param thread_id\n   Id of the thread for which to get priority.\n\n @param priority\n   Location to store the retrieved priority.\n\n @return\n   On success, return 0.\n   On failure, return a positive errno-style error number."]
    pub fn rte_thread_get_priority(
        thread_id: rte_thread_t,
        priority: *mut rte_thread_priority,
    ) -> ::std::os::raw::c_int;
}
extern "C" {
    #[doc = " Set the priority of a thread.\n\n @param thread_id\n   Id of the thread for which to set priority.\n\n @param priority\n   Priority value to be set.\n\n @return\n   On success, return 0.\n   On failure, return a positive errno-style error number."]
    pub fn rte_thread_set_priority(
        thread_id: rte_thread_t,
        priority: rte_thread_priority,
    ) -> ::std::os::raw::c_int;
}
extern "C" {
    #[doc = " Create a TLS data key visible to all threads in the process.\n the created key is later used to get/set a value.\n and optional destructor can be set to be called when a thread exits.\n\n @param key\n   Pointer to store the allocated key.\n @param destructor\n   The function to be called when the thread exits.\n   Ignored on Windows OS.\n\n @return\n   On success, zero.\n   On failure, a negative number and an error number is set in rte_errno.\n   rte_errno can be: ENOMEM  - Memory allocation error.\n                     ENOEXEC - Specific OS error."]
    pub fn rte_thread_key_create(
        key: *mut rte_thread_key,
        destructor: ::std::option::Option<unsafe extern "C" fn(arg1: *mut ::std::os::raw::c_void)>,
    ) -> ::std::os::raw::c_int;
}
extern "C" {
    #[doc = " Delete a TLS data key visible to all threads in the process.\n\n @param key\n   The key allocated by rte_thread_key_create().\n\n @return\n   On success, zero.\n   On failure, a negative number and an error number is set in rte_errno.\n   rte_errno can be: EINVAL  - Invalid parameter passed.\n                     ENOEXEC - Specific OS error."]
    pub fn rte_thread_key_delete(key: rte_thread_key) -> ::std::os::raw::c_int;
}
extern "C" {
    #[doc = " Set value bound to the TLS key on behalf of the calling thread.\n\n @param key\n   The key allocated by rte_thread_key_create().\n @param value\n   The value bound to the rte_thread_key key for the calling thread.\n\n @return\n   On success, zero.\n   On failure, a negative number and an error number is set in rte_errno.\n   rte_errno can be: EINVAL  - Invalid parameter passed.\n                     ENOEXEC - Specific OS error."]
    pub fn rte_thread_value_set(
        key: rte_thread_key,
        value: *const ::std::os::raw::c_void,
    ) -> ::std::os::raw::c_int;
}
extern "C" {
    #[doc = " Get value bound to the TLS key on behalf of the calling thread.\n\n @param key\n   The key allocated by rte_thread_key_create().\n\n @return\n   On success, value data pointer (can also be NULL).\n   On failure, NULL and an error number is set in rte_errno.\n   rte_errno can be: EINVAL  - Invalid parameter passed.\n                     ENOEXEC - Specific OS error."]
    pub fn rte_thread_value_get(key: rte_thread_key) -> *mut ::std::os::raw::c_void;
}
pub const rte_lcore_role_t_ROLE_RTE: rte_lcore_role_t = 0;
pub const rte_lcore_role_t_ROLE_OFF: rte_lcore_role_t = 1;
pub const rte_lcore_role_t_ROLE_SERVICE: rte_lcore_role_t = 2;
pub const rte_lcore_role_t_ROLE_NON_EAL: rte_lcore_role_t = 3;
#[doc = " The lcore role (used in RTE or not)."]
pub type rte_lcore_role_t = ::std::os::raw::c_uint;
extern "C" {
    #[doc = " Get a lcore's role.\n\n @param lcore_id\n   The identifier of the lcore, which MUST be between 0 and RTE_MAX_LCORE-1.\n @return\n   The role of the lcore."]
    pub fn rte_eal_lcore_role(lcore_id: ::std::os::raw::c_uint) -> rte_lcore_role_t;
}
extern "C" {
    #[doc = " Test if the core supplied has a specific role\n\n @param lcore_id\n   The identifier of the lcore, which MUST be between 0 and\n   RTE_MAX_LCORE-1.\n @param role\n   The role to be checked against.\n @return\n   Boolean value: positive if test is true; otherwise returns 0."]
    pub fn rte_lcore_has_role(
        lcore_id: ::std::os::raw::c_uint,
        role: rte_lcore_role_t,
    ) -> ::std::os::raw::c_int;
}
extern "C" {
    #[doc = " Get the id of the main lcore\n\n @return\n   the id of the main lcore"]
    pub fn rte_get_main_lcore() -> ::std::os::raw::c_uint;
}
extern "C" {
    #[doc = " Return the number of execution units (lcores) on the system.\n\n @return\n   the number of execution units (lcores) on the system."]
    pub fn rte_lcore_count() -> ::std::os::raw::c_uint;
}
extern "C" {
    #[doc = " Return the index of the lcore starting from zero.\n\n When option -c or -l is given, the index corresponds\n to the order in the list.\n For example:\n -c 0x30, lcore 4 has index 0, and 5 has index 1.\n -l 22,18 lcore 22 has index 0, and 18 has index 1.\n\n @param lcore_id\n   The targeted lcore, or -1 for the current one.\n @return\n   The relative index, or -1 if not enabled."]
    pub fn rte_lcore_index(lcore_id: ::std::os::raw::c_int) -> ::std::os::raw::c_int;
}
extern "C" {
    #[doc = " Return the ID of the physical socket of the logical core we are\n running on.\n @return\n   the ID of current lcoreid's physical socket"]
    pub fn rte_socket_id() -> ::std::os::raw::c_uint;
}
extern "C" {
    #[doc = " Return number of physical sockets detected on the system.\n\n Note that number of nodes may not be correspondent to their physical id's:\n for example, a system may report two socket id's, but the actual socket id's\n may be 0 and 8.\n\n @return\n   the number of physical sockets as recognized by EAL"]
    pub fn rte_socket_count() -> ::std::os::raw::c_uint;
}
extern "C" {
    #[doc = " Return socket id with a particular index.\n\n This will return socket id at a particular position in list of all detected\n physical socket id's. For example, on a machine with sockets [0, 8], passing\n 1 as a parameter will return 8.\n\n @param idx\n   index of physical socket id to return\n\n @return\n   - physical socket id as recognized by EAL\n   - -1 on error, with errno set to EINVAL"]
    pub fn rte_socket_id_by_idx(idx: ::std::os::raw::c_uint) -> ::std::os::raw::c_int;
}
extern "C" {
    #[doc = " Get the ID of the physical socket of the specified lcore\n\n @param lcore_id\n   the targeted lcore, which MUST be between 0 and RTE_MAX_LCORE-1.\n @return\n   the ID of lcoreid's physical socket"]
    pub fn rte_lcore_to_socket_id(lcore_id: ::std::os::raw::c_uint) -> ::std::os::raw::c_uint;
}
extern "C" {
    #[doc = " Return the id of the lcore on a socket starting from zero.\n\n @param lcore_id\n   The targeted lcore, or -1 for the current one.\n @return\n   The relative index, or -1 if not enabled."]
    pub fn rte_lcore_to_cpu_id(lcore_id: ::std::os::raw::c_int) -> ::std::os::raw::c_int;
}
extern "C" {
    #[doc = " Test if an lcore is enabled.\n\n @param lcore_id\n   The identifier of the lcore, which MUST be between 0 and\n   RTE_MAX_LCORE-1.\n @return\n   True if the given lcore is enabled; false otherwise."]
    pub fn rte_lcore_is_enabled(lcore_id: ::std::os::raw::c_uint) -> ::std::os::raw::c_int;
}
extern "C" {
    #[doc = " Get the next enabled lcore ID.\n\n @param i\n   The current lcore (reference).\n @param skip_main\n   If true, do not return the ID of the main lcore.\n @param wrap\n   If true, go back to 0 when RTE_MAX_LCORE is reached; otherwise,\n   return RTE_MAX_LCORE.\n @return\n   The next lcore_id or RTE_MAX_LCORE if not found."]
    pub fn rte_get_next_lcore(
        i: ::std::os::raw::c_uint,
        skip_main: ::std::os::raw::c_int,
        wrap: ::std::os::raw::c_int,
    ) -> ::std::os::raw::c_uint;
}
#[doc = " Callback prototype for initializing lcores.\n\n @param lcore_id\n   The lcore to consider.\n @param arg\n   An opaque pointer passed at callback registration.\n @return\n   - -1 when refusing this operation,\n   - 0 otherwise."]
pub type rte_lcore_init_cb = ::std::option::Option<
    unsafe extern "C" fn(
        lcore_id: ::std::os::raw::c_uint,
        arg: *mut ::std::os::raw::c_void,
    ) -> ::std::os::raw::c_int,
>;
#[doc = " Callback prototype for uninitializing lcores.\n\n @param lcore_id\n   The lcore to consider.\n @param arg\n   An opaque pointer passed at callback registration."]
pub type rte_lcore_uninit_cb = ::std::option::Option<
    unsafe extern "C" fn(lcore_id: ::std::os::raw::c_uint, arg: *mut ::std::os::raw::c_void),
>;
extern "C" {
    #[doc = " Register callbacks invoked when initializing and uninitializing a lcore.\n\n This function calls the init callback with all initialized lcores.\n Any error reported by the init callback triggers a rollback calling the\n uninit callback for each lcore.\n If this step succeeds, the callbacks are put in the lcore callbacks list\n that will get called for each lcore allocation/release.\n\n Note: callbacks execution is serialised under a write lock protecting the\n lcores and callbacks list.\n\n @param name\n   A name serving as a small description for this callback.\n @param init\n   The callback invoked when a lcore_id is initialized.\n   init can be NULL.\n @param uninit\n   The callback invoked when a lcore_id is uninitialized.\n   uninit can be NULL.\n @param arg\n   An optional argument that gets passed to the callback when it gets\n   invoked.\n @return\n   On success, returns an opaque pointer for the registered object.\n   On failure (either memory allocation issue in the function itself or an\n   error is returned by the init callback itself), returns NULL."]
    pub fn rte_lcore_callback_register(
        name: *const ::std::os::raw::c_char,
        init: rte_lcore_init_cb,
        uninit: rte_lcore_uninit_cb,
        arg: *mut ::std::os::raw::c_void,
    ) -> *mut ::std::os::raw::c_void;
}
extern "C" {
    #[doc = " Unregister callbacks previously registered with rte_lcore_callback_register.\n\n This function calls the uninit callback with all initialized lcores.\n The callbacks are then removed from the lcore callbacks list.\n\n @param handle\n   The handle pointer returned by a former successful call to\n   rte_lcore_callback_register."]
    pub fn rte_lcore_callback_unregister(handle: *mut ::std::os::raw::c_void);
}
#[doc = " Callback prototype for iterating over lcores.\n\n @param lcore_id\n   The lcore to consider.\n @param arg\n   An opaque pointer coming from the caller.\n @return\n   - 0 lets the iteration continue.\n   - !0 makes the iteration stop."]
pub type rte_lcore_iterate_cb = ::std::option::Option<
    unsafe extern "C" fn(
        lcore_id: ::std::os::raw::c_uint,
        arg: *mut ::std::os::raw::c_void,
    ) -> ::std::os::raw::c_int,
>;
extern "C" {
    #[doc = " Iterate on all active lcores (ROLE_RTE, ROLE_SERVICE and ROLE_NON_EAL).\n No modification on the lcore states is allowed in the callback.\n\n Note: as opposed to init/uninit callbacks, iteration callbacks can be\n invoked in parallel as they are run under a read lock protecting the lcores\n and callbacks list.\n\n @param cb\n   The callback that gets passed each lcore.\n @param arg\n   An opaque pointer passed to cb.\n @return\n   Same return code as the callback last invocation (see rte_lcore_iterate_cb\n   description)."]
    pub fn rte_lcore_iterate(
        cb: rte_lcore_iterate_cb,
        arg: *mut ::std::os::raw::c_void,
    ) -> ::std::os::raw::c_int;
}
#[doc = " lcore usage statistics."]
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct rte_lcore_usage {
    #[doc = " The total amount of time that the application has been running on\n this lcore, in TSC cycles."]
    pub total_cycles: u64,
    #[doc = " The amount of time the application was busy, handling some\n workload on this lcore, in TSC cycles."]
    pub busy_cycles: u64,
}
#[doc = " Callback to allow applications to report lcore usage.\n\n @param [in] lcore_id\n   The lcore to consider.\n @param [out] usage\n   Counters representing this lcore usage. This can never be NULL.\n @return\n   - 0 if fields in usage were updated successfully. The fields that the\n     application does not support must not be modified.\n   - a negative value if the information is not available or if any error\n     occurred."]
pub type rte_lcore_usage_cb = ::std::option::Option<
    unsafe extern "C" fn(
        lcore_id: ::std::os::raw::c_uint,
        usage: *mut rte_lcore_usage,
    ) -> ::std::os::raw::c_int,
>;
extern "C" {
    #[doc = " Register a callback from an application to be called in rte_lcore_dump() and\n the /eal/lcore/info telemetry endpoint handler. Applications are expected to\n report lcore usage statistics via this callback.\n\n If a callback was already registered, it can be replaced with another callback\n or unregistered with NULL. The previously registered callback may remain in\n use for an undetermined period of time.\n\n @param cb\n   The callback function."]
    pub fn rte_lcore_register_usage_cb(cb: rte_lcore_usage_cb);
}
extern "C" {
    #[doc = " List all lcores.\n\n @param f\n   The output stream where the dump should be sent."]
    pub fn rte_lcore_dump(f: *mut FILE);
}
extern "C" {
    #[doc = " Register current non-EAL thread as a lcore.\n\n @note This API is not compatible with the multi-process feature:\n - if a primary process registers a non-EAL thread, then no secondary process\n   will initialise.\n - if a secondary process initialises successfully, trying to register a\n   non-EAL thread from either primary or secondary processes will always end\n   up with the thread getting LCORE_ID_ANY as lcore.\n\n @return\n   On success, return 0; otherwise return -1 with rte_errno set."]
    pub fn rte_thread_register() -> ::std::os::raw::c_int;
}
extern "C" {
    #[doc = " Unregister current thread and release lcore if one was associated."]
    pub fn rte_thread_unregister();
}
pub type __m128i = [::std::os::raw::c_longlong; 2usize];
pub type rte_memory_order = ::std::os::raw::c_int;
#[doc = " The atomic counter structure."]
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct rte_atomic16_t {
    #[doc = "< An internal counter value."]
    pub cnt: i16,
}
#[doc = " The atomic counter structure."]
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct rte_atomic32_t {
    #[doc = "< An internal counter value."]
    pub cnt: i32,
}
#[doc = " The atomic counter structure."]
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct rte_atomic64_t {
    #[doc = "< Internal counter value."]
    pub cnt: i64,
}
#[doc = " 128-bit integer structure."]
#[repr(C)]
#[repr(align(16))]
#[derive(Copy, Clone)]
pub struct rte_int128_t {
    pub __bindgen_anon_1: rte_int128_t__bindgen_ty_1,
}
#[repr(C)]
#[repr(align(16))]
#[derive(Copy, Clone)]
pub union rte_int128_t__bindgen_ty_1 {
    pub val: [u64; 2usize],
    pub int128: i128,
}
#[doc = " The rte_spinlock_t type."]
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct rte_spinlock_t {
    #[doc = "< lock status 0 = unlocked, 1 = locked"]
    pub locked: ::std::os::raw::c_int,
}
#[doc = " The rte_spinlock_recursive_t type."]
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct rte_spinlock_recursive_t {
    #[doc = "< the actual spinlock"]
    pub sl: rte_spinlock_t,
    #[doc = "< core id using lock, -1 for unused"]
    pub user: ::std::os::raw::c_int,
    #[doc = "< count of time this lock has been called"]
    pub count: ::std::os::raw::c_int,
}
#[doc = "< SSE3"]
pub const rte_cpu_flag_t_RTE_CPUFLAG_SSE3: rte_cpu_flag_t = 0;
#[doc = "< PCLMULQDQ"]
pub const rte_cpu_flag_t_RTE_CPUFLAG_PCLMULQDQ: rte_cpu_flag_t = 1;
#[doc = "< DTES64"]
pub const rte_cpu_flag_t_RTE_CPUFLAG_DTES64: rte_cpu_flag_t = 2;
#[doc = "< MONITOR"]
pub const rte_cpu_flag_t_RTE_CPUFLAG_MONITOR: rte_cpu_flag_t = 3;
#[doc = "< DS_CPL"]
pub const rte_cpu_flag_t_RTE_CPUFLAG_DS_CPL: rte_cpu_flag_t = 4;
#[doc = "< VMX"]
pub const rte_cpu_flag_t_RTE_CPUFLAG_VMX: rte_cpu_flag_t = 5;
#[doc = "< SMX"]
pub const rte_cpu_flag_t_RTE_CPUFLAG_SMX: rte_cpu_flag_t = 6;
#[doc = "< EIST"]
pub const rte_cpu_flag_t_RTE_CPUFLAG_EIST: rte_cpu_flag_t = 7;
#[doc = "< TM2"]
pub const rte_cpu_flag_t_RTE_CPUFLAG_TM2: rte_cpu_flag_t = 8;
#[doc = "< SSSE3"]
pub const rte_cpu_flag_t_RTE_CPUFLAG_SSSE3: rte_cpu_flag_t = 9;
#[doc = "< CNXT_ID"]
pub const rte_cpu_flag_t_RTE_CPUFLAG_CNXT_ID: rte_cpu_flag_t = 10;
#[doc = "< FMA"]
pub const rte_cpu_flag_t_RTE_CPUFLAG_FMA: rte_cpu_flag_t = 11;
#[doc = "< CMPXCHG16B"]
pub const rte_cpu_flag_t_RTE_CPUFLAG_CMPXCHG16B: rte_cpu_flag_t = 12;
#[doc = "< XTPR"]
pub const rte_cpu_flag_t_RTE_CPUFLAG_XTPR: rte_cpu_flag_t = 13;
#[doc = "< PDCM"]
pub const rte_cpu_flag_t_RTE_CPUFLAG_PDCM: rte_cpu_flag_t = 14;
#[doc = "< PCID"]
pub const rte_cpu_flag_t_RTE_CPUFLAG_PCID: rte_cpu_flag_t = 15;
#[doc = "< DCA"]
pub const rte_cpu_flag_t_RTE_CPUFLAG_DCA: rte_cpu_flag_t = 16;
#[doc = "< SSE4_1"]
pub const rte_cpu_flag_t_RTE_CPUFLAG_SSE4_1: rte_cpu_flag_t = 17;
#[doc = "< SSE4_2"]
pub const rte_cpu_flag_t_RTE_CPUFLAG_SSE4_2: rte_cpu_flag_t = 18;
#[doc = "< X2APIC"]
pub const rte_cpu_flag_t_RTE_CPUFLAG_X2APIC: rte_cpu_flag_t = 19;
#[doc = "< MOVBE"]
pub const rte_cpu_flag_t_RTE_CPUFLAG_MOVBE: rte_cpu_flag_t = 20;
#[doc = "< POPCNT"]
pub const rte_cpu_flag_t_RTE_CPUFLAG_POPCNT: rte_cpu_flag_t = 21;
#[doc = "< TSC_DEADLINE"]
pub const rte_cpu_flag_t_RTE_CPUFLAG_TSC_DEADLINE: rte_cpu_flag_t = 22;
#[doc = "< AES"]
pub const rte_cpu_flag_t_RTE_CPUFLAG_AES: rte_cpu_flag_t = 23;
#[doc = "< XSAVE"]
pub const rte_cpu_flag_t_RTE_CPUFLAG_XSAVE: rte_cpu_flag_t = 24;
#[doc = "< OSXSAVE"]
pub const rte_cpu_flag_t_RTE_CPUFLAG_OSXSAVE: rte_cpu_flag_t = 25;
#[doc = "< AVX"]
pub const rte_cpu_flag_t_RTE_CPUFLAG_AVX: rte_cpu_flag_t = 26;
#[doc = "< F16C"]
pub const rte_cpu_flag_t_RTE_CPUFLAG_F16C: rte_cpu_flag_t = 27;
#[doc = "< RDRAND"]
pub const rte_cpu_flag_t_RTE_CPUFLAG_RDRAND: rte_cpu_flag_t = 28;
#[doc = "< Running in a VM"]
pub const rte_cpu_flag_t_RTE_CPUFLAG_HYPERVISOR: rte_cpu_flag_t = 29;
#[doc = "< FPU"]
pub const rte_cpu_flag_t_RTE_CPUFLAG_FPU: rte_cpu_flag_t = 30;
#[doc = "< VME"]
pub const rte_cpu_flag_t_RTE_CPUFLAG_VME: rte_cpu_flag_t = 31;
#[doc = "< DE"]
pub const rte_cpu_flag_t_RTE_CPUFLAG_DE: rte_cpu_flag_t = 32;
#[doc = "< PSE"]
pub const rte_cpu_flag_t_RTE_CPUFLAG_PSE: rte_cpu_flag_t = 33;
#[doc = "< TSC"]
pub const rte_cpu_flag_t_RTE_CPUFLAG_TSC: rte_cpu_flag_t = 34;
#[doc = "< MSR"]
pub const rte_cpu_flag_t_RTE_CPUFLAG_MSR: rte_cpu_flag_t = 35;
#[doc = "< PAE"]
pub const rte_cpu_flag_t_RTE_CPUFLAG_PAE: rte_cpu_flag_t = 36;
#[doc = "< MCE"]
pub const rte_cpu_flag_t_RTE_CPUFLAG_MCE: rte_cpu_flag_t = 37;
#[doc = "< CX8"]
pub const rte_cpu_flag_t_RTE_CPUFLAG_CX8: rte_cpu_flag_t = 38;
#[doc = "< APIC"]
pub const rte_cpu_flag_t_RTE_CPUFLAG_APIC: rte_cpu_flag_t = 39;
#[doc = "< SEP"]
pub const rte_cpu_flag_t_RTE_CPUFLAG_SEP: rte_cpu_flag_t = 40;
#[doc = "< MTRR"]
pub const rte_cpu_flag_t_RTE_CPUFLAG_MTRR: rte_cpu_flag_t = 41;
#[doc = "< PGE"]
pub const rte_cpu_flag_t_RTE_CPUFLAG_PGE: rte_cpu_flag_t = 42;
#[doc = "< MCA"]
pub const rte_cpu_flag_t_RTE_CPUFLAG_MCA: rte_cpu_flag_t = 43;
#[doc = "< CMOV"]
pub const rte_cpu_flag_t_RTE_CPUFLAG_CMOV: rte_cpu_flag_t = 44;
#[doc = "< PAT"]
pub const rte_cpu_flag_t_RTE_CPUFLAG_PAT: rte_cpu_flag_t = 45;
#[doc = "< PSE36"]
pub const rte_cpu_flag_t_RTE_CPUFLAG_PSE36: rte_cpu_flag_t = 46;
#[doc = "< PSN"]
pub const rte_cpu_flag_t_RTE_CPUFLAG_PSN: rte_cpu_flag_t = 47;
#[doc = "< CLFSH"]
pub const rte_cpu_flag_t_RTE_CPUFLAG_CLFSH: rte_cpu_flag_t = 48;
#[doc = "< DS"]
pub const rte_cpu_flag_t_RTE_CPUFLAG_DS: rte_cpu_flag_t = 49;
#[doc = "< ACPI"]
pub const rte_cpu_flag_t_RTE_CPUFLAG_ACPI: rte_cpu_flag_t = 50;
#[doc = "< MMX"]
pub const rte_cpu_flag_t_RTE_CPUFLAG_MMX: rte_cpu_flag_t = 51;
#[doc = "< FXSR"]
pub const rte_cpu_flag_t_RTE_CPUFLAG_FXSR: rte_cpu_flag_t = 52;
#[doc = "< SSE"]
pub const rte_cpu_flag_t_RTE_CPUFLAG_SSE: rte_cpu_flag_t = 53;
#[doc = "< SSE2"]
pub const rte_cpu_flag_t_RTE_CPUFLAG_SSE2: rte_cpu_flag_t = 54;
#[doc = "< SS"]
pub const rte_cpu_flag_t_RTE_CPUFLAG_SS: rte_cpu_flag_t = 55;
#[doc = "< HTT"]
pub const rte_cpu_flag_t_RTE_CPUFLAG_HTT: rte_cpu_flag_t = 56;
#[doc = "< TM"]
pub const rte_cpu_flag_t_RTE_CPUFLAG_TM: rte_cpu_flag_t = 57;
#[doc = "< PBE"]
pub const rte_cpu_flag_t_RTE_CPUFLAG_PBE: rte_cpu_flag_t = 58;
#[doc = "< DIGTEMP"]
pub const rte_cpu_flag_t_RTE_CPUFLAG_DIGTEMP: rte_cpu_flag_t = 59;
#[doc = "< TRBOBST"]
pub const rte_cpu_flag_t_RTE_CPUFLAG_TRBOBST: rte_cpu_flag_t = 60;
#[doc = "< ARAT"]
pub const rte_cpu_flag_t_RTE_CPUFLAG_ARAT: rte_cpu_flag_t = 61;
#[doc = "< PLN"]
pub const rte_cpu_flag_t_RTE_CPUFLAG_PLN: rte_cpu_flag_t = 62;
#[doc = "< ECMD"]
pub const rte_cpu_flag_t_RTE_CPUFLAG_ECMD: rte_cpu_flag_t = 63;
#[doc = "< PTM"]
pub const rte_cpu_flag_t_RTE_CPUFLAG_PTM: rte_cpu_flag_t = 64;
#[doc = "< MPERF_APERF_MSR"]
pub const rte_cpu_flag_t_RTE_CPUFLAG_MPERF_APERF_MSR: rte_cpu_flag_t = 65;
#[doc = "< ACNT2"]
pub const rte_cpu_flag_t_RTE_CPUFLAG_ACNT2: rte_cpu_flag_t = 66;
#[doc = "< ENERGY_EFF"]
pub const rte_cpu_flag_t_RTE_CPUFLAG_ENERGY_EFF: rte_cpu_flag_t = 67;
#[doc = "< FSGSBASE"]
pub const rte_cpu_flag_t_RTE_CPUFLAG_FSGSBASE: rte_cpu_flag_t = 68;
#[doc = "< BMI1"]
pub const rte_cpu_flag_t_RTE_CPUFLAG_BMI1: rte_cpu_flag_t = 69;
#[doc = "< Hardware Lock elision"]
pub const rte_cpu_flag_t_RTE_CPUFLAG_HLE: rte_cpu_flag_t = 70;
#[doc = "< AVX2"]
pub const rte_cpu_flag_t_RTE_CPUFLAG_AVX2: rte_cpu_flag_t = 71;
#[doc = "< SMEP"]
pub const rte_cpu_flag_t_RTE_CPUFLAG_SMEP: rte_cpu_flag_t = 72;
#[doc = "< BMI2"]
pub const rte_cpu_flag_t_RTE_CPUFLAG_BMI2: rte_cpu_flag_t = 73;
#[doc = "< ERMS"]
pub const rte_cpu_flag_t_RTE_CPUFLAG_ERMS: rte_cpu_flag_t = 74;
#[doc = "< INVPCID"]
pub const rte_cpu_flag_t_RTE_CPUFLAG_INVPCID: rte_cpu_flag_t = 75;
#[doc = "< Transactional memory"]
pub const rte_cpu_flag_t_RTE_CPUFLAG_RTM: rte_cpu_flag_t = 76;
#[doc = "< AVX512F"]
pub const rte_cpu_flag_t_RTE_CPUFLAG_AVX512F: rte_cpu_flag_t = 77;
#[doc = "< RDSEED instruction"]
pub const rte_cpu_flag_t_RTE_CPUFLAG_RDSEED: rte_cpu_flag_t = 78;
#[doc = "< LAHF_SAHF"]
pub const rte_cpu_flag_t_RTE_CPUFLAG_LAHF_SAHF: rte_cpu_flag_t = 79;
#[doc = "< LZCNT"]
pub const rte_cpu_flag_t_RTE_CPUFLAG_LZCNT: rte_cpu_flag_t = 80;
#[doc = "< SYSCALL"]
pub const rte_cpu_flag_t_RTE_CPUFLAG_SYSCALL: rte_cpu_flag_t = 81;
#[doc = "< XD"]
pub const rte_cpu_flag_t_RTE_CPUFLAG_XD: rte_cpu_flag_t = 82;
#[doc = "< 1GB_PG"]
pub const rte_cpu_flag_t_RTE_CPUFLAG_1GB_PG: rte_cpu_flag_t = 83;
#[doc = "< RDTSCP"]
pub const rte_cpu_flag_t_RTE_CPUFLAG_RDTSCP: rte_cpu_flag_t = 84;
#[doc = "< EM64T"]
pub const rte_cpu_flag_t_RTE_CPUFLAG_EM64T: rte_cpu_flag_t = 85;
#[doc = "< INVTSC"]
pub const rte_cpu_flag_t_RTE_CPUFLAG_INVTSC: rte_cpu_flag_t = 86;
#[doc = "< AVX512 Doubleword and Quadword"]
pub const rte_cpu_flag_t_RTE_CPUFLAG_AVX512DQ: rte_cpu_flag_t = 87;
#[doc = "< AVX512 Integer Fused Multiply-Add"]
pub const rte_cpu_flag_t_RTE_CPUFLAG_AVX512IFMA: rte_cpu_flag_t = 88;
#[doc = "< AVX512 Conflict Detection"]
pub const rte_cpu_flag_t_RTE_CPUFLAG_AVX512CD: rte_cpu_flag_t = 89;
#[doc = "< AVX512 Byte and Word"]
pub const rte_cpu_flag_t_RTE_CPUFLAG_AVX512BW: rte_cpu_flag_t = 90;
#[doc = "< AVX512 Vector Length"]
pub const rte_cpu_flag_t_RTE_CPUFLAG_AVX512VL: rte_cpu_flag_t = 91;
#[doc = "< AVX512 Vector Bit Manipulation"]
pub const rte_cpu_flag_t_RTE_CPUFLAG_AVX512VBMI: rte_cpu_flag_t = 92;
#[doc = "< AVX512 Vector Bit Manipulation 2"]
pub const rte_cpu_flag_t_RTE_CPUFLAG_AVX512VBMI2: rte_cpu_flag_t = 93;
#[doc = "< Galois Field New Instructions"]
pub const rte_cpu_flag_t_RTE_CPUFLAG_GFNI: rte_cpu_flag_t = 94;
#[doc = "< Vector AES"]
pub const rte_cpu_flag_t_RTE_CPUFLAG_VAES: rte_cpu_flag_t = 95;
#[doc = "< Vector Carry-less Multiply"]
pub const rte_cpu_flag_t_RTE_CPUFLAG_VPCLMULQDQ: rte_cpu_flag_t = 96;
pub const rte_cpu_flag_t_RTE_CPUFLAG_AVX512VNNI: rte_cpu_flag_t = 97;
#[doc = "< AVX512 Bit Algorithms"]
pub const rte_cpu_flag_t_RTE_CPUFLAG_AVX512BITALG: rte_cpu_flag_t = 98;
#[doc = "< AVX512 Vector Popcount"]
pub const rte_cpu_flag_t_RTE_CPUFLAG_AVX512VPOPCNTDQ: rte_cpu_flag_t = 99;
#[doc = "< Cache Line Demote"]
pub const rte_cpu_flag_t_RTE_CPUFLAG_CLDEMOTE: rte_cpu_flag_t = 100;
#[doc = "< Direct Store Instructions"]
pub const rte_cpu_flag_t_RTE_CPUFLAG_MOVDIRI: rte_cpu_flag_t = 101;
#[doc = "< Direct Store Instructions 64B"]
pub const rte_cpu_flag_t_RTE_CPUFLAG_MOVDIR64B: rte_cpu_flag_t = 102;
#[doc = "< AVX512 Two Register Intersection"]
pub const rte_cpu_flag_t_RTE_CPUFLAG_AVX512VP2INTERSECT: rte_cpu_flag_t = 103;
#[doc = "< UMONITOR/UMWAIT/TPAUSE"]
pub const rte_cpu_flag_t_RTE_CPUFLAG_WAITPKG: rte_cpu_flag_t = 104;
#[doc = "< MONITORX"]
pub const rte_cpu_flag_t_RTE_CPUFLAG_MONITORX: rte_cpu_flag_t = 105;
#[doc = " Enumeration of all CPU features supported"]
pub type rte_cpu_flag_t = ::std::os::raw::c_uint;
#[doc = " Structure used to describe platform-specific intrinsics that may or may not\n be supported at runtime."]
#[repr(C)]
#[repr(align(4))]
#[derive(Debug, Copy, Clone)]
pub struct rte_cpu_intrinsics {
    pub _bitfield_align_1: [u8; 0],
    pub _bitfield_1: __BindgenBitfieldUnit<[u8; 1usize]>,
    pub __bindgen_padding_0: [u8; 3usize],
}
impl rte_cpu_intrinsics {
    #[inline]
    pub fn power_monitor(&self) -> u32 {
        unsafe { ::std::mem::transmute(self._bitfield_1.get(0usize, 1u8) as u32) }
    }
    #[inline]
    pub fn set_power_monitor(&mut self, val: u32) {
        unsafe {
            let val: u32 = ::std::mem::transmute(val);
            self._bitfield_1.set(0usize, 1u8, val as u64)
        }
    }
    #[inline]
    pub fn power_pause(&self) -> u32 {
        unsafe { ::std::mem::transmute(self._bitfield_1.get(1usize, 1u8) as u32) }
    }
    #[inline]
    pub fn set_power_pause(&mut self, val: u32) {
        unsafe {
            let val: u32 = ::std::mem::transmute(val);
            self._bitfield_1.set(1usize, 1u8, val as u64)
        }
    }
    #[inline]
    pub fn power_monitor_multi(&self) -> u32 {
        unsafe { ::std::mem::transmute(self._bitfield_1.get(2usize, 1u8) as u32) }
    }
    #[inline]
    pub fn set_power_monitor_multi(&mut self, val: u32) {
        unsafe {
            let val: u32 = ::std::mem::transmute(val);
            self._bitfield_1.set(2usize, 1u8, val as u64)
        }
    }
    #[inline]
    pub fn new_bitfield_1(
        power_monitor: u32,
        power_pause: u32,
        power_monitor_multi: u32,
    ) -> __BindgenBitfieldUnit<[u8; 1usize]> {
        let mut __bindgen_bitfield_unit: __BindgenBitfieldUnit<[u8; 1usize]> = Default::default();
        __bindgen_bitfield_unit.set(0usize, 1u8, {
            let power_monitor: u32 = unsafe { ::std::mem::transmute(power_monitor) };
            power_monitor as u64
        });
        __bindgen_bitfield_unit.set(1usize, 1u8, {
            let power_pause: u32 = unsafe { ::std::mem::transmute(power_pause) };
            power_pause as u64
        });
        __bindgen_bitfield_unit.set(2usize, 1u8, {
            let power_monitor_multi: u32 = unsafe { ::std::mem::transmute(power_monitor_multi) };
            power_monitor_multi as u64
        });
        __bindgen_bitfield_unit
    }
}
extern "C" {
    #[doc = " Check CPU support for various intrinsics at runtime.\n\n @param intrinsics\n     Pointer to a structure to be filled."]
    pub fn rte_cpu_get_intrinsics_support(intrinsics: *mut rte_cpu_intrinsics);
}
extern "C" {
    #[doc = " Get name of CPU flag\n\n @param feature\n     CPU flag ID\n @return\n     flag name\n     NULL if flag ID is invalid"]
    pub fn rte_cpu_get_flag_name(feature: rte_cpu_flag_t) -> *const ::std::os::raw::c_char;
}
extern "C" {
    #[doc = " Function for checking a CPU flag availability\n\n @param feature\n     CPU flag to query CPU for\n @return\n     1 if flag is available\n     0 if flag is not available\n     -ENOENT if flag is invalid"]
    pub fn rte_cpu_get_flag_enabled(feature: rte_cpu_flag_t) -> ::std::os::raw::c_int;
}
extern "C" {
    #[doc = " This function checks that the currently used CPU supports the CPU features\n that were specified at compile time. It is called automatically within the\n EAL, so does not need to be used by applications.  This version returns a\n result so that decisions may be made (for instance, graceful shutdowns)."]
    pub fn rte_cpu_is_supported() -> ::std::os::raw::c_int;
}
extern "C" {
    #[doc = " This function attempts to retrieve a value from the auxiliary vector.\n If it is unsuccessful, the result will be 0, and errno will be set.\n\n @return A value from the auxiliary vector.  When the value is 0, check\n errno to determine if an error occurred."]
    pub fn rte_cpu_getauxval(type_: ::std::os::raw::c_ulong) -> ::std::os::raw::c_ulong;
}
extern "C" {
    #[doc = " This function retrieves a value from the auxiliary vector, and compares it\n as a string against the value retrieved.\n\n @return The result of calling strcmp() against the value retrieved from\n the auxiliary vector.  When the value is 0 (meaning a match is found),\n check errno to determine if an error occurred."]
    pub fn rte_cpu_strcmp_auxval(
        type_: ::std::os::raw::c_ulong,
        str_: *const ::std::os::raw::c_char,
    ) -> ::std::os::raw::c_int;
}
extern "C" {
    #[doc = " Dump the stack of the calling core to the standard error."]
    pub fn rte_dump_stack();
}
extern "C" {
    #[doc = " Get the measured frequency of the RDTSC counter\n\n @return\n   The TSC frequency for this lcore"]
    pub fn rte_get_tsc_hz() -> u64;
}
extern "C" {
    #[doc = " Wait at least us microseconds.\n This function can be replaced with user-defined function.\n @see rte_delay_us_callback_register\n\n @param us\n   The number of microseconds to wait."]
    pub static mut rte_delay_us:
        ::std::option::Option<unsafe extern "C" fn(us: ::std::os::raw::c_uint)>;
}
extern "C" {
    #[doc = " Blocking delay function.\n\n @param us\n   Number of microseconds to wait."]
    pub fn rte_delay_us_block(us: ::std::os::raw::c_uint);
}
extern "C" {
    #[doc = " Delay function that uses system sleep.\n Does not block the CPU core.\n\n @param us\n   Number of microseconds to wait."]
    pub fn rte_delay_us_sleep(us: ::std::os::raw::c_uint);
}
extern "C" {
    #[doc = " Replace rte_delay_us with user defined function.\n\n @param userfunc\n   User function which replaces rte_delay_us. rte_delay_us_block restores\n   builtin block delay function."]
    pub fn rte_delay_us_callback_register(
        userfunc: ::std::option::Option<unsafe extern "C" fn(arg1: ::std::os::raw::c_uint)>,
    );
}
extern "C" {
    pub static mut rte_rtm_supported: u8;
}
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct rte_rwlock_t {
    pub cnt: i32,
}
extern "C" {
    #[doc = " Internal helpers used for lock annotations."]
    pub fn rte_mcfg_mem_get_lock() -> *mut rte_rwlock_t;
}
extern "C" {
    pub fn rte_mcfg_tailq_get_lock() -> *mut rte_rwlock_t;
}
extern "C" {
    pub fn rte_mcfg_mempool_get_lock() -> *mut rte_rwlock_t;
}
extern "C" {
    pub fn rte_mcfg_timer_get_lock() -> *mut rte_spinlock_t;
}
extern "C" {
    pub fn rte_mcfg_ethdev_get_lock() -> *mut rte_spinlock_t;
}
extern "C" {
    #[doc = " Lock the internal EAL shared memory configuration for shared access."]
    pub fn rte_mcfg_mem_read_lock();
}
extern "C" {
    #[doc = " Unlock the internal EAL shared memory configuration for shared access."]
    pub fn rte_mcfg_mem_read_unlock();
}
extern "C" {
    #[doc = " Lock the internal EAL shared memory configuration for exclusive access."]
    pub fn rte_mcfg_mem_write_lock();
}
extern "C" {
    #[doc = " Unlock the internal EAL shared memory configuration for exclusive access."]
    pub fn rte_mcfg_mem_write_unlock();
}
extern "C" {
    #[doc = " Lock the internal EAL TAILQ list for shared access."]
    pub fn rte_mcfg_tailq_read_lock();
}
extern "C" {
    #[doc = " Unlock the internal EAL TAILQ list for shared access."]
    pub fn rte_mcfg_tailq_read_unlock();
}
extern "C" {
    #[doc = " Lock the internal EAL TAILQ list for exclusive access."]
    pub fn rte_mcfg_tailq_write_lock();
}
extern "C" {
    #[doc = " Unlock the internal EAL TAILQ list for exclusive access."]
    pub fn rte_mcfg_tailq_write_unlock();
}
extern "C" {
    #[doc = " Lock the internal EAL Mempool list for shared access."]
    pub fn rte_mcfg_mempool_read_lock();
}
extern "C" {
    #[doc = " Unlock the internal EAL Mempool list for shared access."]
    pub fn rte_mcfg_mempool_read_unlock();
}
extern "C" {
    #[doc = " Lock the internal EAL Mempool list for exclusive access."]
    pub fn rte_mcfg_mempool_write_lock();
}
extern "C" {
    #[doc = " Unlock the internal EAL Mempool list for exclusive access."]
    pub fn rte_mcfg_mempool_write_unlock();
}
extern "C" {
    #[doc = " Lock the internal EAL Timer Library lock for exclusive access."]
    pub fn rte_mcfg_timer_lock();
}
extern "C" {
    #[doc = " Unlock the internal EAL Timer Library lock for exclusive access."]
    pub fn rte_mcfg_timer_unlock();
}
extern "C" {
    #[doc = " If true, pages are put in single files (per memseg list),\n as opposed to creating a file per page."]
    pub fn rte_mcfg_get_single_file_segments() -> bool;
}
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct rte_fbarray {
    #[doc = "< name associated with an array"]
    pub name: [::std::os::raw::c_char; 64usize],
    #[doc = "< number of entries stored"]
    pub count: ::std::os::raw::c_uint,
    #[doc = "< current length of the array"]
    pub len: ::std::os::raw::c_uint,
    #[doc = "< size of each element"]
    pub elt_sz: ::std::os::raw::c_uint,
    #[doc = "< data pointer"]
    pub data: *mut ::std::os::raw::c_void,
    #[doc = "< multiprocess lock"]
    pub rwlock: rte_rwlock_t,
}
extern "C" {
    #[doc = " Set up ``rte_fbarray`` structure and allocate underlying resources.\n\n Call this function to correctly set up ``rte_fbarray`` and allocate\n underlying files that will be backing the data in the current process. Note\n that in order to use and share ``rte_fbarray`` between multiple processes,\n data pointed to by ``arr`` pointer must itself be allocated in shared memory.\n\n @param arr\n   Valid pointer to allocated ``rte_fbarray`` structure.\n\n @param name\n   Unique name to be assigned to this array.\n\n @param len\n   Number of elements initially available in the array.\n\n @param elt_sz\n   Size of each element.\n\n @return\n  - 0 on success.\n  - -1 on failure, with ``rte_errno`` indicating reason for failure."]
    pub fn rte_fbarray_init(
        arr: *mut rte_fbarray,
        name: *const ::std::os::raw::c_char,
        len: ::std::os::raw::c_uint,
        elt_sz: ::std::os::raw::c_uint,
    ) -> ::std::os::raw::c_int;
}
extern "C" {
    #[doc = " Attach to a file backing an already allocated and correctly set up\n ``rte_fbarray`` structure.\n\n Call this function to attach to file that will be backing the data in the\n current process. The structure must have been previously correctly set up\n with a call to ``rte_fbarray_init()``. Calls to ``rte_fbarray_attach()`` are\n usually meant to be performed in a multiprocessing scenario, with data\n pointed to by ``arr`` pointer allocated in shared memory.\n\n @param arr\n   Valid pointer to allocated and correctly set up rte_fbarray structure.\n\n @return\n  - 0 on success.\n  - -1 on failure, with ``rte_errno`` indicating reason for failure."]
    pub fn rte_fbarray_attach(arr: *mut rte_fbarray) -> ::std::os::raw::c_int;
}
extern "C" {
    #[doc = " Deallocate resources for an already allocated and correctly set up\n ``rte_fbarray`` structure, and remove the underlying file.\n\n Call this function to deallocate all resources associated with an\n ``rte_fbarray`` structure within the current process. This will also\n zero-fill data pointed to by ``arr`` pointer and remove the underlying file\n backing the data, so it is expected that by the time this function is called,\n all other processes have detached from this ``rte_fbarray``.\n\n @param arr\n   Valid pointer to allocated and correctly set up ``rte_fbarray`` structure.\n\n @return\n  - 0 on success.\n  - -1 on failure, with ``rte_errno`` indicating reason for failure."]
    pub fn rte_fbarray_destroy(arr: *mut rte_fbarray) -> ::std::os::raw::c_int;
}
extern "C" {
    #[doc = " Deallocate resources for an already allocated and correctly set up\n ``rte_fbarray`` structure.\n\n Call this function to deallocate all resources associated with an\n ``rte_fbarray`` structure within current process.\n\n @param arr\n   Valid pointer to allocated and correctly set up ``rte_fbarray`` structure.\n\n @return\n  - 0 on success.\n  - -1 on failure, with ``rte_errno`` indicating reason for failure."]
    pub fn rte_fbarray_detach(arr: *mut rte_fbarray) -> ::std::os::raw::c_int;
}
extern "C" {
    #[doc = " Get pointer to element residing at specified index.\n\n @param arr\n   Valid pointer to allocated and correctly set up ``rte_fbarray`` structure.\n\n @param idx\n   Index of an element to get a pointer to.\n\n @return\n  - non-NULL pointer on success.\n  - NULL on failure, with ``rte_errno`` indicating reason for failure."]
    pub fn rte_fbarray_get(
        arr: *const rte_fbarray,
        idx: ::std::os::raw::c_uint,
    ) -> *mut ::std::os::raw::c_void;
}
extern "C" {
    #[doc = " Find index of a specified element within the array.\n\n @param arr\n   Valid pointer to allocated and correctly set up ``rte_fbarray`` structure.\n\n @param elt\n   Pointer to element to find index to.\n\n @return\n  - non-negative integer on success.\n  - -1 on failure, with ``rte_errno`` indicating reason for failure."]
    pub fn rte_fbarray_find_idx(
        arr: *const rte_fbarray,
        elt: *const ::std::os::raw::c_void,
    ) -> ::std::os::raw::c_int;
}
extern "C" {
    #[doc = " Mark specified element as used.\n\n @param arr\n   Valid pointer to allocated and correctly set up ``rte_fbarray`` structure.\n\n @param idx\n   Element index to mark as used.\n\n @return\n  - 0 on success.\n  - -1 on failure, with ``rte_errno`` indicating reason for failure."]
    pub fn rte_fbarray_set_used(
        arr: *mut rte_fbarray,
        idx: ::std::os::raw::c_uint,
    ) -> ::std::os::raw::c_int;
}
extern "C" {
    #[doc = " Mark specified element as free.\n\n @param arr\n   Valid pointer to allocated and correctly set up ``rte_fbarray`` structure.\n\n @param idx\n   Element index to mark as free.\n\n @return\n  - 0 on success.\n  - -1 on failure, with ``rte_errno`` indicating reason for failure."]
    pub fn rte_fbarray_set_free(
        arr: *mut rte_fbarray,
        idx: ::std::os::raw::c_uint,
    ) -> ::std::os::raw::c_int;
}
extern "C" {
    #[doc = " Check whether element at specified index is marked as used.\n\n @param arr\n   Valid pointer to allocated and correctly set up ``rte_fbarray`` structure.\n\n @param idx\n   Element index to check as used.\n\n @return\n  - 1 if element is used.\n  - 0 if element is unused.\n  - -1 on failure, with ``rte_errno`` indicating reason for failure."]
    pub fn rte_fbarray_is_used(
        arr: *mut rte_fbarray,
        idx: ::std::os::raw::c_uint,
    ) -> ::std::os::raw::c_int;
}
extern "C" {
    #[doc = " Find index of next free element, starting at specified index.\n\n @param arr\n   Valid pointer to allocated and correctly set up ``rte_fbarray`` structure.\n\n @param start\n   Element index to start search from.\n\n @return\n  - non-negative integer on success.\n  - -1 on failure, with ``rte_errno`` indicating reason for failure."]
    pub fn rte_fbarray_find_next_free(
        arr: *mut rte_fbarray,
        start: ::std::os::raw::c_uint,
    ) -> ::std::os::raw::c_int;
}
extern "C" {
    #[doc = " Find index of next used element, starting at specified index.\n\n @param arr\n   Valid pointer to allocated and correctly set up ``rte_fbarray`` structure.\n\n @param start\n   Element index to start search from.\n\n @return\n  - non-negative integer on success.\n  - -1 on failure, with ``rte_errno`` indicating reason for failure."]
    pub fn rte_fbarray_find_next_used(
        arr: *mut rte_fbarray,
        start: ::std::os::raw::c_uint,
    ) -> ::std::os::raw::c_int;
}
extern "C" {
    #[doc = " Find index of next chunk of ``n`` free elements, starting at specified index.\n\n @param arr\n   Valid pointer to allocated and correctly set up ``rte_fbarray`` structure.\n\n @param start\n   Element index to start search from.\n\n @param n\n   Number of free elements to look for.\n\n @return\n  - non-negative integer on success.\n  - -1 on failure, with ``rte_errno`` indicating reason for failure."]
    pub fn rte_fbarray_find_next_n_free(
        arr: *mut rte_fbarray,
        start: ::std::os::raw::c_uint,
        n: ::std::os::raw::c_uint,
    ) -> ::std::os::raw::c_int;
}
extern "C" {
    #[doc = " Find index of next chunk of ``n`` used elements, starting at specified index.\n\n @param arr\n   Valid pointer to allocated and correctly set up ``rte_fbarray`` structure.\n\n @param start\n   Element index to start search from.\n\n @param n\n   Number of used elements to look for.\n\n @return\n  - non-negative integer on success.\n  - -1 on failure, with ``rte_errno`` indicating reason for failure."]
    pub fn rte_fbarray_find_next_n_used(
        arr: *mut rte_fbarray,
        start: ::std::os::raw::c_uint,
        n: ::std::os::raw::c_uint,
    ) -> ::std::os::raw::c_int;
}
extern "C" {
    #[doc = " Find how many more free entries there are, starting at specified index.\n\n @param arr\n   Valid pointer to allocated and correctly set up ``rte_fbarray`` structure.\n\n @param start\n   Element index to start search from.\n\n @return\n  - non-negative integer on success.\n  - -1 on failure, with ``rte_errno`` indicating reason for failure."]
    pub fn rte_fbarray_find_contig_free(
        arr: *mut rte_fbarray,
        start: ::std::os::raw::c_uint,
    ) -> ::std::os::raw::c_int;
}
extern "C" {
    #[doc = " Find how many more used entries there are, starting at specified index.\n\n @param arr\n   Valid pointer to allocated and correctly set up ``rte_fbarray`` structure.\n\n @param start\n   Element index to start search from.\n\n @return\n  - non-negative integer on success.\n  - -1 on failure, with ``rte_errno`` indicating reason for failure."]
    pub fn rte_fbarray_find_contig_used(
        arr: *mut rte_fbarray,
        start: ::std::os::raw::c_uint,
    ) -> ::std::os::raw::c_int;
}
extern "C" {
    #[doc = " Find index of previous free element, starting at specified index.\n\n @param arr\n   Valid pointer to allocated and correctly set up ``rte_fbarray`` structure.\n\n @param start\n   Element index to start search from.\n\n @return\n  - non-negative integer on success.\n  - -1 on failure, with ``rte_errno`` indicating reason for failure."]
    pub fn rte_fbarray_find_prev_free(
        arr: *mut rte_fbarray,
        start: ::std::os::raw::c_uint,
    ) -> ::std::os::raw::c_int;
}
extern "C" {
    #[doc = " Find index of previous used element, starting at specified index.\n\n @param arr\n   Valid pointer to allocated and correctly set up ``rte_fbarray`` structure.\n\n @param start\n   Element index to start search from.\n\n @return\n  - non-negative integer on success.\n  - -1 on failure, with ``rte_errno`` indicating reason for failure."]
    pub fn rte_fbarray_find_prev_used(
        arr: *mut rte_fbarray,
        start: ::std::os::raw::c_uint,
    ) -> ::std::os::raw::c_int;
}
extern "C" {
    #[doc = " Find lowest start index of chunk of ``n`` free elements, down from specified\n index.\n\n @param arr\n   Valid pointer to allocated and correctly set up ``rte_fbarray`` structure.\n\n @param start\n   Element index to start search from.\n\n @param n\n   Number of free elements to look for.\n\n @return\n  - non-negative integer on success.\n  - -1 on failure, with ``rte_errno`` indicating reason for failure."]
    pub fn rte_fbarray_find_prev_n_free(
        arr: *mut rte_fbarray,
        start: ::std::os::raw::c_uint,
        n: ::std::os::raw::c_uint,
    ) -> ::std::os::raw::c_int;
}
extern "C" {
    #[doc = " Find lowest start index of chunk of ``n`` used elements, down from specified\n index.\n\n @param arr\n   Valid pointer to allocated and correctly set up ``rte_fbarray`` structure.\n\n @param start\n   Element index to start search from.\n\n @param n\n   Number of used elements to look for.\n\n @return\n  - non-negative integer on success.\n  - -1 on failure, with ``rte_errno`` indicating reason for failure."]
    pub fn rte_fbarray_find_prev_n_used(
        arr: *mut rte_fbarray,
        start: ::std::os::raw::c_uint,
        n: ::std::os::raw::c_uint,
    ) -> ::std::os::raw::c_int;
}
extern "C" {
    #[doc = " Find how many more free entries there are before specified index (like\n ``rte_fbarray_find_contig_free`` but going in reverse).\n\n @param arr\n   Valid pointer to allocated and correctly set up ``rte_fbarray`` structure.\n\n @param start\n   Element index to start search from.\n\n @return\n  - non-negative integer on success.\n  - -1 on failure, with ``rte_errno`` indicating reason for failure."]
    pub fn rte_fbarray_find_rev_contig_free(
        arr: *mut rte_fbarray,
        start: ::std::os::raw::c_uint,
    ) -> ::std::os::raw::c_int;
}
extern "C" {
    #[doc = " Find how many more used entries there are before specified index (like\n ``rte_fbarray_find_contig_used`` but going in reverse).\n\n @param arr\n   Valid pointer to allocated and correctly set up ``rte_fbarray`` structure.\n\n @param start\n   Element index to start search from.\n\n @return\n  - non-negative integer on success.\n  - -1 on failure, with ``rte_errno`` indicating reason for failure."]
    pub fn rte_fbarray_find_rev_contig_used(
        arr: *mut rte_fbarray,
        start: ::std::os::raw::c_uint,
    ) -> ::std::os::raw::c_int;
}
extern "C" {
    #[doc = " Find index of biggest chunk of free elements, starting at specified index.\n\n @param arr\n   Valid pointer to allocated and correctly set up ``rte_fbarray`` structure.\n\n @param start\n   Element index to start search from.\n\n @return\n  - non-negative integer on success.\n  - -1 on failure, with ``rte_errno`` indicating reason for failure."]
    pub fn rte_fbarray_find_biggest_free(
        arr: *mut rte_fbarray,
        start: ::std::os::raw::c_uint,
    ) -> ::std::os::raw::c_int;
}
extern "C" {
    #[doc = " Find index of biggest chunk of used elements, starting at specified index.\n\n @param arr\n   Valid pointer to allocated and correctly set up ``rte_fbarray`` structure.\n\n @param start\n   Element index to start search from.\n\n @return\n  - non-negative integer on success.\n  - -1 on failure, with ``rte_errno`` indicating reason for failure."]
    pub fn rte_fbarray_find_biggest_used(
        arr: *mut rte_fbarray,
        start: ::std::os::raw::c_uint,
    ) -> ::std::os::raw::c_int;
}
extern "C" {
    #[doc = " Find index of biggest chunk of free elements before a specified index (like\n ``rte_fbarray_find_biggest_free``, but going in reverse).\n\n @param arr\n   Valid pointer to allocated and correctly set up ``rte_fbarray`` structure.\n\n @param start\n   Element index to start search from.\n\n @return\n  - non-negative integer on success.\n  - -1 on failure, with ``rte_errno`` indicating reason for failure."]
    pub fn rte_fbarray_find_rev_biggest_free(
        arr: *mut rte_fbarray,
        start: ::std::os::raw::c_uint,
    ) -> ::std::os::raw::c_int;
}
extern "C" {
    #[doc = " Find index of biggest chunk of used elements before a specified index (like\n ``rte_fbarray_find_biggest_used``, but going in reverse).\n\n @param arr\n   Valid pointer to allocated and correctly set up ``rte_fbarray`` structure.\n\n @param start\n   Element index to start search from.\n\n @return\n  - non-negative integer on success.\n  - -1 on failure, with ``rte_errno`` indicating reason for failure."]
    pub fn rte_fbarray_find_rev_biggest_used(
        arr: *mut rte_fbarray,
        start: ::std::os::raw::c_uint,
    ) -> ::std::os::raw::c_int;
}
extern "C" {
    #[doc = " Dump ``rte_fbarray`` metadata.\n\n @param arr\n   Valid pointer to allocated and correctly set up ``rte_fbarray`` structure.\n\n @param f\n   File object to dump information into."]
    pub fn rte_fbarray_dump_metadata(arr: *mut rte_fbarray, f: *mut FILE);
}
#[doc = " Physical memory segment descriptor."]
#[repr(C, packed)]
#[derive(Copy, Clone)]
pub struct rte_memseg {
    #[doc = "< Start IO address."]
    pub iova: rte_iova_t,
    pub __bindgen_anon_1: rte_memseg__bindgen_ty_1,
    #[doc = "< Length of the segment."]
    pub len: usize,
    #[doc = "< The pagesize of underlying memory"]
    pub hugepage_sz: u64,
    #[doc = "< NUMA socket ID."]
    pub socket_id: i32,
    #[doc = "< Number of channels."]
    pub nchannel: u32,
    #[doc = "< Number of ranks."]
    pub nrank: u32,
    #[doc = "< Memseg-specific flags"]
    pub flags: u32,
}
#[repr(C)]
#[derive(Copy, Clone)]
pub union rte_memseg__bindgen_ty_1 {
    #[doc = "< Start virtual address."]
    pub addr: *mut ::std::os::raw::c_void,
    #[doc = "< Makes sure addr is always 64 bits"]
    pub addr_64: u64,
}
#[doc = " memseg list is a special case as we need to store a bunch of other data\n together with the array itself."]
#[repr(C)]
#[derive(Copy, Clone)]
pub struct rte_memseg_list {
    pub __bindgen_anon_1: rte_memseg_list__bindgen_ty_1,
    #[doc = "< Page size for all memsegs in this list."]
    pub page_sz: u64,
    #[doc = "< Socket ID for all memsegs in this list."]
    pub socket_id: ::std::os::raw::c_int,
    #[doc = "< version number for multiprocess sync."]
    pub version: u32,
    #[doc = "< Length of memory area covered by this memseg list."]
    pub len: usize,
    #[doc = "< 1 if this list points to external memory"]
    pub external: ::std::os::raw::c_uint,
    #[doc = "< 1 if this list points to a heap"]
    pub heap: ::std::os::raw::c_uint,
    pub memseg_arr: rte_fbarray,
}
#[repr(C)]
#[derive(Copy, Clone)]
pub union rte_memseg_list__bindgen_ty_1 {
    pub base_va: *mut ::std::os::raw::c_void,
    pub addr_64: u64,
}
extern "C" {
    #[doc = " Lock page in physical memory and prevent from swapping.\n\n @param virt\n   The virtual address.\n @return\n   0 on success, negative on error."]
    pub fn rte_mem_lock_page(virt: *const ::std::os::raw::c_void) -> ::std::os::raw::c_int;
}
extern "C" {
    #[doc = " Get physical address of any mapped virtual address in the current process.\n It is found by browsing the /proc/self/pagemap special file.\n The page must be locked.\n\n @param virt\n   The virtual address.\n @return\n   The physical address or RTE_BAD_IOVA on error."]
    pub fn rte_mem_virt2phy(virt: *const ::std::os::raw::c_void) -> phys_addr_t;
}
extern "C" {
    #[doc = " Get IO virtual address of any mapped virtual address in the current process.\n\n @note This function will not check internal page table. Instead, in IOVA as\n       PA mode, it will fall back to getting real physical address (which may\n       not match the expected IOVA, such as what was specified for external\n       memory).\n\n @param virt\n   The virtual address.\n @return\n   The IO address or RTE_BAD_IOVA on error."]
    pub fn rte_mem_virt2iova(virt: *const ::std::os::raw::c_void) -> rte_iova_t;
}
extern "C" {
    #[doc = " Get virtual memory address corresponding to iova address.\n\n @note This function read-locks the memory hotplug subsystem, and thus cannot\n       be used within memory-related callback functions.\n\n @param iova\n   The iova address.\n @return\n   Virtual address corresponding to iova address (or NULL if address does not\n   exist within DPDK memory map)."]
    pub fn rte_mem_iova2virt(iova: rte_iova_t) -> *mut ::std::os::raw::c_void;
}
extern "C" {
    #[doc = " Get memseg to which a particular virtual address belongs.\n\n @param virt\n   The virtual address.\n @param msl\n   The memseg list in which to look up based on ``virt`` address\n   (can be NULL).\n @return\n   Memseg pointer on success, or NULL on error."]
    pub fn rte_mem_virt2memseg(
        virt: *const ::std::os::raw::c_void,
        msl: *const rte_memseg_list,
    ) -> *mut rte_memseg;
}
extern "C" {
    #[doc = " Get memseg list corresponding to virtual memory address.\n\n @param virt\n   The virtual address.\n @return\n   Memseg list to which this virtual address belongs to."]
    pub fn rte_mem_virt2memseg_list(virt: *const ::std::os::raw::c_void) -> *mut rte_memseg_list;
}
#[doc = " Memseg walk function prototype.\n\n Returning 0 will continue walk\n Returning 1 will stop the walk\n Returning -1 will stop the walk and report error"]
pub type rte_memseg_walk_t = ::std::option::Option<
    unsafe extern "C" fn(
        msl: *const rte_memseg_list,
        ms: *const rte_memseg,
        arg: *mut ::std::os::raw::c_void,
    ) -> ::std::os::raw::c_int,
>;
#[doc = " Memseg contig walk function prototype. This will trigger a callback on every\n VA-contiguous area starting at memseg ``ms``, so total valid VA space at each\n callback call will be [``ms->addr``, ``ms->addr + len``).\n\n Returning 0 will continue walk\n Returning 1 will stop the walk\n Returning -1 will stop the walk and report error"]
pub type rte_memseg_contig_walk_t = ::std::option::Option<
    unsafe extern "C" fn(
        msl: *const rte_memseg_list,
        ms: *const rte_memseg,
        len: usize,
        arg: *mut ::std::os::raw::c_void,
    ) -> ::std::os::raw::c_int,
>;
#[doc = " Memseg list walk function prototype. This will trigger a callback on every\n allocated memseg list.\n\n Returning 0 will continue walk\n Returning 1 will stop the walk\n Returning -1 will stop the walk and report error"]
pub type rte_memseg_list_walk_t = ::std::option::Option<
    unsafe extern "C" fn(
        msl: *const rte_memseg_list,
        arg: *mut ::std::os::raw::c_void,
    ) -> ::std::os::raw::c_int,
>;
extern "C" {
    #[doc = " Walk list of all memsegs.\n\n @note This function read-locks the memory hotplug subsystem, and thus cannot\n       be used within memory-related callback functions.\n\n @note This function will also walk through externally allocated segments. It\n       is up to the user to decide whether to skip through these segments.\n\n @param func\n   Iterator function\n @param arg\n   Argument passed to iterator\n @return\n   0 if walked over the entire list\n   1 if stopped by the user\n   -1 if user function reported error"]
    pub fn rte_memseg_walk(
        func: rte_memseg_walk_t,
        arg: *mut ::std::os::raw::c_void,
    ) -> ::std::os::raw::c_int;
}
extern "C" {
    #[doc = " Walk each VA-contiguous area.\n\n @note This function read-locks the memory hotplug subsystem, and thus cannot\n       be used within memory-related callback functions.\n\n @note This function will also walk through externally allocated segments. It\n       is up to the user to decide whether to skip through these segments.\n\n @param func\n   Iterator function\n @param arg\n   Argument passed to iterator\n @return\n   0 if walked over the entire list\n   1 if stopped by the user\n   -1 if user function reported error"]
    pub fn rte_memseg_contig_walk(
        func: rte_memseg_contig_walk_t,
        arg: *mut ::std::os::raw::c_void,
    ) -> ::std::os::raw::c_int;
}
extern "C" {
    #[doc = " Walk each allocated memseg list.\n\n @note This function read-locks the memory hotplug subsystem, and thus cannot\n       be used within memory-related callback functions.\n\n @note This function will also walk through externally allocated segments. It\n       is up to the user to decide whether to skip through these segments.\n\n @param func\n   Iterator function\n @param arg\n   Argument passed to iterator\n @return\n   0 if walked over the entire list\n   1 if stopped by the user\n   -1 if user function reported error"]
    pub fn rte_memseg_list_walk(
        func: rte_memseg_list_walk_t,
        arg: *mut ::std::os::raw::c_void,
    ) -> ::std::os::raw::c_int;
}
extern "C" {
    #[doc = " Walk list of all memsegs without performing any locking.\n\n @note This function does not perform any locking, and is only safe to call\n       from within memory-related callback functions.\n\n @param func\n   Iterator function\n @param arg\n   Argument passed to iterator\n @return\n   0 if walked over the entire list\n   1 if stopped by the user\n   -1 if user function reported error"]
    pub fn rte_memseg_walk_thread_unsafe(
        func: rte_memseg_walk_t,
        arg: *mut ::std::os::raw::c_void,
    ) -> ::std::os::raw::c_int;
}
extern "C" {
    #[doc = " Walk each VA-contiguous area without performing any locking.\n\n @note This function does not perform any locking, and is only safe to call\n       from within memory-related callback functions.\n\n @param func\n   Iterator function\n @param arg\n   Argument passed to iterator\n @return\n   0 if walked over the entire list\n   1 if stopped by the user\n   -1 if user function reported error"]
    pub fn rte_memseg_contig_walk_thread_unsafe(
        func: rte_memseg_contig_walk_t,
        arg: *mut ::std::os::raw::c_void,
    ) -> ::std::os::raw::c_int;
}
extern "C" {
    #[doc = " Walk each allocated memseg list without performing any locking.\n\n @note This function does not perform any locking, and is only safe to call\n       from within memory-related callback functions.\n\n @param func\n   Iterator function\n @param arg\n   Argument passed to iterator\n @return\n   0 if walked over the entire list\n   1 if stopped by the user\n   -1 if user function reported error"]
    pub fn rte_memseg_list_walk_thread_unsafe(
        func: rte_memseg_list_walk_t,
        arg: *mut ::std::os::raw::c_void,
    ) -> ::std::os::raw::c_int;
}
extern "C" {
    #[doc = " Return file descriptor associated with a particular memseg (if available).\n\n @note This function read-locks the memory hotplug subsystem, and thus cannot\n       be used within memory-related callback functions.\n\n @note This returns an internal file descriptor. Performing any operations on\n       this file descriptor is inherently dangerous, so it should be treated\n       as read-only for all intents and purposes.\n\n @param ms\n   A pointer to memseg for which to get file descriptor.\n\n @return\n   Valid file descriptor in case of success.\n   -1 in case of error, with ``rte_errno`` set to the following values:\n     - EINVAL  - ``ms`` pointer was NULL or did not point to a valid memseg\n     - ENODEV  - ``ms`` fd is not available\n     - ENOENT  - ``ms`` is an unused segment\n     - ENOTSUP - segment fd's are not supported"]
    pub fn rte_memseg_get_fd(ms: *const rte_memseg) -> ::std::os::raw::c_int;
}
extern "C" {
    #[doc = " Return file descriptor associated with a particular memseg (if available).\n\n @note This function does not perform any locking, and is only safe to call\n       from within memory-related callback functions.\n\n @note This returns an internal file descriptor. Performing any operations on\n       this file descriptor is inherently dangerous, so it should be treated\n       as read-only for all intents and purposes.\n\n @param ms\n   A pointer to memseg for which to get file descriptor.\n\n @return\n   Valid file descriptor in case of success.\n   -1 in case of error, with ``rte_errno`` set to the following values:\n     - EINVAL  - ``ms`` pointer was NULL or did not point to a valid memseg\n     - ENODEV  - ``ms`` fd is not available\n     - ENOENT  - ``ms`` is an unused segment\n     - ENOTSUP - segment fd's are not supported"]
    pub fn rte_memseg_get_fd_thread_unsafe(ms: *const rte_memseg) -> ::std::os::raw::c_int;
}
extern "C" {
    #[doc = " Get offset into segment file descriptor associated with a particular memseg\n (if available).\n\n @note This function read-locks the memory hotplug subsystem, and thus cannot\n       be used within memory-related callback functions.\n\n @param ms\n   A pointer to memseg for which to get file descriptor.\n @param offset\n   A pointer to offset value where the result will be stored.\n\n @return\n   Valid file descriptor in case of success.\n   -1 in case of error, with ``rte_errno`` set to the following values:\n     - EINVAL  - ``ms`` pointer was NULL or did not point to a valid memseg\n     - EINVAL  - ``offset`` pointer was NULL\n     - ENODEV  - ``ms`` fd is not available\n     - ENOENT  - ``ms`` is an unused segment\n     - ENOTSUP - segment fd's are not supported"]
    pub fn rte_memseg_get_fd_offset(
        ms: *const rte_memseg,
        offset: *mut usize,
    ) -> ::std::os::raw::c_int;
}
extern "C" {
    #[doc = " Get offset into segment file descriptor associated with a particular memseg\n (if available).\n\n @note This function does not perform any locking, and is only safe to call\n       from within memory-related callback functions.\n\n @param ms\n   A pointer to memseg for which to get file descriptor.\n @param offset\n   A pointer to offset value where the result will be stored.\n\n @return\n   Valid file descriptor in case of success.\n   -1 in case of error, with ``rte_errno`` set to the following values:\n     - EINVAL  - ``ms`` pointer was NULL or did not point to a valid memseg\n     - EINVAL  - ``offset`` pointer was NULL\n     - ENODEV  - ``ms`` fd is not available\n     - ENOENT  - ``ms`` is an unused segment\n     - ENOTSUP - segment fd's are not supported"]
    pub fn rte_memseg_get_fd_offset_thread_unsafe(
        ms: *const rte_memseg,
        offset: *mut usize,
    ) -> ::std::os::raw::c_int;
}
extern "C" {
    #[doc = " Register external memory chunk with DPDK.\n\n @note Using this API is mutually exclusive with ``rte_malloc`` family of\n   API's.\n\n @note This API will not perform any DMA mapping. It is expected that user\n   will do that themselves.\n\n @note Before accessing this memory in other processes, it needs to be\n   attached in each of those processes by calling ``rte_extmem_attach`` in\n   each other process.\n\n @param va_addr\n   Start of virtual area to register. Must be aligned by ``page_sz``.\n @param len\n   Length of virtual area to register. Must be aligned by ``page_sz``.\n @param iova_addrs\n   Array of page IOVA addresses corresponding to each page in this memory\n   area. Can be NULL, in which case page IOVA addresses will be set to\n   RTE_BAD_IOVA.\n @param n_pages\n   Number of elements in the iova_addrs array. Ignored if  ``iova_addrs``\n   is NULL.\n @param page_sz\n   Page size of the underlying memory\n\n @return\n   - 0 on success\n   - -1 in case of error, with rte_errno set to one of the following:\n     EINVAL - one of the parameters was invalid\n     EEXIST - memory chunk is already registered\n     ENOSPC - no more space in internal config to store a new memory chunk"]
    pub fn rte_extmem_register(
        va_addr: *mut ::std::os::raw::c_void,
        len: usize,
        iova_addrs: *mut rte_iova_t,
        n_pages: ::std::os::raw::c_uint,
        page_sz: usize,
    ) -> ::std::os::raw::c_int;
}
extern "C" {
    #[doc = " Unregister external memory chunk with DPDK.\n\n @note Using this API is mutually exclusive with ``rte_malloc`` family of\n   API's.\n\n @note This API will not perform any DMA unmapping. It is expected that user\n   will do that themselves.\n\n @note Before calling this function, all other processes must call\n   ``rte_extmem_detach`` to detach from the memory area.\n\n @param va_addr\n   Start of virtual area to unregister\n @param len\n   Length of virtual area to unregister\n\n @return\n   - 0 on success\n   - -1 in case of error, with rte_errno set to one of the following:\n     EINVAL - one of the parameters was invalid\n     ENOENT - memory chunk was not found"]
    pub fn rte_extmem_unregister(
        va_addr: *mut ::std::os::raw::c_void,
        len: usize,
    ) -> ::std::os::raw::c_int;
}
extern "C" {
    #[doc = " Attach to external memory chunk registered in another process.\n\n @note Using this API is mutually exclusive with ``rte_malloc`` family of\n   API's.\n\n @note This API will not perform any DMA mapping. It is expected that user\n   will do that themselves.\n\n @param va_addr\n   Start of virtual area to register\n @param len\n   Length of virtual area to register\n\n @return\n   - 0 on success\n   - -1 in case of error, with rte_errno set to one of the following:\n     EINVAL - one of the parameters was invalid\n     ENOENT - memory chunk was not found"]
    pub fn rte_extmem_attach(
        va_addr: *mut ::std::os::raw::c_void,
        len: usize,
    ) -> ::std::os::raw::c_int;
}
extern "C" {
    #[doc = " Detach from external memory chunk registered in another process.\n\n @note Using this API is mutually exclusive with ``rte_malloc`` family of\n   API's.\n\n @note This API will not perform any DMA unmapping. It is expected that user\n   will do that themselves.\n\n @param va_addr\n   Start of virtual area to unregister\n @param len\n   Length of virtual area to unregister\n\n @return\n   - 0 on success\n   - -1 in case of error, with rte_errno set to one of the following:\n     EINVAL - one of the parameters was invalid\n     ENOENT - memory chunk was not found"]
    pub fn rte_extmem_detach(
        va_addr: *mut ::std::os::raw::c_void,
        len: usize,
    ) -> ::std::os::raw::c_int;
}
extern "C" {
    #[doc = " Dump the physical memory layout to a file.\n\n @note This function read-locks the memory hotplug subsystem, and thus cannot\n       be used within memory-related callback functions.\n\n @param f\n   A pointer to a file for output"]
    pub fn rte_dump_physmem_layout(f: *mut FILE);
}
extern "C" {
    #[doc = " Get the total amount of available physical memory.\n\n @note This function read-locks the memory hotplug subsystem, and thus cannot\n       be used within memory-related callback functions.\n\n @return\n    The total amount of available physical memory in bytes."]
    pub fn rte_eal_get_physmem_size() -> u64;
}
extern "C" {
    #[doc = " Get the number of memory channels.\n\n @return\n   The number of memory channels on the system. The value is 0 if unknown\n   or not the same on all devices."]
    pub fn rte_memory_get_nchannel() -> ::std::os::raw::c_uint;
}
extern "C" {
    #[doc = " Get the number of memory ranks.\n\n @return\n   The number of memory ranks on the system. The value is 0 if unknown or\n   not the same on all devices."]
    pub fn rte_memory_get_nrank() -> ::std::os::raw::c_uint;
}
extern "C" {
    #[doc = " Check if all currently allocated memory segments are compliant with\n supplied DMA address width.\n\n  @param maskbits\n    Address width to check against."]
    pub fn rte_mem_check_dma_mask(maskbits: u8) -> ::std::os::raw::c_int;
}
extern "C" {
    #[doc = " Check if all currently allocated memory segments are compliant with\n supplied DMA address width. This function will use\n rte_memseg_walk_thread_unsafe instead of rte_memseg_walk implying\n memory_hotplug_lock will not be acquired avoiding deadlock during\n memory initialization.\n\n This function is just for EAL core memory internal use. Drivers should\n use the previous rte_mem_check_dma_mask.\n\n  @param maskbits\n    Address width to check against."]
    pub fn rte_mem_check_dma_mask_thread_unsafe(maskbits: u8) -> ::std::os::raw::c_int;
}
extern "C" {
    #[doc = "  Set dma mask to use once memory initialization is done. Previous functions\n  rte_mem_check_dma_mask and rte_mem_check_dma_mask_thread_unsafe can not be\n  used safely until memory has been initialized."]
    pub fn rte_mem_set_dma_mask(maskbits: u8);
}
extern "C" {
    #[doc = " Drivers based on uio will not load unless physical\n addresses are obtainable. It is only possible to get\n physical addresses when running as a privileged user.\n\n @return\n   1 if the system is able to obtain physical addresses.\n   0 if using DMA addresses through an IOMMU."]
    pub fn rte_eal_using_phys_addrs() -> ::std::os::raw::c_int;
}
#[doc = "< Allocation event."]
pub const rte_mem_event_RTE_MEM_EVENT_ALLOC: rte_mem_event = 0;
#[doc = "< Deallocation event."]
pub const rte_mem_event_RTE_MEM_EVENT_FREE: rte_mem_event = 1;
#[doc = " Enum indicating which kind of memory event has happened. Used by callbacks to\n distinguish between memory allocations and deallocations."]
pub type rte_mem_event = ::std::os::raw::c_uint;
#[doc = " Function typedef used to register callbacks for memory events."]
pub type rte_mem_event_callback_t = ::std::option::Option<
    unsafe extern "C" fn(
        event_type: rte_mem_event,
        addr: *const ::std::os::raw::c_void,
        len: usize,
        arg: *mut ::std::os::raw::c_void,
    ),
>;
extern "C" {
    #[doc = " Function used to register callbacks for memory events.\n\n @note callbacks will happen while memory hotplug subsystem is write-locked,\n       therefore some functions (e.g. `rte_memseg_walk()`) will cause a\n       deadlock when called from within such callbacks.\n\n @note mem event callbacks not being supported is an expected error condition,\n       so user code needs to handle this situation. In these cases, return\n       value will be -1, and rte_errno will be set to ENOTSUP.\n\n @param name\n   Name associated with specified callback to be added to the list.\n\n @param clb\n   Callback function pointer.\n\n @param arg\n   Argument to pass to the callback.\n\n @return\n   0 on successful callback register\n   -1 on unsuccessful callback register, with rte_errno value indicating\n   reason for failure."]
    pub fn rte_mem_event_callback_register(
        name: *const ::std::os::raw::c_char,
        clb: rte_mem_event_callback_t,
        arg: *mut ::std::os::raw::c_void,
    ) -> ::std::os::raw::c_int;
}
extern "C" {
    #[doc = " Function used to unregister callbacks for memory events.\n\n @param name\n   Name associated with specified callback to be removed from the list.\n\n @param arg\n   Argument to look for among callbacks with specified callback name.\n\n @return\n   0 on successful callback unregister\n   -1 on unsuccessful callback unregister, with rte_errno value indicating\n   reason for failure."]
    pub fn rte_mem_event_callback_unregister(
        name: *const ::std::os::raw::c_char,
        arg: *mut ::std::os::raw::c_void,
    ) -> ::std::os::raw::c_int;
}
#[doc = " Function typedef used to register memory allocation validation callbacks.\n\n Returning 0 will allow allocation attempt to continue. Returning -1 will\n prevent allocation from succeeding."]
pub type rte_mem_alloc_validator_t = ::std::option::Option<
    unsafe extern "C" fn(
        socket_id: ::std::os::raw::c_int,
        cur_limit: usize,
        new_len: usize,
    ) -> ::std::os::raw::c_int,
>;
extern "C" {
    #[doc = " @brief Register validator callback for memory allocations.\n\n Callbacks registered by this function will be called right before memory\n allocator is about to trigger allocation of more pages from the system if\n said allocation will bring total memory usage above specified limit on\n specified socket. User will be able to cancel pending allocation if callback\n returns -1.\n\n @note callbacks will happen while memory hotplug subsystem is write-locked,\n       therefore some functions (e.g. `rte_memseg_walk()`) will cause a\n       deadlock when called from within such callbacks.\n\n @note validator callbacks not being supported is an expected error condition,\n       so user code needs to handle this situation. In these cases, return\n       value will be -1, and rte_errno will be set to ENOTSUP.\n\n @param name\n   Name associated with specified callback to be added to the list.\n\n @param clb\n   Callback function pointer.\n\n @param socket_id\n   Socket ID on which to watch for allocations.\n\n @param limit\n   Limit above which to trigger callbacks.\n\n @return\n   0 on successful callback register\n   -1 on unsuccessful callback register, with rte_errno value indicating\n   reason for failure."]
    pub fn rte_mem_alloc_validator_register(
        name: *const ::std::os::raw::c_char,
        clb: rte_mem_alloc_validator_t,
        socket_id: ::std::os::raw::c_int,
        limit: usize,
    ) -> ::std::os::raw::c_int;
}
extern "C" {
    #[doc = " @brief Unregister validator callback for memory allocations.\n\n @param name\n   Name associated with specified callback to be removed from the list.\n\n @param socket_id\n   Socket ID on which to watch for allocations.\n\n @return\n   0 on successful callback unregister\n   -1 on unsuccessful callback unregister, with rte_errno value indicating\n   reason for failure."]
    pub fn rte_mem_alloc_validator_unregister(
        name: *const ::std::os::raw::c_char,
        socket_id: ::std::os::raw::c_int,
    ) -> ::std::os::raw::c_int;
}
#[doc = " A structure describing a memzone, which is a contiguous portion of\n physical memory identified by a name."]
#[repr(C, packed)]
#[derive(Copy, Clone)]
pub struct rte_memzone {
    #[doc = "< Name of the memory zone."]
    pub name: [::std::os::raw::c_char; 32usize],
    #[doc = "< Start IO address."]
    pub iova: rte_iova_t,
    pub __bindgen_anon_1: rte_memzone__bindgen_ty_1,
    #[doc = "< Length of the memzone."]
    pub len: usize,
    #[doc = "< The page size of underlying memory"]
    pub hugepage_sz: u64,
    #[doc = "< NUMA socket ID."]
    pub socket_id: i32,
    #[doc = "< Characteristics of this memzone."]
    pub flags: u32,
}
#[repr(C)]
#[derive(Copy, Clone)]
pub union rte_memzone__bindgen_ty_1 {
    #[doc = "< Start virtual address."]
    pub addr: *mut ::std::os::raw::c_void,
    #[doc = "< Makes sure addr is always 64-bits"]
    pub addr_64: u64,
}
extern "C" {
    #[doc = " Set the maximum number of memzones.\n\n This function can only be called prior to rte_eal_init().\n\n @param max\n   Maximum number of memzones.\n @return\n  0 on success, -1 otherwise."]
    pub fn rte_memzone_max_set(max: usize) -> ::std::os::raw::c_int;
}
extern "C" {
    #[doc = " Get the maximum number of memzones.\n\n @note: The maximum value will not change after calling rte_eal_init().\n\n @return\n   Maximum number of memzones."]
    pub fn rte_memzone_max_get() -> usize;
}
extern "C" {
    #[doc = " Reserve a portion of physical memory.\n\n This function reserves some memory and returns a pointer to a\n correctly filled memzone descriptor. If the allocation cannot be\n done, return NULL.\n\n @note Reserving memzones with len set to 0 will only attempt to allocate\n   memzones from memory that is already available. It will not trigger any\n   new allocations.\n\n @note: When reserving memzones with len set to 0, it is preferable to also\n   set a valid socket_id. Setting socket_id to SOCKET_ID_ANY is supported, but\n   will likely not yield expected results. Specifically, the resulting memzone\n   may not necessarily be the biggest memzone available, but rather biggest\n   memzone available on socket id corresponding to an lcore from which\n   reservation was called.\n\n @param name\n   The name of the memzone. If it already exists, the function will\n   fail and return NULL.\n @param len\n   The size of the memory to be reserved. If it\n   is 0, the biggest contiguous zone will be reserved.\n @param socket_id\n   The socket identifier in the case of\n   NUMA. The value can be SOCKET_ID_ANY if there is no NUMA\n   constraint for the reserved zone.\n @param flags\n   The flags parameter is used to request memzones to be\n   taken from specifically sized hugepages.\n   - RTE_MEMZONE_2MB - Reserved from 2MB pages\n   - RTE_MEMZONE_1GB - Reserved from 1GB pages\n   - RTE_MEMZONE_16MB - Reserved from 16MB pages\n   - RTE_MEMZONE_16GB - Reserved from 16GB pages\n   - RTE_MEMZONE_256KB - Reserved from 256KB pages\n   - RTE_MEMZONE_256MB - Reserved from 256MB pages\n   - RTE_MEMZONE_512MB - Reserved from 512MB pages\n   - RTE_MEMZONE_4GB - Reserved from 4GB pages\n   - RTE_MEMZONE_SIZE_HINT_ONLY - Allow alternative page size to be used if\n                                  the requested page size is unavailable.\n                                  If this flag is not set, the function\n                                  will return error on an unavailable size\n                                  request.\n   - RTE_MEMZONE_IOVA_CONTIG - Ensure reserved memzone is IOVA-contiguous.\n                               This option should be used when allocating\n                               memory intended for hardware rings etc.\n @return\n   A pointer to a correctly-filled read-only memzone descriptor, or NULL\n   on error.\n   On error case, rte_errno will be set appropriately:\n    - E_RTE_NO_CONFIG - function could not get pointer to rte_config structure\n    - ENOSPC - the maximum number of memzones has already been allocated\n    - EEXIST - a memzone with the same name already exists\n    - ENOMEM - no appropriate memory area found in which to create memzone\n    - EINVAL - invalid parameters"]
    pub fn rte_memzone_reserve(
        name: *const ::std::os::raw::c_char,
        len: usize,
        socket_id: ::std::os::raw::c_int,
        flags: ::std::os::raw::c_uint,
    ) -> *const rte_memzone;
}
extern "C" {
    #[doc = " Reserve a portion of physical memory with alignment on a specified\n boundary.\n\n This function reserves some memory with alignment on a specified\n boundary, and returns a pointer to a correctly filled memzone\n descriptor. If the allocation cannot be done or if the alignment\n is not a power of 2, returns NULL.\n\n @note Reserving memzones with len set to 0 will only attempt to allocate\n   memzones from memory that is already available. It will not trigger any\n   new allocations.\n\n @note: When reserving memzones with len set to 0, it is preferable to also\n   set a valid socket_id. Setting socket_id to SOCKET_ID_ANY is supported, but\n   will likely not yield expected results. Specifically, the resulting memzone\n   may not necessarily be the biggest memzone available, but rather biggest\n   memzone available on socket id corresponding to an lcore from which\n   reservation was called.\n\n @param name\n   The name of the memzone. If it already exists, the function will\n   fail and return NULL.\n @param len\n   The size of the memory to be reserved. If it\n   is 0, the biggest contiguous zone will be reserved.\n @param socket_id\n   The socket identifier in the case of\n   NUMA. The value can be SOCKET_ID_ANY if there is no NUMA\n   constraint for the reserved zone.\n @param flags\n   The flags parameter is used to request memzones to be\n   taken from specifically sized hugepages.\n   - RTE_MEMZONE_2MB - Reserved from 2MB pages\n   - RTE_MEMZONE_1GB - Reserved from 1GB pages\n   - RTE_MEMZONE_16MB - Reserved from 16MB pages\n   - RTE_MEMZONE_16GB - Reserved from 16GB pages\n   - RTE_MEMZONE_256KB - Reserved from 256KB pages\n   - RTE_MEMZONE_256MB - Reserved from 256MB pages\n   - RTE_MEMZONE_512MB - Reserved from 512MB pages\n   - RTE_MEMZONE_4GB - Reserved from 4GB pages\n   - RTE_MEMZONE_SIZE_HINT_ONLY - Allow alternative page size to be used if\n                                  the requested page size is unavailable.\n                                  If this flag is not set, the function\n                                  will return error on an unavailable size\n                                  request.\n   - RTE_MEMZONE_IOVA_CONTIG - Ensure reserved memzone is IOVA-contiguous.\n                               This option should be used when allocating\n                               memory intended for hardware rings etc.\n @param align\n   Alignment for resulting memzone. Must be a power of 2.\n @return\n   A pointer to a correctly-filled read-only memzone descriptor, or NULL\n   on error.\n   On error case, rte_errno will be set appropriately:\n    - E_RTE_NO_CONFIG - function could not get pointer to rte_config structure\n    - ENOSPC - the maximum number of memzones has already been allocated\n    - EEXIST - a memzone with the same name already exists\n    - ENOMEM - no appropriate memory area found in which to create memzone\n    - EINVAL - invalid parameters"]
    pub fn rte_memzone_reserve_aligned(
        name: *const ::std::os::raw::c_char,
        len: usize,
        socket_id: ::std::os::raw::c_int,
        flags: ::std::os::raw::c_uint,
        align: ::std::os::raw::c_uint,
    ) -> *const rte_memzone;
}
extern "C" {
    #[doc = " Reserve a portion of physical memory with specified alignment and\n boundary.\n\n This function reserves some memory with specified alignment and\n boundary, and returns a pointer to a correctly filled memzone\n descriptor. If the allocation cannot be done or if the alignment\n or boundary are not a power of 2, returns NULL.\n Memory buffer is reserved in a way, that it wouldn't cross specified\n boundary. That implies that requested length should be less or equal\n then boundary.\n\n @note Reserving memzones with len set to 0 will only attempt to allocate\n   memzones from memory that is already available. It will not trigger any\n   new allocations.\n\n @note: When reserving memzones with len set to 0, it is preferable to also\n   set a valid socket_id. Setting socket_id to SOCKET_ID_ANY is supported, but\n   will likely not yield expected results. Specifically, the resulting memzone\n   may not necessarily be the biggest memzone available, but rather biggest\n   memzone available on socket id corresponding to an lcore from which\n   reservation was called.\n\n @param name\n   The name of the memzone. If it already exists, the function will\n   fail and return NULL.\n @param len\n   The size of the memory to be reserved. If it\n   is 0, the biggest contiguous zone will be reserved.\n @param socket_id\n   The socket identifier in the case of\n   NUMA. The value can be SOCKET_ID_ANY if there is no NUMA\n   constraint for the reserved zone.\n @param flags\n   The flags parameter is used to request memzones to be\n   taken from specifically sized hugepages.\n   - RTE_MEMZONE_2MB - Reserved from 2MB pages\n   - RTE_MEMZONE_1GB - Reserved from 1GB pages\n   - RTE_MEMZONE_16MB - Reserved from 16MB pages\n   - RTE_MEMZONE_16GB - Reserved from 16GB pages\n   - RTE_MEMZONE_256KB - Reserved from 256KB pages\n   - RTE_MEMZONE_256MB - Reserved from 256MB pages\n   - RTE_MEMZONE_512MB - Reserved from 512MB pages\n   - RTE_MEMZONE_4GB - Reserved from 4GB pages\n   - RTE_MEMZONE_SIZE_HINT_ONLY - Allow alternative page size to be used if\n                                  the requested page size is unavailable.\n                                  If this flag is not set, the function\n                                  will return error on an unavailable size\n                                  request.\n   - RTE_MEMZONE_IOVA_CONTIG - Ensure reserved memzone is IOVA-contiguous.\n                               This option should be used when allocating\n                               memory intended for hardware rings etc.\n @param align\n   Alignment for resulting memzone. Must be a power of 2.\n @param bound\n   Boundary for resulting memzone. Must be a power of 2 or zero.\n   Zero value implies no boundary condition.\n @return\n   A pointer to a correctly-filled read-only memzone descriptor, or NULL\n   on error.\n   On error case, rte_errno will be set appropriately:\n    - E_RTE_NO_CONFIG - function could not get pointer to rte_config structure\n    - ENOSPC - the maximum number of memzones has already been allocated\n    - EEXIST - a memzone with the same name already exists\n    - ENOMEM - no appropriate memory area found in which to create memzone\n    - EINVAL - invalid parameters"]
    pub fn rte_memzone_reserve_bounded(
        name: *const ::std::os::raw::c_char,
        len: usize,
        socket_id: ::std::os::raw::c_int,
        flags: ::std::os::raw::c_uint,
        align: ::std::os::raw::c_uint,
        bound: ::std::os::raw::c_uint,
    ) -> *const rte_memzone;
}
extern "C" {
    #[doc = " Free a memzone.\n\n @param mz\n   A pointer to the memzone\n @return\n  -EINVAL - invalid parameter.\n  0 - success"]
    pub fn rte_memzone_free(mz: *const rte_memzone) -> ::std::os::raw::c_int;
}
extern "C" {
    #[doc = " Lookup for a memzone.\n\n Get a pointer to a descriptor of an already reserved memory\n zone identified by the name given as an argument.\n\n @param name\n   The name of the memzone.\n @return\n   A pointer to a read-only memzone descriptor."]
    pub fn rte_memzone_lookup(name: *const ::std::os::raw::c_char) -> *const rte_memzone;
}
extern "C" {
    #[doc = " Dump all reserved memzones to a file.\n\n @param f\n   A pointer to a file for output"]
    pub fn rte_memzone_dump(f: *mut FILE);
}
extern "C" {
    #[doc = " Walk list of all memzones\n\n @param func\n   Iterator function\n @param arg\n   Argument passed to iterator"]
    pub fn rte_memzone_walk(
        func: ::std::option::Option<
            unsafe extern "C" fn(arg1: *const rte_memzone, arg: *mut ::std::os::raw::c_void),
        >,
        arg: *mut ::std::os::raw::c_void,
    );
}
#[doc = " Enq/Deq a fixed number of items from a ring"]
pub const rte_ring_queue_behavior_RTE_RING_QUEUE_FIXED: rte_ring_queue_behavior = 0;
#[doc = " Enq/Deq as many items as possible from ring"]
pub const rte_ring_queue_behavior_RTE_RING_QUEUE_VARIABLE: rte_ring_queue_behavior = 1;
#[doc = " enqueue/dequeue behavior types"]
pub type rte_ring_queue_behavior = ::std::os::raw::c_uint;
#[doc = "< multi-thread safe (default mode)"]
pub const rte_ring_sync_type_RTE_RING_SYNC_MT: rte_ring_sync_type = 0;
#[doc = "< single thread only"]
pub const rte_ring_sync_type_RTE_RING_SYNC_ST: rte_ring_sync_type = 1;
#[doc = "< multi-thread relaxed tail sync"]
pub const rte_ring_sync_type_RTE_RING_SYNC_MT_RTS: rte_ring_sync_type = 2;
#[doc = "< multi-thread head/tail sync"]
pub const rte_ring_sync_type_RTE_RING_SYNC_MT_HTS: rte_ring_sync_type = 3;
#[doc = " prod/cons sync types"]
pub type rte_ring_sync_type = ::std::os::raw::c_uint;
#[doc = " structures to hold a pair of head/tail values and other metadata.\n Depending on sync_type format of that structure might be different,\n but offset for *sync_type* and *tail* values should remain the same."]
#[repr(C)]
#[derive(Copy, Clone)]
pub struct rte_ring_headtail {
    #[doc = "< prod/consumer head."]
    pub head: u32,
    #[doc = "< prod/consumer tail."]
    pub tail: u32,
    pub __bindgen_anon_1: rte_ring_headtail__bindgen_ty_1,
}
#[repr(C)]
#[derive(Copy, Clone)]
pub union rte_ring_headtail__bindgen_ty_1 {
    #[doc = " sync type of prod/cons"]
    pub sync_type: rte_ring_sync_type,
    #[doc = " deprecated -  True if single prod/cons"]
    pub single: u32,
}
#[repr(C)]
#[derive(Copy, Clone)]
pub union __rte_ring_rts_poscnt {
    #[doc = " raw 8B value to read/write *cnt* and *pos* as one atomic op"]
    pub raw: u64,
    pub val: __rte_ring_rts_poscnt__bindgen_ty_1,
}
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct __rte_ring_rts_poscnt__bindgen_ty_1 {
    #[doc = "< head/tail reference counter"]
    pub cnt: u32,
    #[doc = "< head/tail position"]
    pub pos: u32,
}
#[repr(C)]
#[derive(Copy, Clone)]
pub struct rte_ring_rts_headtail {
    pub tail: __rte_ring_rts_poscnt,
    #[doc = "< sync type of prod/cons"]
    pub sync_type: rte_ring_sync_type,
    #[doc = "< max allowed distance between head/tail"]
    pub htd_max: u32,
    pub head: __rte_ring_rts_poscnt,
}
#[repr(C)]
#[derive(Copy, Clone)]
pub union __rte_ring_hts_pos {
    #[doc = " raw 8B value to read/write *head* and *tail* as one atomic op"]
    pub raw: u64,
    pub pos: __rte_ring_hts_pos__bindgen_ty_1,
}
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct __rte_ring_hts_pos__bindgen_ty_1 {
    #[doc = "< head position"]
    pub head: u32,
    #[doc = "< tail position"]
    pub tail: u32,
}
#[repr(C)]
#[derive(Copy, Clone)]
pub struct rte_ring_hts_headtail {
    pub ht: __rte_ring_hts_pos,
    #[doc = "< sync type of prod/cons"]
    pub sync_type: rte_ring_sync_type,
}
#[doc = " An RTE ring structure.\n\n The producer and the consumer have a head and a tail index. The particularity\n of these index is that they are not between 0 and size(ring)-1. These indexes\n are between 0 and 2^32 -1, and we mask their value when we access the ring[]\n field. Thanks to this assumption, we can do subtractions between 2 index\n values in a modulo-32bit base: that's why the overflow of the indexes is not\n a problem."]
#[repr(C)]
#[repr(align(64))]
#[derive(Copy, Clone)]
pub struct rte_ring {
    pub name: [::std::os::raw::c_char; 29usize],
    #[doc = "< Flags supplied at creation."]
    pub flags: ::std::os::raw::c_int,
    pub memzone: *const rte_memzone,
    #[doc = "< Size of ring."]
    pub size: u32,
    #[doc = "< Mask (size-1) of ring."]
    pub mask: u32,
    #[doc = "< Usable size of ring"]
    pub capacity: u32,
    pub __bindgen_padding_0: [u8; 4usize],
    pub cache_guard_0: [::std::os::raw::c_char; 64usize],
    pub __bindgen_anon_1: rte_ring__bindgen_ty_1,
    pub cache_guard_1: [::std::os::raw::c_char; 64usize],
    pub __bindgen_anon_2: rte_ring__bindgen_ty_2,
    pub cache_guard_2: [::std::os::raw::c_char; 64usize],
}
#[doc = " Ring producer status."]
#[repr(C)]
#[repr(align(64))]
#[derive(Copy, Clone)]
pub union rte_ring__bindgen_ty_1 {
    pub prod: rte_ring_headtail,
    pub hts_prod: rte_ring_hts_headtail,
    pub rts_prod: rte_ring_rts_headtail,
}
#[doc = " Ring consumer status."]
#[repr(C)]
#[repr(align(64))]
#[derive(Copy, Clone)]
pub union rte_ring__bindgen_ty_2 {
    pub cons: rte_ring_headtail,
    pub hts_cons: rte_ring_hts_headtail,
    pub rts_cons: rte_ring_rts_headtail,
}
extern "C" {
    #[doc = " Calculate the memory size needed for a ring with given element size\n\n This function returns the number of bytes needed for a ring, given\n the number of elements in it and the size of the element. This value\n is the sum of the size of the structure rte_ring and the size of the\n memory needed for storing the elements. The value is aligned to a cache\n line size.\n\n @param esize\n   The size of ring element, in bytes. It must be a multiple of 4.\n @param count\n   The number of elements in the ring (must be a power of 2).\n @return\n   - The memory size needed for the ring on success.\n   - -EINVAL - esize is not a multiple of 4 or count provided is not a\n\t\t power of 2."]
    pub fn rte_ring_get_memsize_elem(
        esize: ::std::os::raw::c_uint,
        count: ::std::os::raw::c_uint,
    ) -> isize;
}
extern "C" {
    #[doc = " Create a new ring named *name* that stores elements with given size.\n\n This function uses ``memzone_reserve()`` to allocate memory. Then it\n calls rte_ring_init() to initialize an empty ring.\n\n The new ring size is set to *count*, which must be a power of\n two. Water marking is disabled by default. The real usable ring size\n is *count-1* instead of *count* to differentiate a full ring from an\n empty ring.\n\n The ring is added in RTE_TAILQ_RING list.\n\n @param name\n   The name of the ring.\n @param esize\n   The size of ring element, in bytes. It must be a multiple of 4.\n @param count\n   The number of elements in the ring (must be a power of 2).\n @param socket_id\n   The *socket_id* argument is the socket identifier in case of\n   NUMA. The value can be *SOCKET_ID_ANY* if there is no NUMA\n   constraint for the reserved zone.\n @param flags\n   An OR of the following:\n   - One of mutually exclusive flags that define producer behavior:\n      - RING_F_SP_ENQ: If this flag is set, the default behavior when\n        using ``rte_ring_enqueue()`` or ``rte_ring_enqueue_bulk()``\n        is \"single-producer\".\n      - RING_F_MP_RTS_ENQ: If this flag is set, the default behavior when\n        using ``rte_ring_enqueue()`` or ``rte_ring_enqueue_bulk()``\n        is \"multi-producer RTS mode\".\n      - RING_F_MP_HTS_ENQ: If this flag is set, the default behavior when\n        using ``rte_ring_enqueue()`` or ``rte_ring_enqueue_bulk()``\n        is \"multi-producer HTS mode\".\n     If none of these flags is set, then default \"multi-producer\"\n     behavior is selected.\n   - One of mutually exclusive flags that define consumer behavior:\n      - RING_F_SC_DEQ: If this flag is set, the default behavior when\n        using ``rte_ring_dequeue()`` or ``rte_ring_dequeue_bulk()``\n        is \"single-consumer\". Otherwise, it is \"multi-consumers\".\n      - RING_F_MC_RTS_DEQ: If this flag is set, the default behavior when\n        using ``rte_ring_dequeue()`` or ``rte_ring_dequeue_bulk()``\n        is \"multi-consumer RTS mode\".\n      - RING_F_MC_HTS_DEQ: If this flag is set, the default behavior when\n        using ``rte_ring_dequeue()`` or ``rte_ring_dequeue_bulk()``\n        is \"multi-consumer HTS mode\".\n     If none of these flags is set, then default \"multi-consumer\"\n     behavior is selected.\n @return\n   On success, the pointer to the new allocated ring. NULL on error with\n    rte_errno set appropriately. Possible errno values include:\n    - E_RTE_NO_CONFIG - function could not get pointer to rte_config structure\n    - EINVAL - esize is not a multiple of 4 or count provided is not a\n\t\t power of 2.\n    - ENOSPC - the maximum number of memzones has already been allocated\n    - EEXIST - a memzone with the same name already exists\n    - ENOMEM - no appropriate memory area found in which to create memzone"]
    pub fn rte_ring_create_elem(
        name: *const ::std::os::raw::c_char,
        esize: ::std::os::raw::c_uint,
        count: ::std::os::raw::c_uint,
        socket_id: ::std::os::raw::c_int,
        flags: ::std::os::raw::c_uint,
    ) -> *mut rte_ring;
}
#[doc = " Ring zero-copy information structure.\n\n This structure contains the pointers and length of the space\n reserved on the ring storage."]
#[repr(C)]
#[repr(align(64))]
#[derive(Debug, Copy, Clone)]
pub struct rte_ring_zc_data {
    pub ptr1: *mut ::std::os::raw::c_void,
    pub ptr2: *mut ::std::os::raw::c_void,
    pub n1: ::std::os::raw::c_uint,
}
extern "C" {
    #[doc = " Calculate the memory size needed for a ring\n\n This function returns the number of bytes needed for a ring, given\n the number of elements in it. This value is the sum of the size of\n the structure rte_ring and the size of the memory needed by the\n objects pointers. The value is aligned to a cache line size.\n\n @param count\n   The number of elements in the ring (must be a power of 2).\n @return\n   - The memory size needed for the ring on success.\n   - -EINVAL if count is not a power of 2."]
    pub fn rte_ring_get_memsize(count: ::std::os::raw::c_uint) -> isize;
}
extern "C" {
    #[doc = " Initialize a ring structure.\n\n Initialize a ring structure in memory pointed by \"r\". The size of the\n memory area must be large enough to store the ring structure and the\n object table. It is advised to use rte_ring_get_memsize() to get the\n appropriate size.\n\n The ring size is set to *count*, which must be a power of two.\n The real usable ring size is *count-1* instead of *count* to\n differentiate a full ring from an empty ring.\n\n The ring is not added in RTE_TAILQ_RING global list. Indeed, the\n memory given by the caller may not be shareable among dpdk\n processes.\n\n @param r\n   The pointer to the ring structure followed by the objects table.\n @param name\n   The name of the ring.\n @param count\n   The number of elements in the ring (must be a power of 2,\n   unless RING_F_EXACT_SZ is set in flags).\n @param flags\n   An OR of the following:\n   - One of mutually exclusive flags that define producer behavior:\n      - RING_F_SP_ENQ: If this flag is set, the default behavior when\n        using ``rte_ring_enqueue()`` or ``rte_ring_enqueue_bulk()``\n        is \"single-producer\".\n      - RING_F_MP_RTS_ENQ: If this flag is set, the default behavior when\n        using ``rte_ring_enqueue()`` or ``rte_ring_enqueue_bulk()``\n        is \"multi-producer RTS mode\".\n      - RING_F_MP_HTS_ENQ: If this flag is set, the default behavior when\n        using ``rte_ring_enqueue()`` or ``rte_ring_enqueue_bulk()``\n        is \"multi-producer HTS mode\".\n     If none of these flags is set, then default \"multi-producer\"\n     behavior is selected.\n   - One of mutually exclusive flags that define consumer behavior:\n      - RING_F_SC_DEQ: If this flag is set, the default behavior when\n        using ``rte_ring_dequeue()`` or ``rte_ring_dequeue_bulk()``\n        is \"single-consumer\". Otherwise, it is \"multi-consumers\".\n      - RING_F_MC_RTS_DEQ: If this flag is set, the default behavior when\n        using ``rte_ring_dequeue()`` or ``rte_ring_dequeue_bulk()``\n        is \"multi-consumer RTS mode\".\n      - RING_F_MC_HTS_DEQ: If this flag is set, the default behavior when\n        using ``rte_ring_dequeue()`` or ``rte_ring_dequeue_bulk()``\n        is \"multi-consumer HTS mode\".\n     If none of these flags is set, then default \"multi-consumer\"\n     behavior is selected.\n   - RING_F_EXACT_SZ: If this flag is set, the ring will hold exactly the\n     requested number of entries, and the requested size will be rounded up\n     to the next power of two, but the usable space will be exactly that\n     requested. Worst case, if a power-of-2 size is requested, half the\n     ring space will be wasted.\n     Without this flag set, the ring size requested must be a power of 2,\n     and the usable space will be that size - 1.\n @return\n   0 on success, or a negative value on error."]
    pub fn rte_ring_init(
        r: *mut rte_ring,
        name: *const ::std::os::raw::c_char,
        count: ::std::os::raw::c_uint,
        flags: ::std::os::raw::c_uint,
    ) -> ::std::os::raw::c_int;
}
extern "C" {
    #[doc = " Create a new ring named *name* in memory.\n\n This function uses ``memzone_reserve()`` to allocate memory. Then it\n calls rte_ring_init() to initialize an empty ring.\n\n The new ring size is set to *count*, which must be a power of two.\n The real usable ring size is *count-1* instead of *count* to\n differentiate a full ring from an empty ring.\n\n The ring is added in RTE_TAILQ_RING list.\n\n @param name\n   The name of the ring.\n @param count\n   The size of the ring (must be a power of 2,\n   unless RING_F_EXACT_SZ is set in flags).\n @param socket_id\n   The *socket_id* argument is the socket identifier in case of\n   NUMA. The value can be *SOCKET_ID_ANY* if there is no NUMA\n   constraint for the reserved zone.\n @param flags\n   An OR of the following:\n   - One of mutually exclusive flags that define producer behavior:\n      - RING_F_SP_ENQ: If this flag is set, the default behavior when\n        using ``rte_ring_enqueue()`` or ``rte_ring_enqueue_bulk()``\n        is \"single-producer\".\n      - RING_F_MP_RTS_ENQ: If this flag is set, the default behavior when\n        using ``rte_ring_enqueue()`` or ``rte_ring_enqueue_bulk()``\n        is \"multi-producer RTS mode\".\n      - RING_F_MP_HTS_ENQ: If this flag is set, the default behavior when\n        using ``rte_ring_enqueue()`` or ``rte_ring_enqueue_bulk()``\n        is \"multi-producer HTS mode\".\n     If none of these flags is set, then default \"multi-producer\"\n     behavior is selected.\n   - One of mutually exclusive flags that define consumer behavior:\n      - RING_F_SC_DEQ: If this flag is set, the default behavior when\n        using ``rte_ring_dequeue()`` or ``rte_ring_dequeue_bulk()``\n        is \"single-consumer\". Otherwise, it is \"multi-consumers\".\n      - RING_F_MC_RTS_DEQ: If this flag is set, the default behavior when\n        using ``rte_ring_dequeue()`` or ``rte_ring_dequeue_bulk()``\n        is \"multi-consumer RTS mode\".\n      - RING_F_MC_HTS_DEQ: If this flag is set, the default behavior when\n        using ``rte_ring_dequeue()`` or ``rte_ring_dequeue_bulk()``\n        is \"multi-consumer HTS mode\".\n     If none of these flags is set, then default \"multi-consumer\"\n     behavior is selected.\n   - RING_F_EXACT_SZ: If this flag is set, the ring will hold exactly the\n     requested number of entries, and the requested size will be rounded up\n     to the next power of two, but the usable space will be exactly that\n     requested. Worst case, if a power-of-2 size is requested, half the\n     ring space will be wasted.\n     Without this flag set, the ring size requested must be a power of 2,\n     and the usable space will be that size - 1.\n @return\n   On success, the pointer to the new allocated ring. NULL on error with\n    rte_errno set appropriately. Possible errno values include:\n    - E_RTE_NO_CONFIG - function could not get pointer to rte_config structure\n    - EINVAL - count provided is not a power of 2\n    - ENOSPC - the maximum number of memzones has already been allocated\n    - EEXIST - a memzone with the same name already exists\n    - ENOMEM - no appropriate memory area found in which to create memzone"]
    pub fn rte_ring_create(
        name: *const ::std::os::raw::c_char,
        count: ::std::os::raw::c_uint,
        socket_id: ::std::os::raw::c_int,
        flags: ::std::os::raw::c_uint,
    ) -> *mut rte_ring;
}
extern "C" {
    #[doc = " De-allocate all memory used by the ring.\n\n @param r\n   Ring to free.\n   If NULL then, the function does nothing."]
    pub fn rte_ring_free(r: *mut rte_ring);
}
extern "C" {
    #[doc = " Dump the status of the ring to a file.\n\n @param f\n   A pointer to a file for output\n @param r\n   A pointer to the ring structure."]
    pub fn rte_ring_dump(f: *mut FILE, r: *const rte_ring);
}
extern "C" {
    #[doc = " Flush a ring.\n\n This function flush all the elements in a ring\n\n @warning\n Make sure the ring is not in use while calling this function.\n\n @param r\n   A pointer to the ring structure."]
    pub fn rte_ring_reset(r: *mut rte_ring);
}
extern "C" {
    #[doc = " Dump the status of all rings on the console\n\n @param f\n   A pointer to a file for output"]
    pub fn rte_ring_list_dump(f: *mut FILE);
}
extern "C" {
    #[doc = " Search a ring from its name\n\n @param name\n   The name of the ring.\n @return\n   The pointer to the ring matching the name, or NULL if not found,\n   with rte_errno set appropriately. Possible rte_errno values include:\n    - ENOENT - required entry not available to return."]
    pub fn rte_ring_lookup(name: *const ::std::os::raw::c_char) -> *mut rte_ring;
}
#[doc = " 64 bits vector size to use with unsigned 8 bits elements.\n\n a = (rte_v64u8_t){ a0, a1, a2, a3, a4, a5, a6, a7 }"]
pub type rte_v64u8_t = [u8; 8usize];
#[doc = " 64 bits vector size to use with unsigned 16 bits elements.\n\n a = (rte_v64u16_t){ a0, a1, a2, a3 }"]
pub type rte_v64u16_t = [u16; 4usize];
#[doc = " 64 bits vector size to use with unsigned 32 bits elements.\n\n a = (rte_v64u32_t){ a0, a1 }"]
pub type rte_v64u32_t = [u32; 2usize];
#[doc = " 128 bits vector size to use with unsigned 8 bits elements.\n\n a = (rte_v128u8_t){ a00, a01, a02, a03, a04, a05, a06, a07,\n                     a08, a09, a10, a11, a12, a13, a14, a15 }"]
pub type rte_v128u8_t = [u8; 16usize];
#[doc = " 128 bits vector size to use with unsigned 16 bits elements.\n\n a = (rte_v128u16_t){ a0, a1, a2, a3, a4, a5, a6, a7 }"]
pub type rte_v128u16_t = [u16; 8usize];
#[doc = " 128 bits vector size to use with unsigned 32 bits elements.\n\n a = (rte_v128u32_t){ a0, a1, a2, a3 }"]
pub type rte_v128u32_t = [u32; 4usize];
#[doc = " 128 bits vector size to use with unsigned 64 bits elements.\n\n a = (rte_v128u64_t){ a0, a1 }"]
pub type rte_v128u64_t = [u64; 2usize];
#[doc = " 256 bits vector size to use with unsigned 8 bits elements.\n\n a = (rte_v256u8_t){ a00, a01, a02, a03, a04, a05, a06, a07,\n                     a08, a09, a10, a11, a12, a13, a14, a15,\n                     a16, a17, a18, a19, a20, a21, a22, a23,\n                     a24, a25, a26, a27, a28, a29, a30, a31 }"]
pub type rte_v256u8_t = [u8; 32usize];
#[doc = " 256 bits vector size to use with unsigned 16 bits elements.\n\n a = (rte_v256u16_t){ a00, a01, a02, a03, a04, a05, a06, a07,\n                      a08, a09, a10, a11, a12, a13, a14, a15 }"]
pub type rte_v256u16_t = [u16; 16usize];
#[doc = " 256 bits vector size to use with unsigned 32 bits elements.\n\n a = (rte_v256u32_t){ a0, a1, a2, a3, a4, a5, a6, a7 }"]
pub type rte_v256u32_t = [u32; 8usize];
#[doc = " 256 bits vector size to use with unsigned 64 bits elements.\n\n a = (rte_v256u64_t){ a0, a1, a2, a3 }"]
pub type rte_v256u64_t = [u64; 4usize];
#[doc = " 64 bits vector size to use with 8 bits elements.\n\n a = (rte_v64s8_t){ a0, a1, a2, a3, a4, a5, a6, a7 }"]
pub type rte_v64s8_t = [i8; 8usize];
#[doc = " 64 bits vector size to use with 16 bits elements.\n\n a = (rte_v64s16_t){ a0, a1, a2, a3 }"]
pub type rte_v64s16_t = [i16; 4usize];
#[doc = " 64 bits vector size to use with 32 bits elements.\n\n a = (rte_v64s32_t){ a0, a1 }"]
pub type rte_v64s32_t = [i32; 2usize];
#[doc = " 128 bits vector size to use with 8 bits elements.\n\n a = (rte_v128s8_t){ a00, a01, a02, a03, a04, a05, a06, a07,\n                     a08, a09, a10, a11, a12, a13, a14, a15 }"]
pub type rte_v128s8_t = [i8; 16usize];
#[doc = " 128 bits vector size to use with 16 bits elements.\n\n a = (rte_v128s16_t){ a0, a1, a2, a3, a4, a5, a6, a7 }"]
pub type rte_v128s16_t = [i16; 8usize];
#[doc = " 128 bits vector size to use with 32 bits elements.\n\n a = (rte_v128s32_t){ a0, a1, a2, a3 }"]
pub type rte_v128s32_t = [i32; 4usize];
#[doc = " 128 bits vector size to use with 64 bits elements.\n\n a = (rte_v128s64_t){ a1, a2 }"]
pub type rte_v128s64_t = [i64; 2usize];
#[doc = " 256 bits vector size to use with 8 bits elements.\n\n a = (rte_v256s8_t){ a00, a01, a02, a03, a04, a05, a06, a07,\n                     a08, a09, a10, a11, a12, a13, a14, a15,\n                     a16, a17, a18, a19, a20, a21, a22, a23,\n                     a24, a25, a26, a27, a28, a29, a30, a31 }"]
pub type rte_v256s8_t = [i8; 32usize];
#[doc = " 256 bits vector size to use with 16 bits elements.\n\n a = (rte_v256s16_t){ a00, a01, a02, a03, a04, a05, a06, a07,\n                      a08, a09, a10, a11, a12, a13, a14, a15 }"]
pub type rte_v256s16_t = [i16; 16usize];
#[doc = " 256 bits vector size to use with 32 bits elements.\n\n a = (rte_v256s32_t){ a0, a1, a2, a3, a4, a5, a6, a7 }"]
pub type rte_v256s32_t = [i32; 8usize];
#[doc = " 256 bits vector size to use with 64 bits elements.\n\n a = (rte_v256s64_t){ a0, a1, a2, a3 }"]
pub type rte_v256s64_t = [i64; 4usize];
pub const rte_vect_max_simd_RTE_VECT_SIMD_DISABLED: rte_vect_max_simd = 64;
pub const rte_vect_max_simd_RTE_VECT_SIMD_128: rte_vect_max_simd = 128;
#[doc = "< Limits path selection to AVX2 or below."]
pub const rte_vect_max_simd_RTE_VECT_SIMD_256: rte_vect_max_simd = 256;
#[doc = "< Limits path selection to AVX512 or below."]
pub const rte_vect_max_simd_RTE_VECT_SIMD_512: rte_vect_max_simd = 512;
pub const rte_vect_max_simd_RTE_VECT_SIMD_MAX: rte_vect_max_simd = 32768;
#[doc = " The max SIMD bitwidth value to limit vector path selection."]
pub type rte_vect_max_simd = ::std::os::raw::c_uint;
extern "C" {
    #[doc = " Get the supported SIMD bitwidth.\n\n @return\n   uint16_t bitwidth."]
    pub fn rte_vect_get_max_simd_bitwidth() -> u16;
}
extern "C" {
    #[doc = " Set the supported SIMD bitwidth.\n This API should only be called once at initialization, before EAL init.\n\n @param bitwidth\n   uint16_t bitwidth.\n @return\n   - 0 on success.\n   - -EINVAL on invalid bitwidth parameter.\n   - -EPERM if bitwidth is forced."]
    pub fn rte_vect_set_max_simd_bitwidth(bitwidth: u16) -> ::std::os::raw::c_int;
}
pub type xmm_t = __m128i;
#[repr(C)]
#[repr(align(16))]
#[derive(Copy, Clone)]
pub union rte_xmm {
    pub x: xmm_t,
    pub u8_: [u8; 16usize],
    pub u16_: [u16; 8usize],
    pub u32_: [u32; 4usize],
    pub u64_: [u64; 2usize],
    pub pd: [f64; 2usize],
}
pub type rte_xmm_t = rte_xmm;
extern "C" {
    #[doc = " Takes string \"string\" parameter and splits it at character \"delim\"\n up to maxtokens-1 times - to give \"maxtokens\" resulting tokens. Like\n strtok or strsep functions, this modifies its input string, by replacing\n instances of \"delim\" with '\\\\0'. All resultant tokens are returned in the\n \"tokens\" array which must have enough entries to hold \"maxtokens\".\n\n @param string\n   The input string to be split into tokens\n\n @param stringlen\n   The max length of the input buffer\n\n @param tokens\n   The array to hold the pointers to the tokens in the string\n\n @param maxtokens\n   The number of elements in the tokens array. At most, maxtokens-1 splits\n   of the string will be done.\n\n @param delim\n   The character on which the split of the data will be done\n\n @return\n   The number of tokens in the tokens array."]
    pub fn rte_strsplit(
        string: *mut ::std::os::raw::c_char,
        stringlen: ::std::os::raw::c_int,
        tokens: *mut *mut ::std::os::raw::c_char,
        maxtokens: ::std::os::raw::c_int,
        delim: ::std::os::raw::c_char,
    ) -> ::std::os::raw::c_int;
}
extern "C" {
    #[doc = " Copy string src to buffer dst of size dsize.\n At most dsize-1 chars will be copied.\n Always NUL-terminates, unless (dsize == 0).\n\n @param dst\n   The destination string.\n\n @param src\n   The input string to be copied.\n\n @param dsize\n   Length in bytes of the destination buffer.\n\n @return\n   The number of bytes copied (terminating NUL-byte excluded) on success.\n   -E2BIG if the destination buffer is too small.\n   rte_errno is set."]
    pub fn rte_strscpy(
        dst: *mut ::std::os::raw::c_char,
        src: *const ::std::os::raw::c_char,
        dsize: usize,
    ) -> isize;
}
extern "C" {
    #[doc = "  Test if trace is enabled.\n\n  @return\n     true if trace is enabled, false otherwise."]
    pub fn rte_trace_is_enabled() -> bool;
}
#[doc = " In this mode, when no space is left in the trace buffer, the\n subsequent events overwrite the old events."]
pub const rte_trace_mode_RTE_TRACE_MODE_OVERWRITE: rte_trace_mode = 0;
#[doc = " In this mode, when no space is left in the trace buffer, the\n subsequent events shall not be recorded."]
pub const rte_trace_mode_RTE_TRACE_MODE_DISCARD: rte_trace_mode = 1;
#[doc = " Enumerate trace mode operation."]
pub type rte_trace_mode = ::std::os::raw::c_uint;
extern "C" {
    #[doc = " Set the trace mode.\n\n @param mode\n   Trace mode."]
    pub fn rte_trace_mode_set(mode: rte_trace_mode);
}
extern "C" {
    #[doc = " Get the trace mode.\n\n @return\n   The current trace mode."]
    pub fn rte_trace_mode_get() -> rte_trace_mode;
}
extern "C" {
    #[doc = " Enable/Disable a set of tracepoints based on globbing pattern.\n\n @param pattern\n   The globbing pattern identifying the tracepoint.\n @param enable\n   true to enable tracepoint, false to disable the tracepoint, upon match.\n @return\n   - 0: Success and no pattern match.\n   - 1: Success and found pattern match.\n   - (-ERANGE): Tracepoint object is not registered."]
    pub fn rte_trace_pattern(
        pattern: *const ::std::os::raw::c_char,
        enable: bool,
    ) -> ::std::os::raw::c_int;
}
extern "C" {
    #[doc = " Enable/Disable a set of tracepoints based on regular expression.\n\n @param regex\n   A regular expression identifying the tracepoint.\n @param enable\n   true to enable tracepoint, false to disable the tracepoint, upon match.\n @return\n   - 0: Success and no pattern match.\n   - 1: Success and found pattern match.\n   - (-ERANGE): Tracepoint object is not registered.\n   - (-EINVAL): Invalid regular expression rule."]
    pub fn rte_trace_regexp(
        regex: *const ::std::os::raw::c_char,
        enable: bool,
    ) -> ::std::os::raw::c_int;
}
extern "C" {
    #[doc = " Save the trace buffer to the trace directory.\n\n By default, trace directory will be created at $HOME directory and this can\n be overridden by --trace-dir EAL parameter.\n\n @return\n   - 0: Success.\n   - <0 : Failure."]
    pub fn rte_trace_save() -> ::std::os::raw::c_int;
}
extern "C" {
    #[doc = " Dump the trace metadata to a file.\n\n @param f\n   A pointer to a file for output\n @return\n   - 0: Success.\n   - <0 : Failure."]
    pub fn rte_trace_metadata_dump(f: *mut FILE) -> ::std::os::raw::c_int;
}
extern "C" {
    #[doc = " Dump the trace subsystem status to a file.\n\n @param f\n   A pointer to a file for output"]
    pub fn rte_trace_dump(f: *mut FILE);
}
#[doc = " The tracepoint object."]
pub type rte_trace_point_t = u64;
extern "C" {
    #[doc = " Enable recording events of the given tracepoint in the trace buffer.\n\n @param tp\n   The tracepoint object to enable.\n @return\n   - 0: Success.\n   - (-ERANGE): Trace object is not registered."]
    pub fn rte_trace_point_enable(tp: *mut rte_trace_point_t) -> ::std::os::raw::c_int;
}
extern "C" {
    #[doc = " Disable recording events of the given tracepoint in the trace buffer.\n\n @param tp\n   The tracepoint object to disable.\n @return\n   - 0: Success.\n   - (-ERANGE): Trace object is not registered."]
    pub fn rte_trace_point_disable(tp: *mut rte_trace_point_t) -> ::std::os::raw::c_int;
}
extern "C" {
    #[doc = " Test if recording events from the given tracepoint is enabled.\n\n @param tp\n    The tracepoint object.\n @return\n    true if tracepoint is enabled, false otherwise."]
    pub fn rte_trace_point_is_enabled(tp: *mut rte_trace_point_t) -> bool;
}
extern "C" {
    #[doc = " Lookup a tracepoint object from its name.\n\n @param name\n   The name of the tracepoint.\n @return\n   The tracepoint object or NULL if not found."]
    pub fn rte_trace_point_lookup(name: *const ::std::os::raw::c_char) -> *mut rte_trace_point_t;
}
#[doc = " A structure that stores a per-core object cache."]
#[repr(C)]
#[repr(align(64))]
#[derive(Debug, Copy, Clone)]
pub struct rte_mempool_cache {
    #[doc = "< Size of the cache"]
    pub size: u32,
    #[doc = "< Threshold before we flush excess elements"]
    pub flushthresh: u32,
    #[doc = "< Current cache count"]
    pub len: u32,
    pub __bindgen_padding_0: [u64; 6usize],
    #[doc = " Cache objects\n\n Cache is allocated to this size to allow it to overflow in certain\n cases to avoid needless emptying of cache."]
    pub objs: [*mut ::std::os::raw::c_void; 1024usize],
}
#[doc = " A structure that stores the size of mempool elements."]
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct rte_mempool_objsz {
    #[doc = "< Size of an element."]
    pub elt_size: u32,
    #[doc = "< Size of header (before elt)."]
    pub header_size: u32,
    #[doc = "< Size of trailer (after elt)."]
    pub trailer_size: u32,
    pub total_size: u32,
}
#[doc = " Mempool object header structure\n\n Each object stored in mempools are prefixed by this header structure,\n it allows to retrieve the mempool pointer from the object and to\n iterate on all objects attached to a mempool. When debug is enabled,\n a cookie is also added in this structure preventing corruptions and\n double-frees."]
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct rte_mempool_objhdr {
    #[doc = "< Next in list."]
    pub next: rte_mempool_objhdr__bindgen_ty_1,
    #[doc = "< The mempool owning the object."]
    pub mp: *mut rte_mempool,
    #[doc = "< IO address of the object."]
    pub iova: rte_iova_t,
}
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct rte_mempool_objhdr__bindgen_ty_1 {
    pub stqe_next: *mut rte_mempool_objhdr,
}
#[doc = " A list of object headers type"]
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct rte_mempool_objhdr_list {
    pub stqh_first: *mut rte_mempool_objhdr,
    pub stqh_last: *mut *mut rte_mempool_objhdr,
}
extern "C" {
    #[doc = " @internal Logtype used for mempool related messages."]
    pub static mut rte_mempool_logtype: ::std::os::raw::c_int;
}
#[doc = " A list of memory where objects are stored"]
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct rte_mempool_memhdr_list {
    pub stqh_first: *mut rte_mempool_memhdr,
    pub stqh_last: *mut *mut rte_mempool_memhdr,
}
#[doc = " Callback used to free a memory chunk"]
pub type rte_mempool_memchunk_free_cb_t = ::std::option::Option<
    unsafe extern "C" fn(memhdr: *mut rte_mempool_memhdr, opaque: *mut ::std::os::raw::c_void),
>;
#[doc = " Mempool objects memory header structure\n\n The memory chunks where objects are stored. Each chunk is virtually\n and physically contiguous."]
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct rte_mempool_memhdr {
    #[doc = "< Next in list."]
    pub next: rte_mempool_memhdr__bindgen_ty_1,
    #[doc = "< The mempool owning the chunk"]
    pub mp: *mut rte_mempool,
    #[doc = "< Virtual address of the chunk"]
    pub addr: *mut ::std::os::raw::c_void,
    #[doc = "< IO address of the chunk"]
    pub iova: rte_iova_t,
    #[doc = "< length of the chunk"]
    pub len: usize,
    #[doc = "< Free callback"]
    pub free_cb: rte_mempool_memchunk_free_cb_t,
    #[doc = "< Argument passed to the free callback"]
    pub opaque: *mut ::std::os::raw::c_void,
}
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct rte_mempool_memhdr__bindgen_ty_1 {
    pub stqe_next: *mut rte_mempool_memhdr,
}
#[doc = " Additional information about the mempool\n\n The structure is cache-line aligned to avoid ABI breakages in\n a number of cases when something small is added."]
#[repr(C)]
#[repr(align(64))]
#[derive(Debug, Copy, Clone)]
pub struct rte_mempool_info {
    #[doc = " Number of objects in the contiguous block"]
    pub contig_block_size: ::std::os::raw::c_uint,
}
#[doc = " The RTE mempool structure."]
#[repr(C)]
#[repr(align(64))]
#[derive(Copy, Clone)]
pub struct rte_mempool {
    #[doc = "< Name of mempool."]
    pub name: [::std::os::raw::c_char; 26usize],
    pub __bindgen_anon_1: rte_mempool__bindgen_ty_1,
    #[doc = "< optional args for ops alloc."]
    pub pool_config: *mut ::std::os::raw::c_void,
    #[doc = "< Memzone where pool is alloc'd."]
    pub mz: *const rte_memzone,
    #[doc = "< Flags of the mempool."]
    pub flags: ::std::os::raw::c_uint,
    #[doc = "< Socket id passed at create."]
    pub socket_id: ::std::os::raw::c_int,
    #[doc = "< Max size of the mempool."]
    pub size: u32,
    pub cache_size: u32,
    #[doc = "< Size of an element."]
    pub elt_size: u32,
    #[doc = "< Size of header (before elt)."]
    pub header_size: u32,
    #[doc = "< Size of trailer (after elt)."]
    pub trailer_size: u32,
    #[doc = "< Size of private data."]
    pub private_data_size: ::std::os::raw::c_uint,
    #[doc = " Index into rte_mempool_ops_table array of mempool ops\n structs, which contain callback function pointers.\n We're using an index here rather than pointers to the callbacks\n to facilitate any secondary processes that may want to use\n this mempool."]
    pub ops_index: i32,
    #[doc = "< Per-lcore local cache"]
    pub local_cache: *mut rte_mempool_cache,
    #[doc = "< Number of populated objects."]
    pub populated_size: u32,
    #[doc = "< List of objects in pool"]
    pub elt_list: rte_mempool_objhdr_list,
    #[doc = "< Number of memory chunks"]
    pub nb_mem_chunks: u32,
    #[doc = "< List of memory chunks"]
    pub mem_list: rte_mempool_memhdr_list,
}
#[repr(C)]
#[derive(Copy, Clone)]
pub union rte_mempool__bindgen_ty_1 {
    #[doc = "< Ring or pool to store objects."]
    pub pool_data: *mut ::std::os::raw::c_void,
    #[doc = "< External mempool identifier."]
    pub pool_id: u64,
}
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct rte_mempool_objtlr {
    _unused: [u8; 0],
}
extern "C" {
    #[doc = " @internal Check and update cookies or panic.\n\n @param mp\n   Pointer to the memory pool.\n @param obj_table_const\n   Pointer to a table of void * pointers (objects).\n @param n\n   Index of object in object table.\n @param free\n   - 0: object is supposed to be allocated, mark it as free\n   - 1: object is supposed to be free, mark it as allocated\n   - 2: just check that cookie is valid (free or allocated)"]
    pub fn rte_mempool_check_cookies(
        mp: *const rte_mempool,
        obj_table_const: *const *mut ::std::os::raw::c_void,
        n: ::std::os::raw::c_uint,
        free: ::std::os::raw::c_int,
    );
}
extern "C" {
    #[doc = " @internal Check contiguous object blocks and update cookies or panic.\n\n @param mp\n   Pointer to the memory pool.\n @param first_obj_table_const\n   Pointer to a table of void * pointers (first object of the contiguous\n   object blocks).\n @param n\n   Number of contiguous object blocks.\n @param free\n   - 0: object is supposed to be allocated, mark it as free\n   - 1: object is supposed to be free, mark it as allocated\n   - 2: just check that cookie is valid (free or allocated)"]
    pub fn rte_mempool_contig_blocks_check_cookies(
        mp: *const rte_mempool,
        first_obj_table_const: *const *mut ::std::os::raw::c_void,
        n: ::std::os::raw::c_uint,
        free: ::std::os::raw::c_int,
    );
}
#[doc = " Prototype for implementation specific data provisioning function.\n\n The function should provide the implementation specific memory for\n use by the other mempool ops functions in a given mempool ops struct.\n E.g. the default ops provides an instance of the rte_ring for this purpose.\n it will most likely point to a different type of data structure, and\n will be transparent to the application programmer.\n This function should set mp->pool_data."]
pub type rte_mempool_alloc_t =
    ::std::option::Option<unsafe extern "C" fn(mp: *mut rte_mempool) -> ::std::os::raw::c_int>;
#[doc = " Free the opaque private data pointed to by mp->pool_data pointer."]
pub type rte_mempool_free_t = ::std::option::Option<unsafe extern "C" fn(mp: *mut rte_mempool)>;
#[doc = " Enqueue 'n' objects into the external pool.\n @return\n   - 0: Success\n   - <0: Error"]
pub type rte_mempool_enqueue_t = ::std::option::Option<
    unsafe extern "C" fn(
        mp: *mut rte_mempool,
        obj_table: *const *mut ::std::os::raw::c_void,
        n: ::std::os::raw::c_uint,
    ) -> ::std::os::raw::c_int,
>;
#[doc = " Dequeue 'n' objects from the external pool.\n @return\n   - 0: Success\n   - <0: Error"]
pub type rte_mempool_dequeue_t = ::std::option::Option<
    unsafe extern "C" fn(
        mp: *mut rte_mempool,
        obj_table: *mut *mut ::std::os::raw::c_void,
        n: ::std::os::raw::c_uint,
    ) -> ::std::os::raw::c_int,
>;
#[doc = " Dequeue a number of contiguous object blocks from the external pool."]
pub type rte_mempool_dequeue_contig_blocks_t = ::std::option::Option<
    unsafe extern "C" fn(
        mp: *mut rte_mempool,
        first_obj_table: *mut *mut ::std::os::raw::c_void,
        n: ::std::os::raw::c_uint,
    ) -> ::std::os::raw::c_int,
>;
#[doc = " Return the number of available objects in the external pool."]
pub type rte_mempool_get_count =
    ::std::option::Option<unsafe extern "C" fn(mp: *const rte_mempool) -> ::std::os::raw::c_uint>;
#[doc = " Calculate memory size required to store given number of objects.\n\n If mempool objects are not required to be IOVA-contiguous\n (the flag RTE_MEMPOOL_F_NO_IOVA_CONTIG is set), min_chunk_size defines\n virtually contiguous chunk size. Otherwise, if mempool objects must\n be IOVA-contiguous (the flag RTE_MEMPOOL_F_NO_IOVA_CONTIG is clear),\n min_chunk_size defines IOVA-contiguous chunk size.\n\n @param[in] mp\n   Pointer to the memory pool.\n @param[in] obj_num\n   Number of objects.\n @param[in] pg_shift\n   LOG2 of the physical pages size. If set to 0, ignore page boundaries.\n @param[out] min_chunk_size\n   Location for minimum size of the memory chunk which may be used to\n   store memory pool objects.\n @param[out] align\n   Location for required memory chunk alignment.\n @return\n   Required memory size."]
pub type rte_mempool_calc_mem_size_t = ::std::option::Option<
    unsafe extern "C" fn(
        mp: *const rte_mempool,
        obj_num: u32,
        pg_shift: u32,
        min_chunk_size: *mut usize,
        align: *mut usize,
    ) -> isize,
>;
extern "C" {
    #[doc = " @internal Helper to calculate memory size required to store given\n number of objects.\n\n This function is internal to mempool library and mempool drivers.\n\n If page boundaries may be ignored, it is just a product of total\n object size including header and trailer and number of objects.\n Otherwise, it is a number of pages required to store given number of\n objects without crossing page boundary.\n\n Note that if object size is bigger than page size, then it assumes\n that pages are grouped in subsets of physically continuous pages big\n enough to store at least one object.\n\n Minimum size of memory chunk is the total element size.\n Required memory chunk alignment is the cache line size.\n\n @param[in] mp\n   A pointer to the mempool structure.\n @param[in] obj_num\n   Number of objects to be added in mempool.\n @param[in] pg_shift\n   LOG2 of the physical pages size. If set to 0, ignore page boundaries.\n @param[in] chunk_reserve\n   Amount of memory that must be reserved at the beginning of each page,\n   or at the beginning of the memory area if pg_shift is 0.\n @param[out] min_chunk_size\n   Location for minimum size of the memory chunk which may be used to\n   store memory pool objects.\n @param[out] align\n   Location for required memory chunk alignment.\n @return\n   Required memory size."]
    pub fn rte_mempool_op_calc_mem_size_helper(
        mp: *const rte_mempool,
        obj_num: u32,
        pg_shift: u32,
        chunk_reserve: usize,
        min_chunk_size: *mut usize,
        align: *mut usize,
    ) -> isize;
}
extern "C" {
    #[doc = " Default way to calculate memory size required to store given number of\n objects.\n\n Equivalent to rte_mempool_op_calc_mem_size_helper(mp, obj_num, pg_shift,\n 0, min_chunk_size, align)."]
    pub fn rte_mempool_op_calc_mem_size_default(
        mp: *const rte_mempool,
        obj_num: u32,
        pg_shift: u32,
        min_chunk_size: *mut usize,
        align: *mut usize,
    ) -> isize;
}
#[doc = " Function to be called for each populated object.\n\n @param[in] mp\n   A pointer to the mempool structure.\n @param[in] opaque\n   An opaque pointer passed to iterator.\n @param[in] vaddr\n   Object virtual address.\n @param[in] iova\n   Input/output virtual address of the object or RTE_BAD_IOVA."]
pub type rte_mempool_populate_obj_cb_t = ::std::option::Option<
    unsafe extern "C" fn(
        mp: *mut rte_mempool,
        opaque: *mut ::std::os::raw::c_void,
        vaddr: *mut ::std::os::raw::c_void,
        iova: rte_iova_t,
    ),
>;
#[doc = " Populate memory pool objects using provided memory chunk.\n\n Populated objects should be enqueued to the pool, e.g. using\n rte_mempool_ops_enqueue_bulk().\n\n If the given IO address is unknown (iova = RTE_BAD_IOVA),\n the chunk doesn't need to be physically contiguous (only virtually),\n and allocated objects may span two pages.\n\n @param[in] mp\n   A pointer to the mempool structure.\n @param[in] max_objs\n   Maximum number of objects to be populated.\n @param[in] vaddr\n   The virtual address of memory that should be used to store objects.\n @param[in] iova\n   The IO address\n @param[in] len\n   The length of memory in bytes.\n @param[in] obj_cb\n   Callback function to be executed for each populated object.\n @param[in] obj_cb_arg\n   An opaque pointer passed to the callback function.\n @return\n   The number of objects added on success.\n   On error, no objects are populated and a negative errno is returned."]
pub type rte_mempool_populate_t = ::std::option::Option<
    unsafe extern "C" fn(
        mp: *mut rte_mempool,
        max_objs: ::std::os::raw::c_uint,
        vaddr: *mut ::std::os::raw::c_void,
        iova: rte_iova_t,
        len: usize,
        obj_cb: rte_mempool_populate_obj_cb_t,
        obj_cb_arg: *mut ::std::os::raw::c_void,
    ) -> ::std::os::raw::c_int,
>;
extern "C" {
    #[doc = " @internal Helper to populate memory pool object using provided memory\n chunk: just slice objects one by one, taking care of not\n crossing page boundaries.\n\n If RTE_MEMPOOL_POPULATE_F_ALIGN_OBJ is set in flags, the addresses\n of object headers will be aligned on a multiple of total_elt_sz.\n This feature is used by octeontx hardware.\n\n This function is internal to mempool library and mempool drivers.\n\n @param[in] mp\n   A pointer to the mempool structure.\n @param[in] flags\n   Logical OR of following flags:\n   - RTE_MEMPOOL_POPULATE_F_ALIGN_OBJ: align objects on addresses\n     multiple of total_elt_sz.\n @param[in] max_objs\n   Maximum number of objects to be added in mempool.\n @param[in] vaddr\n   The virtual address of memory that should be used to store objects.\n @param[in] iova\n   The IO address corresponding to vaddr, or RTE_BAD_IOVA.\n @param[in] len\n   The length of memory in bytes.\n @param[in] obj_cb\n   Callback function to be executed for each populated object.\n @param[in] obj_cb_arg\n   An opaque pointer passed to the callback function.\n @return\n   The number of objects added in mempool."]
    pub fn rte_mempool_op_populate_helper(
        mp: *mut rte_mempool,
        flags: ::std::os::raw::c_uint,
        max_objs: ::std::os::raw::c_uint,
        vaddr: *mut ::std::os::raw::c_void,
        iova: rte_iova_t,
        len: usize,
        obj_cb: rte_mempool_populate_obj_cb_t,
        obj_cb_arg: *mut ::std::os::raw::c_void,
    ) -> ::std::os::raw::c_int;
}
extern "C" {
    #[doc = " Default way to populate memory pool object using provided memory chunk.\n\n Equivalent to rte_mempool_op_populate_helper(mp, 0, max_objs, vaddr, iova,\n len, obj_cb, obj_cb_arg)."]
    pub fn rte_mempool_op_populate_default(
        mp: *mut rte_mempool,
        max_objs: ::std::os::raw::c_uint,
        vaddr: *mut ::std::os::raw::c_void,
        iova: rte_iova_t,
        len: usize,
        obj_cb: rte_mempool_populate_obj_cb_t,
        obj_cb_arg: *mut ::std::os::raw::c_void,
    ) -> ::std::os::raw::c_int;
}
#[doc = " Get some additional information about a mempool."]
pub type rte_mempool_get_info_t = ::std::option::Option<
    unsafe extern "C" fn(
        mp: *const rte_mempool,
        info: *mut rte_mempool_info,
    ) -> ::std::os::raw::c_int,
>;
#[doc = " Structure defining mempool operations structure"]
#[repr(C)]
#[repr(align(64))]
#[derive(Debug, Copy, Clone)]
pub struct rte_mempool_ops {
    #[doc = "< Name of mempool ops struct."]
    pub name: [::std::os::raw::c_char; 32usize],
    #[doc = "< Allocate private data."]
    pub alloc: rte_mempool_alloc_t,
    #[doc = "< Free the external pool."]
    pub free: rte_mempool_free_t,
    #[doc = "< Enqueue an object."]
    pub enqueue: rte_mempool_enqueue_t,
    #[doc = "< Dequeue an object."]
    pub dequeue: rte_mempool_dequeue_t,
    #[doc = "< Get qty of available objs."]
    pub get_count: rte_mempool_get_count,
    #[doc = " Optional callback to calculate memory size required to\n store specified number of objects."]
    pub calc_mem_size: rte_mempool_calc_mem_size_t,
    #[doc = " Optional callback to populate mempool objects using\n provided memory chunk."]
    pub populate: rte_mempool_populate_t,
    #[doc = " Get mempool info"]
    pub get_info: rte_mempool_get_info_t,
    #[doc = " Dequeue a number of contiguous object blocks."]
    pub dequeue_contig_blocks: rte_mempool_dequeue_contig_blocks_t,
}
#[doc = " Structure storing the table of registered ops structs, each of which contain\n the function pointers for the mempool ops functions.\n Each process has its own storage for this ops struct array so that\n the mempools can be shared across primary and secondary processes.\n The indices used to access the array are valid across processes, whereas\n any function pointers stored directly in the mempool struct would not be.\n This results in us simply having \"ops_index\" in the mempool struct."]
#[repr(C)]
#[repr(align(64))]
#[derive(Debug, Copy, Clone)]
pub struct rte_mempool_ops_table {
    #[doc = "< Spinlock for add/delete."]
    pub sl: rte_spinlock_t,
    #[doc = "< Number of used ops structs in the table."]
    pub num_ops: u32,
    pub __bindgen_padding_0: [u64; 7usize],
    #[doc = " Storage for all possible ops structs."]
    pub ops: [rte_mempool_ops; 16usize],
}
extern "C" {
    #[doc = " Array of registered ops structs."]
    pub static mut rte_mempool_ops_table: rte_mempool_ops_table;
}
extern "C" {
    #[doc = " @internal Wrapper for mempool_ops alloc callback.\n\n @param mp\n   Pointer to the memory pool.\n @return\n   - 0: Success; successfully allocated mempool pool_data.\n   - <0: Error; code of alloc function."]
    pub fn rte_mempool_ops_alloc(mp: *mut rte_mempool) -> ::std::os::raw::c_int;
}
extern "C" {
    #[doc = " @internal wrapper for mempool_ops get_count callback.\n\n @param mp\n   Pointer to the memory pool.\n @return\n   The number of available objects in the external pool."]
    pub fn rte_mempool_ops_get_count(mp: *const rte_mempool) -> ::std::os::raw::c_uint;
}
extern "C" {
    #[doc = " @internal wrapper for mempool_ops calc_mem_size callback.\n API to calculate size of memory required to store specified number of\n object.\n\n @param[in] mp\n   Pointer to the memory pool.\n @param[in] obj_num\n   Number of objects.\n @param[in] pg_shift\n   LOG2 of the physical pages size. If set to 0, ignore page boundaries.\n @param[out] min_chunk_size\n   Location for minimum size of the memory chunk which may be used to\n   store memory pool objects.\n @param[out] align\n   Location for required memory chunk alignment.\n @return\n   Required memory size aligned at page boundary."]
    pub fn rte_mempool_ops_calc_mem_size(
        mp: *const rte_mempool,
        obj_num: u32,
        pg_shift: u32,
        min_chunk_size: *mut usize,
        align: *mut usize,
    ) -> isize;
}
extern "C" {
    #[doc = " @internal wrapper for mempool_ops populate callback.\n\n Populate memory pool objects using provided memory chunk.\n\n @param[in] mp\n   A pointer to the mempool structure.\n @param[in] max_objs\n   Maximum number of objects to be populated.\n @param[in] vaddr\n   The virtual address of memory that should be used to store objects.\n @param[in] iova\n   The IO address\n @param[in] len\n   The length of memory in bytes.\n @param[in] obj_cb\n   Callback function to be executed for each populated object.\n @param[in] obj_cb_arg\n   An opaque pointer passed to the callback function.\n @return\n   The number of objects added on success.\n   On error, no objects are populated and a negative errno is returned."]
    pub fn rte_mempool_ops_populate(
        mp: *mut rte_mempool,
        max_objs: ::std::os::raw::c_uint,
        vaddr: *mut ::std::os::raw::c_void,
        iova: rte_iova_t,
        len: usize,
        obj_cb: rte_mempool_populate_obj_cb_t,
        obj_cb_arg: *mut ::std::os::raw::c_void,
    ) -> ::std::os::raw::c_int;
}
extern "C" {
    #[doc = " Wrapper for mempool_ops get_info callback.\n\n @param[in] mp\n   Pointer to the memory pool.\n @param[out] info\n   Pointer to the rte_mempool_info structure\n @return\n   - 0: Success; The mempool driver supports retrieving supplementary\n        mempool information\n   - -ENOTSUP - doesn't support get_info ops (valid case)."]
    pub fn rte_mempool_ops_get_info(
        mp: *const rte_mempool,
        info: *mut rte_mempool_info,
    ) -> ::std::os::raw::c_int;
}
extern "C" {
    #[doc = " @internal wrapper for mempool_ops free callback.\n\n @param mp\n   Pointer to the memory pool."]
    pub fn rte_mempool_ops_free(mp: *mut rte_mempool);
}
extern "C" {
    #[doc = " Set the ops of a mempool.\n\n This can only be done on a mempool that is not populated, i.e. just after\n a call to rte_mempool_create_empty().\n\n @param mp\n   Pointer to the memory pool.\n @param name\n   Name of the ops structure to use for this mempool.\n @param pool_config\n   Opaque data that can be passed by the application to the ops functions.\n @return\n   - 0: Success; the mempool is now using the requested ops functions.\n   - -EINVAL - Invalid ops struct name provided.\n   - -EEXIST - mempool already has an ops struct assigned."]
    pub fn rte_mempool_set_ops_byname(
        mp: *mut rte_mempool,
        name: *const ::std::os::raw::c_char,
        pool_config: *mut ::std::os::raw::c_void,
    ) -> ::std::os::raw::c_int;
}
extern "C" {
    #[doc = " Register mempool operations.\n\n @param ops\n   Pointer to an ops structure to register.\n @return\n   - >=0: Success; return the index of the ops struct in the table.\n   - -EINVAL - some missing callbacks while registering ops struct.\n   - -ENOSPC - the maximum number of ops structs has been reached."]
    pub fn rte_mempool_register_ops(ops: *const rte_mempool_ops) -> ::std::os::raw::c_int;
}
#[doc = " An object callback function for mempool.\n\n Used by rte_mempool_create() and rte_mempool_obj_iter()."]
pub type rte_mempool_obj_cb_t = ::std::option::Option<
    unsafe extern "C" fn(
        mp: *mut rte_mempool,
        opaque: *mut ::std::os::raw::c_void,
        obj: *mut ::std::os::raw::c_void,
        obj_idx: ::std::os::raw::c_uint,
    ),
>;
pub type rte_mempool_obj_ctor_t = rte_mempool_obj_cb_t;
#[doc = " A memory callback function for mempool.\n\n Used by rte_mempool_mem_iter()."]
pub type rte_mempool_mem_cb_t = ::std::option::Option<
    unsafe extern "C" fn(
        mp: *mut rte_mempool,
        opaque: *mut ::std::os::raw::c_void,
        memhdr: *mut rte_mempool_memhdr,
        mem_idx: ::std::os::raw::c_uint,
    ),
>;
#[doc = " A mempool constructor callback function.\n\n Arguments are the mempool and the opaque pointer given by the user in\n rte_mempool_create()."]
pub type rte_mempool_ctor_t = ::std::option::Option<
    unsafe extern "C" fn(arg1: *mut rte_mempool, arg2: *mut ::std::os::raw::c_void),
>;
extern "C" {
    #[doc = " Create a new mempool named *name* in memory.\n\n This function uses ``rte_memzone_reserve()`` to allocate memory. The\n pool contains n elements of elt_size. Its size is set to n.\n\n @param name\n   The name of the mempool.\n @param n\n   The number of elements in the mempool. The optimum size (in terms of\n   memory usage) for a mempool is when n is a power of two minus one:\n   n = (2^q - 1).\n @param elt_size\n   The size of each element.\n @param cache_size\n   If cache_size is non-zero, the rte_mempool library will try to\n   limit the accesses to the common lockless pool, by maintaining a\n   per-lcore object cache. This argument must be lower or equal to\n   RTE_MEMPOOL_CACHE_MAX_SIZE and n / 1.5. It is advised to choose\n   cache_size to have \"n modulo cache_size == 0\": if this is\n   not the case, some elements will always stay in the pool and will\n   never be used. The access to the per-lcore table is of course\n   faster than the multi-producer/consumer pool. The cache can be\n   disabled if the cache_size argument is set to 0; it can be useful to\n   avoid losing objects in cache.\n @param private_data_size\n   The size of the private data appended after the mempool\n   structure. This is useful for storing some private data after the\n   mempool structure, as is done for rte_mbuf_pool for example.\n @param mp_init\n   A function pointer that is called for initialization of the pool,\n   before object initialization. The user can initialize the private\n   data in this function if needed. This parameter can be NULL if\n   not needed.\n @param mp_init_arg\n   An opaque pointer to data that can be used in the mempool\n   constructor function.\n @param obj_init\n   A function pointer that is called for each object at\n   initialization of the pool. The user can set some meta data in\n   objects if needed. This parameter can be NULL if not needed.\n   The obj_init() function takes the mempool pointer, the init_arg,\n   the object pointer and the object number as parameters.\n @param obj_init_arg\n   An opaque pointer to data that can be used as an argument for\n   each call to the object constructor function.\n @param socket_id\n   The *socket_id* argument is the socket identifier in the case of\n   NUMA. The value can be *SOCKET_ID_ANY* if there is no NUMA\n   constraint for the reserved zone.\n @param flags\n   The *flags* arguments is an OR of following flags:\n   - RTE_MEMPOOL_F_NO_SPREAD: By default, objects addresses are spread\n     between channels in RAM: the pool allocator will add padding\n     between objects depending on the hardware configuration. See\n     Memory alignment constraints for details. If this flag is set,\n     the allocator will just align them to a cache line.\n   - RTE_MEMPOOL_F_NO_CACHE_ALIGN: By default, the returned objects are\n     cache-aligned. This flag removes this constraint, and no\n     padding will be present between objects. This flag implies\n     RTE_MEMPOOL_F_NO_SPREAD.\n   - RTE_MEMPOOL_F_SP_PUT: If this flag is set, the default behavior\n     when using rte_mempool_put() or rte_mempool_put_bulk() is\n     \"single-producer\". Otherwise, it is \"multi-producers\".\n   - RTE_MEMPOOL_F_SC_GET: If this flag is set, the default behavior\n     when using rte_mempool_get() or rte_mempool_get_bulk() is\n     \"single-consumer\". Otherwise, it is \"multi-consumers\".\n   - RTE_MEMPOOL_F_NO_IOVA_CONTIG: If set, allocated objects won't\n     necessarily be contiguous in IO memory.\n @return\n   The pointer to the new allocated mempool, on success. NULL on error\n   with rte_errno set appropriately. Possible rte_errno values include:\n    - E_RTE_NO_CONFIG - function could not get pointer to rte_config structure\n    - EINVAL - cache size provided is too large or an unknown flag was passed\n    - ENOSPC - the maximum number of memzones has already been allocated\n    - EEXIST - a memzone with the same name already exists\n    - ENOMEM - no appropriate memory area found in which to create memzone"]
    pub fn rte_mempool_create(
        name: *const ::std::os::raw::c_char,
        n: ::std::os::raw::c_uint,
        elt_size: ::std::os::raw::c_uint,
        cache_size: ::std::os::raw::c_uint,
        private_data_size: ::std::os::raw::c_uint,
        mp_init: rte_mempool_ctor_t,
        mp_init_arg: *mut ::std::os::raw::c_void,
        obj_init: rte_mempool_obj_cb_t,
        obj_init_arg: *mut ::std::os::raw::c_void,
        socket_id: ::std::os::raw::c_int,
        flags: ::std::os::raw::c_uint,
    ) -> *mut rte_mempool;
}
extern "C" {
    #[doc = " Create an empty mempool\n\n The mempool is allocated and initialized, but it is not populated: no\n memory is allocated for the mempool elements. The user has to call\n rte_mempool_populate_*() to add memory chunks to the pool. Once\n populated, the user may also want to initialize each object with\n rte_mempool_obj_iter().\n\n @param name\n   The name of the mempool.\n @param n\n   The maximum number of elements that can be added in the mempool.\n   The optimum size (in terms of memory usage) for a mempool is when n\n   is a power of two minus one: n = (2^q - 1).\n @param elt_size\n   The size of each element.\n @param cache_size\n   Size of the cache. See rte_mempool_create() for details.\n @param private_data_size\n   The size of the private data appended after the mempool\n   structure. This is useful for storing some private data after the\n   mempool structure, as is done for rte_mbuf_pool for example.\n @param socket_id\n   The *socket_id* argument is the socket identifier in the case of\n   NUMA. The value can be *SOCKET_ID_ANY* if there is no NUMA\n   constraint for the reserved zone.\n @param flags\n   Flags controlling the behavior of the mempool. See\n   rte_mempool_create() for details.\n @return\n   The pointer to the new allocated mempool, on success. NULL on error\n   with rte_errno set appropriately. See rte_mempool_create() for details."]
    pub fn rte_mempool_create_empty(
        name: *const ::std::os::raw::c_char,
        n: ::std::os::raw::c_uint,
        elt_size: ::std::os::raw::c_uint,
        cache_size: ::std::os::raw::c_uint,
        private_data_size: ::std::os::raw::c_uint,
        socket_id: ::std::os::raw::c_int,
        flags: ::std::os::raw::c_uint,
    ) -> *mut rte_mempool;
}
extern "C" {
    #[doc = " Free a mempool\n\n Unlink the mempool from global list, free the memory chunks, and all\n memory referenced by the mempool. The objects must not be used by\n other cores as they will be freed.\n\n @param mp\n   A pointer to the mempool structure.\n   If NULL then, the function does nothing."]
    pub fn rte_mempool_free(mp: *mut rte_mempool);
}
extern "C" {
    #[doc = " Add physically contiguous memory for objects in the pool at init\n\n Add a virtually and physically contiguous memory chunk in the pool\n where objects can be instantiated.\n\n If the given IO address is unknown (iova = RTE_BAD_IOVA),\n the chunk doesn't need to be physically contiguous (only virtually),\n and allocated objects may span two pages.\n\n @param mp\n   A pointer to the mempool structure.\n @param vaddr\n   The virtual address of memory that should be used to store objects.\n @param iova\n   The IO address\n @param len\n   The length of memory in bytes.\n @param free_cb\n   The callback used to free this chunk when destroying the mempool.\n @param opaque\n   An opaque argument passed to free_cb.\n @return\n   The number of objects added on success (strictly positive).\n   On error, the chunk is not added in the memory list of the\n   mempool the following code is returned:\n     (0): not enough room in chunk for one object.\n     (-ENOSPC): mempool is already populated.\n     (-ENOMEM): allocation failure."]
    pub fn rte_mempool_populate_iova(
        mp: *mut rte_mempool,
        vaddr: *mut ::std::os::raw::c_char,
        iova: rte_iova_t,
        len: usize,
        free_cb: rte_mempool_memchunk_free_cb_t,
        opaque: *mut ::std::os::raw::c_void,
    ) -> ::std::os::raw::c_int;
}
extern "C" {
    #[doc = " Add virtually contiguous memory for objects in the pool at init\n\n Add a virtually contiguous memory chunk in the pool where objects can\n be instantiated.\n\n @param mp\n   A pointer to the mempool structure.\n @param addr\n   The virtual address of memory that should be used to store objects.\n @param len\n   The length of memory in bytes.\n @param pg_sz\n   The size of memory pages in this virtual area.\n @param free_cb\n   The callback used to free this chunk when destroying the mempool.\n @param opaque\n   An opaque argument passed to free_cb.\n @return\n   The number of objects added on success (strictly positive).\n   On error, the chunk is not added in the memory list of the\n   mempool the following code is returned:\n     (0): not enough room in chunk for one object.\n     (-ENOSPC): mempool is already populated.\n     (-ENOMEM): allocation failure."]
    pub fn rte_mempool_populate_virt(
        mp: *mut rte_mempool,
        addr: *mut ::std::os::raw::c_char,
        len: usize,
        pg_sz: usize,
        free_cb: rte_mempool_memchunk_free_cb_t,
        opaque: *mut ::std::os::raw::c_void,
    ) -> ::std::os::raw::c_int;
}
extern "C" {
    #[doc = " Add memory for objects in the pool at init\n\n This is the default function used by rte_mempool_create() to populate\n the mempool. It adds memory allocated using rte_memzone_reserve().\n\n @param mp\n   A pointer to the mempool structure.\n @return\n   The number of objects added on success.\n   On error, the chunk is not added in the memory list of the\n   mempool and a negative errno is returned."]
    pub fn rte_mempool_populate_default(mp: *mut rte_mempool) -> ::std::os::raw::c_int;
}
extern "C" {
    #[doc = " Add memory from anonymous mapping for objects in the pool at init\n\n This function mmap an anonymous memory zone that is locked in\n memory to store the objects of the mempool.\n\n @param mp\n   A pointer to the mempool structure.\n @return\n   The number of objects added on success.\n   On error, 0 is returned, rte_errno is set, and the chunk is not added in\n   the memory list of the mempool."]
    pub fn rte_mempool_populate_anon(mp: *mut rte_mempool) -> ::std::os::raw::c_int;
}
extern "C" {
    #[doc = " Call a function for each mempool element\n\n Iterate across all objects attached to a rte_mempool and call the\n callback function on it.\n\n @param mp\n   A pointer to an initialized mempool.\n @param obj_cb\n   A function pointer that is called for each object.\n @param obj_cb_arg\n   An opaque pointer passed to the callback function.\n @return\n   Number of objects iterated."]
    pub fn rte_mempool_obj_iter(
        mp: *mut rte_mempool,
        obj_cb: rte_mempool_obj_cb_t,
        obj_cb_arg: *mut ::std::os::raw::c_void,
    ) -> u32;
}
extern "C" {
    #[doc = " Call a function for each mempool memory chunk\n\n Iterate across all memory chunks attached to a rte_mempool and call\n the callback function on it.\n\n @param mp\n   A pointer to an initialized mempool.\n @param mem_cb\n   A function pointer that is called for each memory chunk.\n @param mem_cb_arg\n   An opaque pointer passed to the callback function.\n @return\n   Number of memory chunks iterated."]
    pub fn rte_mempool_mem_iter(
        mp: *mut rte_mempool,
        mem_cb: rte_mempool_mem_cb_t,
        mem_cb_arg: *mut ::std::os::raw::c_void,
    ) -> u32;
}
extern "C" {
    #[doc = " Dump the status of the mempool to a file.\n\n @param f\n   A pointer to a file for output\n @param mp\n   A pointer to the mempool structure."]
    pub fn rte_mempool_dump(f: *mut FILE, mp: *mut rte_mempool);
}
extern "C" {
    #[doc = " Create a user-owned mempool cache.\n\n This can be used by unregistered non-EAL threads to enable caching when they\n interact with a mempool.\n\n @param size\n   The size of the mempool cache. See rte_mempool_create()'s cache_size\n   parameter description for more information. The same limits and\n   considerations apply here too.\n @param socket_id\n   The socket identifier in the case of NUMA. The value can be\n   SOCKET_ID_ANY if there is no NUMA constraint for the reserved zone."]
    pub fn rte_mempool_cache_create(
        size: u32,
        socket_id: ::std::os::raw::c_int,
    ) -> *mut rte_mempool_cache;
}
extern "C" {
    #[doc = " Free a user-owned mempool cache.\n\n @param cache\n   A pointer to the mempool cache."]
    pub fn rte_mempool_cache_free(cache: *mut rte_mempool_cache);
}
extern "C" {
    #[doc = " Return the number of entries in the mempool.\n\n When cache is enabled, this function has to browse the length of\n all lcores, so it should not be used in a data path, but only for\n debug purposes. User-owned mempool caches are not accounted for.\n\n @param mp\n   A pointer to the mempool structure.\n @return\n   The number of entries in the mempool."]
    pub fn rte_mempool_avail_count(mp: *const rte_mempool) -> ::std::os::raw::c_uint;
}
extern "C" {
    #[doc = " Return the number of elements which have been allocated from the mempool\n\n When cache is enabled, this function has to browse the length of\n all lcores, so it should not be used in a data path, but only for\n debug purposes.\n\n @param mp\n   A pointer to the mempool structure.\n @return\n   The number of free entries in the mempool."]
    pub fn rte_mempool_in_use_count(mp: *const rte_mempool) -> ::std::os::raw::c_uint;
}
extern "C" {
    #[doc = " Check the consistency of mempool objects.\n\n Verify the coherency of fields in the mempool structure. Also check\n that the cookies of mempool objects (even the ones that are not\n present in pool) have a correct value. If not, a panic will occur.\n\n @param mp\n   A pointer to the mempool structure."]
    pub fn rte_mempool_audit(mp: *mut rte_mempool);
}
extern "C" {
    #[doc = " Dump the status of all mempools on the console\n\n @param f\n   A pointer to a file for output"]
    pub fn rte_mempool_list_dump(f: *mut FILE);
}
extern "C" {
    #[doc = " Search a mempool from its name\n\n @param name\n   The name of the mempool.\n @return\n   The pointer to the mempool matching the name, or NULL if not found.\n   NULL on error\n   with rte_errno set appropriately. Possible rte_errno values include:\n    - ENOENT - required entry not available to return."]
    pub fn rte_mempool_lookup(name: *const ::std::os::raw::c_char) -> *mut rte_mempool;
}
extern "C" {
    #[doc = " Get the header, trailer and total size of a mempool element.\n\n Given a desired size of the mempool element and mempool flags,\n calculates header, trailer, body and total sizes of the mempool object.\n\n @param elt_size\n   The size of each element, without header and trailer.\n @param flags\n   The flags used for the mempool creation.\n   Consult rte_mempool_create() for more information about possible values.\n   The size of each element.\n @param sz\n   The calculated detailed size the mempool object. May be NULL.\n @return\n   Total size of the mempool object."]
    pub fn rte_mempool_calc_obj_size(elt_size: u32, flags: u32, sz: *mut rte_mempool_objsz) -> u32;
}
extern "C" {
    #[doc = " Walk list of all memory pools\n\n @param func\n   Iterator function\n @param arg\n   Argument passed to iterator"]
    pub fn rte_mempool_walk(
        func: ::std::option::Option<
            unsafe extern "C" fn(arg1: *mut rte_mempool, arg: *mut ::std::os::raw::c_void),
        >,
        arg: *mut ::std::os::raw::c_void,
    );
}
#[doc = " A structure used to retrieve information about the memory range\n of the mempool."]
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct rte_mempool_mem_range_info {
    #[doc = " Start of the memory range used by mempool objects"]
    pub start: *mut ::std::os::raw::c_void,
    #[doc = " Length of the memory range used by mempool objects"]
    pub length: usize,
    #[doc = " Are all memory addresses used by mempool objects contiguous"]
    pub is_contiguous: bool,
}
extern "C" {
    #[doc = " @warning\n @b EXPERIMENTAL: this API may change without prior notice.\n\n Get information about the memory range used to store objects in the mempool.\n\n @param[in] mp\n   Pointer to an initialized mempool.\n @param[out] mem_range\n   Pointer to struct which is used to return lowest address,\n   length of the memory range containing all the addresses,\n   and whether these addresses are contiguous.\n @return\n   0 on success, -EINVAL if mempool is not valid or mem_range is NULL."]
    pub fn rte_mempool_get_mem_range(
        mp: *const rte_mempool,
        mem_range: *mut rte_mempool_mem_range_info,
    ) -> ::std::os::raw::c_int;
}
extern "C" {
    #[doc = " @warning\n @b EXPERIMENTAL: this API may change without prior notice.\n\n Return alignment of objects stored in the mempool.\n\n @param[in] mp\n   Pointer to a mempool.\n @return\n   Object alignment if mp is valid. 0 if mp is NULL.\n"]
    pub fn rte_mempool_get_obj_alignment(mp: *const rte_mempool) -> usize;
}
extern "C" {
    #[doc = " @internal Get page size used for mempool object allocation.\n This function is internal to mempool library and mempool drivers."]
    pub fn rte_mempool_get_page_size(
        mp: *mut rte_mempool,
        pg_sz: *mut usize,
    ) -> ::std::os::raw::c_int;
}
#[doc = " Occurs after a mempool is fully populated."]
pub const rte_mempool_event_RTE_MEMPOOL_EVENT_READY: rte_mempool_event = 0;
#[doc = " Occurs before the destruction of a mempool begins."]
pub const rte_mempool_event_RTE_MEMPOOL_EVENT_DESTROY: rte_mempool_event = 1;
#[doc = " Mempool event type.\n @internal"]
pub type rte_mempool_event = ::std::os::raw::c_uint;
#[doc = " @internal\n Mempool event callback.\n\n rte_mempool_event_callback_register() may be called from within the callback,\n but the callbacks registered this way will not be invoked for the same event.\n rte_mempool_event_callback_unregister() may only be safely called\n to remove the running callback."]
pub type rte_mempool_event_callback = ::std::option::Option<
    unsafe extern "C" fn(
        event: rte_mempool_event,
        mp: *mut rte_mempool,
        user_data: *mut ::std::os::raw::c_void,
    ),
>;
extern "C" {
    #[doc = " @internal\n Register a callback function invoked on mempool life cycle event.\n The function will be invoked in the process\n that performs an action which triggers the callback.\n Registration is process-private,\n i.e. each process must manage callbacks on its own if needed.\n\n @param func\n   Callback function.\n @param user_data\n   User data.\n\n @return\n   0 on success, negative on failure and rte_errno is set."]
    pub fn rte_mempool_event_callback_register(
        func: rte_mempool_event_callback,
        user_data: *mut ::std::os::raw::c_void,
    ) -> ::std::os::raw::c_int;
}
extern "C" {
    #[doc = " @internal\n Unregister a callback added with rte_mempool_event_callback_register().\n @p func and @p user_data must exactly match registration parameters.\n\n @param func\n   Callback function.\n @param user_data\n   User data.\n\n @return\n   0 on success, negative on failure and rte_errno is set."]
    pub fn rte_mempool_event_callback_unregister(
        func: rte_mempool_event_callback,
        user_data: *mut ::std::os::raw::c_void,
    ) -> ::std::os::raw::c_int;
}
extern "C" {
    #[doc = " Get the name of the l2 packet type\n\n @param ptype\n   The packet type value.\n @return\n   A non-null string describing the packet type."]
    pub fn rte_get_ptype_l2_name(ptype: u32) -> *const ::std::os::raw::c_char;
}
extern "C" {
    #[doc = " Get the name of the l3 packet type\n\n @param ptype\n   The packet type value.\n @return\n   A non-null string describing the packet type."]
    pub fn rte_get_ptype_l3_name(ptype: u32) -> *const ::std::os::raw::c_char;
}
extern "C" {
    #[doc = " Get the name of the l4 packet type\n\n @param ptype\n   The packet type value.\n @return\n   A non-null string describing the packet type."]
    pub fn rte_get_ptype_l4_name(ptype: u32) -> *const ::std::os::raw::c_char;
}
extern "C" {
    #[doc = " Get the name of the tunnel packet type\n\n @param ptype\n   The packet type value.\n @return\n   A non-null string describing the packet type."]
    pub fn rte_get_ptype_tunnel_name(ptype: u32) -> *const ::std::os::raw::c_char;
}
extern "C" {
    #[doc = " Get the name of the inner_l2 packet type\n\n @param ptype\n   The packet type value.\n @return\n   A non-null string describing the packet type."]
    pub fn rte_get_ptype_inner_l2_name(ptype: u32) -> *const ::std::os::raw::c_char;
}
extern "C" {
    #[doc = " Get the name of the inner_l3 packet type\n\n @param ptype\n   The packet type value.\n @return\n   A non-null string describing the packet type."]
    pub fn rte_get_ptype_inner_l3_name(ptype: u32) -> *const ::std::os::raw::c_char;
}
extern "C" {
    #[doc = " Get the name of the inner_l4 packet type\n\n @param ptype\n   The packet type value.\n @return\n   A non-null string describing the packet type."]
    pub fn rte_get_ptype_inner_l4_name(ptype: u32) -> *const ::std::os::raw::c_char;
}
extern "C" {
    #[doc = " Write the packet type name into the buffer\n\n @param ptype\n   The packet type value.\n @param buf\n   The buffer where the string is written.\n @param buflen\n   The length of the buffer.\n @return\n   - 0 on success\n   - (-1) if the buffer is too small"]
    pub fn rte_get_ptype_name(
        ptype: u32,
        buf: *mut ::std::os::raw::c_char,
        buflen: usize,
    ) -> ::std::os::raw::c_int;
}
pub type rte_be16_t = u16;
pub type rte_be32_t = u32;
pub type rte_be64_t = u64;
pub type rte_le16_t = u16;
pub type rte_le32_t = u32;
pub type rte_le64_t = u64;
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct rte_mbuf_sched {
    #[doc = "< Queue ID."]
    pub queue_id: u32,
    pub traffic_class: u8,
    pub color: u8,
    #[doc = "< Reserved."]
    pub reserved: u16,
}
#[doc = " The generic rte_mbuf, containing a packet mbuf."]
#[repr(C)]
#[repr(align(64))]
#[derive(Copy, Clone)]
pub struct rte_mbuf {
    #[doc = "< Virtual address of segment buffer."]
    pub buf_addr: *mut ::std::os::raw::c_void,
    #[doc = " Physical address of segment buffer.\n This field is undefined if the build is configured to use only\n virtual address as IOVA (i.e. RTE_IOVA_IN_MBUF is 0).\n Force alignment to 8-bytes, so as to ensure we have the exact\n layout for the first cache line for 32-bit and 64-bit. This makes\n working on vector drivers easier."]
    pub buf_iova: rte_iova_t,
    pub __bindgen_anon_1: rte_mbuf__bindgen_ty_1,
    #[doc = "< Offload features."]
    pub ol_flags: u64,
    pub __bindgen_anon_2: rte_mbuf__bindgen_ty_2,
    #[doc = "< Pool from which mbuf was allocated."]
    pub pool: *mut rte_mempool,
    #[doc = " Next segment of scattered packet. Must be NULL in the last\n segment or in case of non-segmented packet."]
    pub next: *mut rte_mbuf,
    pub __bindgen_anon_3: rte_mbuf__bindgen_ty_3,
    #[doc = " Shared data for external buffer attached to mbuf. See\n rte_pktmbuf_attach_extbuf()."]
    pub shinfo: *mut rte_mbuf_ext_shared_info,
    #[doc = " Size of the application private data. In case of an indirect\n mbuf, it stores the direct mbuf private data size."]
    pub priv_size: u16,
    #[doc = " Timesync flags for use with IEEE1588."]
    pub timesync: u16,
    #[doc = "< Reserved for dynamic fields."]
    pub dynfield1: [u32; 9usize],
}
#[repr(C)]
#[derive(Copy, Clone)]
pub union rte_mbuf__bindgen_ty_1 {
    pub rearm_data: [u64; 1usize],
    pub __bindgen_anon_1: rte_mbuf__bindgen_ty_1__bindgen_ty_1,
}
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct rte_mbuf__bindgen_ty_1__bindgen_ty_1 {
    pub data_off: u16,
    #[doc = " Reference counter. Its size should at least equal to the size\n of port field (16 bits), to support zero-copy broadcast.\n It should only be accessed using the following functions:\n rte_mbuf_refcnt_update(), rte_mbuf_refcnt_read(), and\n rte_mbuf_refcnt_set(). The functionality of these functions (atomic,\n or non-atomic) is controlled by the RTE_MBUF_REFCNT_ATOMIC flag."]
    pub refcnt: u16,
    #[doc = " Number of segments. Only valid for the first segment of an mbuf\n chain."]
    pub nb_segs: u16,
    #[doc = " Input port (16 bits to support more than 256 virtual ports).\n The event eth Tx adapter uses this field to specify the output port."]
    pub port: u16,
}
#[repr(C)]
#[derive(Copy, Clone)]
pub union rte_mbuf__bindgen_ty_2 {
    pub rx_descriptor_fields1: [*mut ::std::os::raw::c_void; 3usize],
    pub __bindgen_anon_1: rte_mbuf__bindgen_ty_2__bindgen_ty_1,
}
#[repr(C)]
#[derive(Copy, Clone)]
pub struct rte_mbuf__bindgen_ty_2__bindgen_ty_1 {
    pub __bindgen_anon_1: rte_mbuf__bindgen_ty_2__bindgen_ty_1__bindgen_ty_1,
    #[doc = "< Total pkt len: sum of all segments."]
    pub pkt_len: u32,
    #[doc = "< Amount of data in segment buffer."]
    pub data_len: u16,
    #[doc = " VLAN TCI (CPU order), valid if RTE_MBUF_F_RX_VLAN is set."]
    pub vlan_tci: u16,
    pub __bindgen_anon_2: rte_mbuf__bindgen_ty_2__bindgen_ty_1__bindgen_ty_2,
    #[doc = " Outer VLAN TCI (CPU order), valid if RTE_MBUF_F_RX_QINQ is set."]
    pub vlan_tci_outer: u16,
    #[doc = "< Length of segment buffer."]
    pub buf_len: u16,
}
#[repr(C)]
#[derive(Copy, Clone)]
pub union rte_mbuf__bindgen_ty_2__bindgen_ty_1__bindgen_ty_1 {
    #[doc = "< L2/L3/L4 and tunnel information."]
    pub packet_type: u32,
    pub __bindgen_anon_1: rte_mbuf__bindgen_ty_2__bindgen_ty_1__bindgen_ty_1__bindgen_ty_1,
}
#[repr(C)]
#[derive(Copy, Clone)]
pub struct rte_mbuf__bindgen_ty_2__bindgen_ty_1__bindgen_ty_1__bindgen_ty_1 {
    pub _bitfield_align_1: [u8; 0],
    pub _bitfield_1: __BindgenBitfieldUnit<[u8; 2usize]>,
    pub __bindgen_anon_1:
        rte_mbuf__bindgen_ty_2__bindgen_ty_1__bindgen_ty_1__bindgen_ty_1__bindgen_ty_1,
    pub _bitfield_align_2: [u8; 0],
    pub _bitfield_2: __BindgenBitfieldUnit<[u8; 1usize]>,
}
#[repr(C)]
#[derive(Copy, Clone)]
pub union rte_mbuf__bindgen_ty_2__bindgen_ty_1__bindgen_ty_1__bindgen_ty_1__bindgen_ty_1 { pub inner_esp_next_proto : u8 , pub __bindgen_anon_1 : rte_mbuf__bindgen_ty_2__bindgen_ty_1__bindgen_ty_1__bindgen_ty_1__bindgen_ty_1__bindgen_ty_1 , }
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct rte_mbuf__bindgen_ty_2__bindgen_ty_1__bindgen_ty_1__bindgen_ty_1__bindgen_ty_1__bindgen_ty_1
{
    pub _bitfield_align_1: [u8; 0],
    pub _bitfield_1: __BindgenBitfieldUnit<[u8; 1usize]>,
}
impl rte_mbuf__bindgen_ty_2__bindgen_ty_1__bindgen_ty_1__bindgen_ty_1__bindgen_ty_1__bindgen_ty_1 {
    #[inline]
    pub fn inner_l2_type(&self) -> u8 {
        unsafe { ::std::mem::transmute(self._bitfield_1.get(0usize, 4u8) as u8) }
    }
    #[inline]
    pub fn set_inner_l2_type(&mut self, val: u8) {
        unsafe {
            let val: u8 = ::std::mem::transmute(val);
            self._bitfield_1.set(0usize, 4u8, val as u64)
        }
    }
    #[inline]
    pub fn inner_l3_type(&self) -> u8 {
        unsafe { ::std::mem::transmute(self._bitfield_1.get(4usize, 4u8) as u8) }
    }
    #[inline]
    pub fn set_inner_l3_type(&mut self, val: u8) {
        unsafe {
            let val: u8 = ::std::mem::transmute(val);
            self._bitfield_1.set(4usize, 4u8, val as u64)
        }
    }
    #[inline]
    pub fn new_bitfield_1(
        inner_l2_type: u8,
        inner_l3_type: u8,
    ) -> __BindgenBitfieldUnit<[u8; 1usize]> {
        let mut __bindgen_bitfield_unit: __BindgenBitfieldUnit<[u8; 1usize]> = Default::default();
        __bindgen_bitfield_unit.set(0usize, 4u8, {
            let inner_l2_type: u8 = unsafe { ::std::mem::transmute(inner_l2_type) };
            inner_l2_type as u64
        });
        __bindgen_bitfield_unit.set(4usize, 4u8, {
            let inner_l3_type: u8 = unsafe { ::std::mem::transmute(inner_l3_type) };
            inner_l3_type as u64
        });
        __bindgen_bitfield_unit
    }
}
impl rte_mbuf__bindgen_ty_2__bindgen_ty_1__bindgen_ty_1__bindgen_ty_1 {
    #[inline]
    pub fn l2_type(&self) -> u8 {
        unsafe { ::std::mem::transmute(self._bitfield_1.get(0usize, 4u8) as u8) }
    }
    #[inline]
    pub fn set_l2_type(&mut self, val: u8) {
        unsafe {
            let val: u8 = ::std::mem::transmute(val);
            self._bitfield_1.set(0usize, 4u8, val as u64)
        }
    }
    #[inline]
    pub fn l3_type(&self) -> u8 {
        unsafe { ::std::mem::transmute(self._bitfield_1.get(4usize, 4u8) as u8) }
    }
    #[inline]
    pub fn set_l3_type(&mut self, val: u8) {
        unsafe {
            let val: u8 = ::std::mem::transmute(val);
            self._bitfield_1.set(4usize, 4u8, val as u64)
        }
    }
    #[inline]
    pub fn l4_type(&self) -> u8 {
        unsafe { ::std::mem::transmute(self._bitfield_1.get(8usize, 4u8) as u8) }
    }
    #[inline]
    pub fn set_l4_type(&mut self, val: u8) {
        unsafe {
            let val: u8 = ::std::mem::transmute(val);
            self._bitfield_1.set(8usize, 4u8, val as u64)
        }
    }
    #[inline]
    pub fn tun_type(&self) -> u8 {
        unsafe { ::std::mem::transmute(self._bitfield_1.get(12usize, 4u8) as u8) }
    }
    #[inline]
    pub fn set_tun_type(&mut self, val: u8) {
        unsafe {
            let val: u8 = ::std::mem::transmute(val);
            self._bitfield_1.set(12usize, 4u8, val as u64)
        }
    }
    #[inline]
    pub fn new_bitfield_1(
        l2_type: u8,
        l3_type: u8,
        l4_type: u8,
        tun_type: u8,
    ) -> __BindgenBitfieldUnit<[u8; 2usize]> {
        let mut __bindgen_bitfield_unit: __BindgenBitfieldUnit<[u8; 2usize]> = Default::default();
        __bindgen_bitfield_unit.set(0usize, 4u8, {
            let l2_type: u8 = unsafe { ::std::mem::transmute(l2_type) };
            l2_type as u64
        });
        __bindgen_bitfield_unit.set(4usize, 4u8, {
            let l3_type: u8 = unsafe { ::std::mem::transmute(l3_type) };
            l3_type as u64
        });
        __bindgen_bitfield_unit.set(8usize, 4u8, {
            let l4_type: u8 = unsafe { ::std::mem::transmute(l4_type) };
            l4_type as u64
        });
        __bindgen_bitfield_unit.set(12usize, 4u8, {
            let tun_type: u8 = unsafe { ::std::mem::transmute(tun_type) };
            tun_type as u64
        });
        __bindgen_bitfield_unit
    }
    #[inline]
    pub fn inner_l4_type(&self) -> u8 {
        unsafe { ::std::mem::transmute(self._bitfield_2.get(0usize, 4u8) as u8) }
    }
    #[inline]
    pub fn set_inner_l4_type(&mut self, val: u8) {
        unsafe {
            let val: u8 = ::std::mem::transmute(val);
            self._bitfield_2.set(0usize, 4u8, val as u64)
        }
    }
    #[inline]
    pub fn new_bitfield_2(inner_l4_type: u8) -> __BindgenBitfieldUnit<[u8; 1usize]> {
        let mut __bindgen_bitfield_unit: __BindgenBitfieldUnit<[u8; 1usize]> = Default::default();
        __bindgen_bitfield_unit.set(0usize, 4u8, {
            let inner_l4_type: u8 = unsafe { ::std::mem::transmute(inner_l4_type) };
            inner_l4_type as u64
        });
        __bindgen_bitfield_unit
    }
}
#[repr(C)]
#[derive(Copy, Clone)]
pub union rte_mbuf__bindgen_ty_2__bindgen_ty_1__bindgen_ty_2 {
    #[doc = "< hash information"]
    pub hash: rte_mbuf__bindgen_ty_2__bindgen_ty_1__bindgen_ty_2__bindgen_ty_1,
}
#[repr(C)]
#[derive(Copy, Clone)]
pub union rte_mbuf__bindgen_ty_2__bindgen_ty_1__bindgen_ty_2__bindgen_ty_1 {
    #[doc = "< RSS hash result if RSS enabled"]
    pub rss: u32,
    #[doc = "< Filter identifier if FDIR enabled"]
    pub fdir: rte_mbuf__bindgen_ty_2__bindgen_ty_1__bindgen_ty_2__bindgen_ty_1__bindgen_ty_1,
    pub sched: rte_mbuf_sched,
    #[doc = "< Eventdev ethdev Tx adapter"]
    pub txadapter: rte_mbuf__bindgen_ty_2__bindgen_ty_1__bindgen_ty_2__bindgen_ty_1__bindgen_ty_2,
    pub usr: u32,
}
#[repr(C)]
#[derive(Copy, Clone)]
pub struct rte_mbuf__bindgen_ty_2__bindgen_ty_1__bindgen_ty_2__bindgen_ty_1__bindgen_ty_1 { pub __bindgen_anon_1 : rte_mbuf__bindgen_ty_2__bindgen_ty_1__bindgen_ty_2__bindgen_ty_1__bindgen_ty_1__bindgen_ty_1 , pub hi : u32 , }
#[repr(C)]
#[derive(Copy, Clone)]
pub union rte_mbuf__bindgen_ty_2__bindgen_ty_1__bindgen_ty_2__bindgen_ty_1__bindgen_ty_1__bindgen_ty_1 { pub __bindgen_anon_1 : rte_mbuf__bindgen_ty_2__bindgen_ty_1__bindgen_ty_2__bindgen_ty_1__bindgen_ty_1__bindgen_ty_1__bindgen_ty_1 , pub lo : u32 , }
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct rte_mbuf__bindgen_ty_2__bindgen_ty_1__bindgen_ty_2__bindgen_ty_1__bindgen_ty_1__bindgen_ty_1__bindgen_ty_1
{
    pub hash: u16,
    pub id: u16,
}
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct rte_mbuf__bindgen_ty_2__bindgen_ty_1__bindgen_ty_2__bindgen_ty_1__bindgen_ty_2 {
    pub reserved1: u32,
    pub reserved2: u16,
    pub txq: u16,
}
#[repr(C)]
#[derive(Copy, Clone)]
pub union rte_mbuf__bindgen_ty_3 {
    #[doc = "< combined for easy fetch"]
    pub tx_offload: u64,
    pub __bindgen_anon_1: rte_mbuf__bindgen_ty_3__bindgen_ty_1,
}
#[repr(C)]
#[repr(align(8))]
#[derive(Debug, Copy, Clone)]
pub struct rte_mbuf__bindgen_ty_3__bindgen_ty_1 {
    pub _bitfield_align_1: [u16; 0],
    pub _bitfield_1: __BindgenBitfieldUnit<[u8; 7usize]>,
}
impl rte_mbuf__bindgen_ty_3__bindgen_ty_1 {
    #[inline]
    pub fn l2_len(&self) -> u64 {
        unsafe { ::std::mem::transmute(self._bitfield_1.get(0usize, 7u8) as u64) }
    }
    #[inline]
    pub fn set_l2_len(&mut self, val: u64) {
        unsafe {
            let val: u64 = ::std::mem::transmute(val);
            self._bitfield_1.set(0usize, 7u8, val as u64)
        }
    }
    #[inline]
    pub fn l3_len(&self) -> u64 {
        unsafe { ::std::mem::transmute(self._bitfield_1.get(7usize, 9u8) as u64) }
    }
    #[inline]
    pub fn set_l3_len(&mut self, val: u64) {
        unsafe {
            let val: u64 = ::std::mem::transmute(val);
            self._bitfield_1.set(7usize, 9u8, val as u64)
        }
    }
    #[inline]
    pub fn l4_len(&self) -> u64 {
        unsafe { ::std::mem::transmute(self._bitfield_1.get(16usize, 8u8) as u64) }
    }
    #[inline]
    pub fn set_l4_len(&mut self, val: u64) {
        unsafe {
            let val: u64 = ::std::mem::transmute(val);
            self._bitfield_1.set(16usize, 8u8, val as u64)
        }
    }
    #[inline]
    pub fn tso_segsz(&self) -> u64 {
        unsafe { ::std::mem::transmute(self._bitfield_1.get(24usize, 16u8) as u64) }
    }
    #[inline]
    pub fn set_tso_segsz(&mut self, val: u64) {
        unsafe {
            let val: u64 = ::std::mem::transmute(val);
            self._bitfield_1.set(24usize, 16u8, val as u64)
        }
    }
    #[inline]
    pub fn outer_l3_len(&self) -> u64 {
        unsafe { ::std::mem::transmute(self._bitfield_1.get(40usize, 9u8) as u64) }
    }
    #[inline]
    pub fn set_outer_l3_len(&mut self, val: u64) {
        unsafe {
            let val: u64 = ::std::mem::transmute(val);
            self._bitfield_1.set(40usize, 9u8, val as u64)
        }
    }
    #[inline]
    pub fn outer_l2_len(&self) -> u64 {
        unsafe { ::std::mem::transmute(self._bitfield_1.get(49usize, 7u8) as u64) }
    }
    #[inline]
    pub fn set_outer_l2_len(&mut self, val: u64) {
        unsafe {
            let val: u64 = ::std::mem::transmute(val);
            self._bitfield_1.set(49usize, 7u8, val as u64)
        }
    }
    #[inline]
    pub fn new_bitfield_1(
        l2_len: u64,
        l3_len: u64,
        l4_len: u64,
        tso_segsz: u64,
        outer_l3_len: u64,
        outer_l2_len: u64,
    ) -> __BindgenBitfieldUnit<[u8; 7usize]> {
        let mut __bindgen_bitfield_unit: __BindgenBitfieldUnit<[u8; 7usize]> = Default::default();
        __bindgen_bitfield_unit.set(0usize, 7u8, {
            let l2_len: u64 = unsafe { ::std::mem::transmute(l2_len) };
            l2_len as u64
        });
        __bindgen_bitfield_unit.set(7usize, 9u8, {
            let l3_len: u64 = unsafe { ::std::mem::transmute(l3_len) };
            l3_len as u64
        });
        __bindgen_bitfield_unit.set(16usize, 8u8, {
            let l4_len: u64 = unsafe { ::std::mem::transmute(l4_len) };
            l4_len as u64
        });
        __bindgen_bitfield_unit.set(24usize, 16u8, {
            let tso_segsz: u64 = unsafe { ::std::mem::transmute(tso_segsz) };
            tso_segsz as u64
        });
        __bindgen_bitfield_unit.set(40usize, 9u8, {
            let outer_l3_len: u64 = unsafe { ::std::mem::transmute(outer_l3_len) };
            outer_l3_len as u64
        });
        __bindgen_bitfield_unit.set(49usize, 7u8, {
            let outer_l2_len: u64 = unsafe { ::std::mem::transmute(outer_l2_len) };
            outer_l2_len as u64
        });
        __bindgen_bitfield_unit
    }
}
#[doc = " Function typedef of callback to free externally attached buffer."]
pub type rte_mbuf_extbuf_free_callback_t = ::std::option::Option<
    unsafe extern "C" fn(addr: *mut ::std::os::raw::c_void, opaque: *mut ::std::os::raw::c_void),
>;
#[doc = " Shared data at the end of an external buffer."]
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct rte_mbuf_ext_shared_info {
    #[doc = "< Free callback function"]
    pub free_cb: rte_mbuf_extbuf_free_callback_t,
    #[doc = "< Free callback argument"]
    pub fcb_opaque: *mut ::std::os::raw::c_void,
    pub refcnt: u16,
}
extern "C" {
    #[doc = " Get the name of a RX offload flag\n\n @param mask\n   The mask describing the flag.\n @return\n   The name of this flag, or NULL if it's not a valid RX flag."]
    pub fn rte_get_rx_ol_flag_name(mask: u64) -> *const ::std::os::raw::c_char;
}
extern "C" {
    #[doc = " Dump the list of RX offload flags in a buffer\n\n @param mask\n   The mask describing the RX flags.\n @param buf\n   The output buffer.\n @param buflen\n   The length of the buffer.\n @return\n   0 on success, (-1) on error."]
    pub fn rte_get_rx_ol_flag_list(
        mask: u64,
        buf: *mut ::std::os::raw::c_char,
        buflen: usize,
    ) -> ::std::os::raw::c_int;
}
extern "C" {
    #[doc = " Get the name of a TX offload flag\n\n @param mask\n   The mask describing the flag. Usually only one bit must be set.\n   Several bits can be given if they belong to the same mask.\n   Ex: RTE_MBUF_F_TX_L4_MASK.\n @return\n   The name of this flag, or NULL if it's not a valid TX flag."]
    pub fn rte_get_tx_ol_flag_name(mask: u64) -> *const ::std::os::raw::c_char;
}
extern "C" {
    #[doc = " Dump the list of TX offload flags in a buffer\n\n @param mask\n   The mask describing the TX flags.\n @param buf\n   The output buffer.\n @param buflen\n   The length of the buffer.\n @return\n   0 on success, (-1) on error."]
    pub fn rte_get_tx_ol_flag_list(
        mask: u64,
        buf: *mut ::std::os::raw::c_char,
        buflen: usize,
    ) -> ::std::os::raw::c_int;
}
#[doc = " Private data in case of pktmbuf pool.\n\n A structure that contains some pktmbuf_pool-specific data that are\n appended after the mempool structure (in private data)."]
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct rte_pktmbuf_pool_private {
    #[doc = "< Size of data space in each mbuf."]
    pub mbuf_data_room_size: u16,
    #[doc = "< Size of private area in each mbuf."]
    pub mbuf_priv_size: u16,
    #[doc = "< reserved for future use."]
    pub flags: u32,
}
extern "C" {
    #[doc = " Sanity checks on an mbuf.\n\n Check the consistency of the given mbuf. The function will cause a\n panic if corruption is detected.\n\n @param m\n   The mbuf to be checked.\n @param is_header\n   True if the mbuf is a packet header, false if it is a sub-segment\n   of a packet (in this case, some fields like nb_segs are not checked)"]
    pub fn rte_mbuf_sanity_check(m: *const rte_mbuf, is_header: ::std::os::raw::c_int);
}
extern "C" {
    #[doc = " Sanity checks on a mbuf.\n\n Almost like rte_mbuf_sanity_check(), but this function gives the reason\n if corruption is detected rather than panic.\n\n @param m\n   The mbuf to be checked.\n @param is_header\n   True if the mbuf is a packet header, false if it is a sub-segment\n   of a packet (in this case, some fields like nb_segs are not checked)\n @param reason\n   A reference to a string pointer where to store the reason why a mbuf is\n   considered invalid.\n @return\n   - 0 if no issue has been found, reason is left untouched.\n   - -1 if a problem is detected, reason then points to a string describing\n     the reason why the mbuf is deemed invalid."]
    pub fn rte_mbuf_check(
        m: *const rte_mbuf,
        is_header: ::std::os::raw::c_int,
        reason: *mut *const ::std::os::raw::c_char,
    ) -> ::std::os::raw::c_int;
}
extern "C" {
    #[doc = " The packet mbuf constructor.\n\n This function initializes some fields in the mbuf structure that are\n not modified by the user once created (origin pool, buffer start\n address, and so on). This function is given as a callback function to\n rte_mempool_obj_iter() or rte_mempool_create() at pool creation time.\n\n This function expects that the mempool private area was previously\n initialized with rte_pktmbuf_pool_init().\n\n @param mp\n   The mempool from which mbufs originate.\n @param opaque_arg\n   A pointer that can be used by the user to retrieve useful information\n   for mbuf initialization. This pointer is the opaque argument passed to\n   rte_mempool_obj_iter() or rte_mempool_create().\n @param m\n   The mbuf to initialize.\n @param i\n   The index of the mbuf in the pool table."]
    pub fn rte_pktmbuf_init(
        mp: *mut rte_mempool,
        opaque_arg: *mut ::std::os::raw::c_void,
        m: *mut ::std::os::raw::c_void,
        i: ::std::os::raw::c_uint,
    );
}
extern "C" {
    #[doc = " A packet mbuf pool constructor.\n\n This function initializes the mempool private data in the case of a\n pktmbuf pool. This private data is needed by the driver. The\n function must be called on the mempool before it is used, or it\n can be given as a callback function to rte_mempool_create() at\n pool creation. It can be extended by the user, for example, to\n provide another packet size.\n\n The mempool private area size must be at least equal to\n sizeof(struct rte_pktmbuf_pool_private).\n\n @param mp\n   The mempool from which mbufs originate.\n @param opaque_arg\n   A pointer that can be used by the user to retrieve useful information\n   for mbuf initialization. This pointer is the opaque argument passed to\n   rte_mempool_create()."]
    pub fn rte_pktmbuf_pool_init(mp: *mut rte_mempool, opaque_arg: *mut ::std::os::raw::c_void);
}
extern "C" {
    #[doc = " Create a mbuf pool.\n\n This function creates and initializes a packet mbuf pool. It is\n a wrapper to rte_mempool functions.\n\n @param name\n   The name of the mbuf pool.\n @param n\n   The number of elements in the mbuf pool. The optimum size (in terms\n   of memory usage) for a mempool is when n is a power of two minus one:\n   n = (2^q - 1).\n @param cache_size\n   Size of the per-core object cache. See rte_mempool_create() for\n   details.\n @param priv_size\n   Size of application private are between the rte_mbuf structure\n   and the data buffer. This value must be aligned to RTE_MBUF_PRIV_ALIGN.\n @param data_room_size\n   Size of data buffer in each mbuf, including RTE_PKTMBUF_HEADROOM.\n @param socket_id\n   The socket identifier where the memory should be allocated. The\n   value can be *SOCKET_ID_ANY* if there is no NUMA constraint for the\n   reserved zone.\n @return\n   The pointer to the new allocated mempool, on success. NULL on error\n   with rte_errno set appropriately. Possible rte_errno values include:\n    - E_RTE_NO_CONFIG - function could not get pointer to rte_config structure\n    - EINVAL - cache size provided is too large, or priv_size is not aligned.\n    - ENOSPC - the maximum number of memzones has already been allocated\n    - EEXIST - a memzone with the same name already exists\n    - ENOMEM - no appropriate memory area found in which to create memzone"]
    pub fn rte_pktmbuf_pool_create(
        name: *const ::std::os::raw::c_char,
        n: ::std::os::raw::c_uint,
        cache_size: ::std::os::raw::c_uint,
        priv_size: u16,
        data_room_size: u16,
        socket_id: ::std::os::raw::c_int,
    ) -> *mut rte_mempool;
}
extern "C" {
    #[doc = " Create a mbuf pool with a given mempool ops name\n\n This function creates and initializes a packet mbuf pool. It is\n a wrapper to rte_mempool functions.\n\n @param name\n   The name of the mbuf pool.\n @param n\n   The number of elements in the mbuf pool. The optimum size (in terms\n   of memory usage) for a mempool is when n is a power of two minus one:\n   n = (2^q - 1).\n @param cache_size\n   Size of the per-core object cache. See rte_mempool_create() for\n   details.\n @param priv_size\n   Size of application private are between the rte_mbuf structure\n   and the data buffer. This value must be aligned to RTE_MBUF_PRIV_ALIGN.\n @param data_room_size\n   Size of data buffer in each mbuf, including RTE_PKTMBUF_HEADROOM.\n @param socket_id\n   The socket identifier where the memory should be allocated. The\n   value can be *SOCKET_ID_ANY* if there is no NUMA constraint for the\n   reserved zone.\n @param ops_name\n   The mempool ops name to be used for this mempool instead of\n   default mempool. The value can be *NULL* to use default mempool.\n @return\n   The pointer to the new allocated mempool, on success. NULL on error\n   with rte_errno set appropriately. Possible rte_errno values include:\n    - E_RTE_NO_CONFIG - function could not get pointer to rte_config structure\n    - EINVAL - cache size provided is too large, or priv_size is not aligned.\n    - ENOSPC - the maximum number of memzones has already been allocated\n    - EEXIST - a memzone with the same name already exists\n    - ENOMEM - no appropriate memory area found in which to create memzone"]
    pub fn rte_pktmbuf_pool_create_by_ops(
        name: *const ::std::os::raw::c_char,
        n: ::std::os::raw::c_uint,
        cache_size: ::std::os::raw::c_uint,
        priv_size: u16,
        data_room_size: u16,
        socket_id: ::std::os::raw::c_int,
        ops_name: *const ::std::os::raw::c_char,
    ) -> *mut rte_mempool;
}
#[doc = " A structure that describes the pinned external buffer segment."]
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct rte_pktmbuf_extmem {
    #[doc = "< The virtual address of data buffer."]
    pub buf_ptr: *mut ::std::os::raw::c_void,
    #[doc = "< The IO address of the data buffer."]
    pub buf_iova: rte_iova_t,
    #[doc = "< External buffer length in bytes."]
    pub buf_len: usize,
    #[doc = "< mbuf element size in bytes."]
    pub elt_size: u16,
}
extern "C" {
    #[doc = " Create a mbuf pool with external pinned data buffers.\n\n This function creates and initializes a packet mbuf pool that contains\n only mbufs with external buffer. It is a wrapper to rte_mempool functions.\n\n @param name\n   The name of the mbuf pool.\n @param n\n   The number of elements in the mbuf pool. The optimum size (in terms\n   of memory usage) for a mempool is when n is a power of two minus one:\n   n = (2^q - 1).\n @param cache_size\n   Size of the per-core object cache. See rte_mempool_create() for\n   details.\n @param priv_size\n   Size of application private are between the rte_mbuf structure\n   and the data buffer. This value must be aligned to RTE_MBUF_PRIV_ALIGN.\n @param data_room_size\n   Size of data buffer in each mbuf, including RTE_PKTMBUF_HEADROOM.\n @param socket_id\n   The socket identifier where the memory should be allocated. The\n   value can be *SOCKET_ID_ANY* if there is no NUMA constraint for the\n   reserved zone.\n @param ext_mem\n   Pointer to the array of structures describing the external memory\n   for data buffers. It is caller responsibility to register this memory\n   with rte_extmem_register() (if needed), map this memory to appropriate\n   physical device, etc.\n @param ext_num\n   Number of elements in the ext_mem array.\n @return\n   The pointer to the new allocated mempool, on success. NULL on error\n   with rte_errno set appropriately. Possible rte_errno values include:\n    - E_RTE_NO_CONFIG - function could not get pointer to rte_config structure\n    - EINVAL - cache size provided is too large, or priv_size is not aligned.\n    - ENOSPC - the maximum number of memzones has already been allocated\n    - EEXIST - a memzone with the same name already exists\n    - ENOMEM - no appropriate memory area found in which to create memzone"]
    pub fn rte_pktmbuf_pool_create_extbuf(
        name: *const ::std::os::raw::c_char,
        n: ::std::os::raw::c_uint,
        cache_size: ::std::os::raw::c_uint,
        priv_size: u16,
        data_room_size: u16,
        socket_id: ::std::os::raw::c_int,
        ext_mem: *const rte_pktmbuf_extmem,
        ext_num: ::std::os::raw::c_uint,
    ) -> *mut rte_mempool;
}
extern "C" {
    #[doc = " Free a bulk of packet mbufs back into their original mempools.\n\n Free a bulk of mbufs, and all their segments in case of chained buffers.\n Each segment is added back into its original mempool.\n\n  @param mbufs\n    Array of pointers to packet mbufs.\n    The array may contain NULL pointers.\n  @param count\n    Array size."]
    pub fn rte_pktmbuf_free_bulk(mbufs: *mut *mut rte_mbuf, count: ::std::os::raw::c_uint);
}
extern "C" {
    #[doc = " Create a \"clone\" of the given packet mbuf.\n\n Walks through all segments of the given packet mbuf, and for each of them:\n  - Creates a new packet mbuf from the given pool.\n  - Attaches newly created mbuf to the segment.\n Then updates pkt_len and nb_segs of the \"clone\" packet mbuf to match values\n from the original packet mbuf.\n\n @param md\n   The packet mbuf to be cloned.\n @param mp\n   The mempool from which the \"clone\" mbufs are allocated.\n @return\n   - The pointer to the new \"clone\" mbuf on success.\n   - NULL if allocation fails."]
    pub fn rte_pktmbuf_clone(md: *mut rte_mbuf, mp: *mut rte_mempool) -> *mut rte_mbuf;
}
extern "C" {
    #[doc = " Create a full copy of a given packet mbuf.\n\n Copies all the data from a given packet mbuf to a newly allocated\n set of mbufs. The private data are is not copied.\n\n @param m\n   The packet mbuf to be copied.\n @param mp\n   The mempool from which the \"clone\" mbufs are allocated.\n @param offset\n   The number of bytes to skip before copying.\n   If the mbuf does not have that many bytes, it is an error\n   and NULL is returned.\n @param length\n   The upper limit on bytes to copy.  Passing UINT32_MAX\n   means all data (after offset).\n @return\n   - The pointer to the new \"clone\" mbuf on success.\n   - NULL if allocation fails."]
    pub fn rte_pktmbuf_copy(
        m: *const rte_mbuf,
        mp: *mut rte_mempool,
        offset: u32,
        length: u32,
    ) -> *mut rte_mbuf;
}
extern "C" {
    #[doc = " Dump an mbuf structure to a file.\n\n Dump all fields for the given packet mbuf and all its associated\n segments (in the case of a chained buffer).\n\n @param f\n   A pointer to a file for output\n @param m\n   The packet mbuf.\n @param dump_len\n   If dump_len != 0, also dump the \"dump_len\" first data bytes of\n   the packet."]
    pub fn rte_pktmbuf_dump(f: *mut FILE, m: *const rte_mbuf, dump_len: ::std::os::raw::c_uint);
}
#[doc = " Ethernet address:\n A universally administered address is uniquely assigned to a device by its\n manufacturer. The first three octets (in transmission order) contain the\n Organizationally Unique Identifier (OUI). The following three (MAC-48 and\n EUI-48) octets are assigned by that organization with the only constraint\n of uniqueness.\n A locally administered address is assigned to a device by a network\n administrator and does not contain OUIs.\n See http://standards.ieee.org/regauth/groupmac/tutorial.html"]
#[repr(C)]
#[repr(align(2))]
#[derive(Debug, Copy, Clone)]
pub struct rte_ether_addr {
    #[doc = "< Addr bytes in tx order"]
    pub addr_bytes: [u8; 6usize],
}
extern "C" {
    #[doc = " Generate a random Ethernet address that is locally administered\n and not multicast.\n @param addr\n   A pointer to Ethernet address."]
    pub fn rte_eth_random_addr(addr: *mut u8);
}
extern "C" {
    #[doc = " Format 48bits Ethernet address in pattern xx:xx:xx:xx:xx:xx.\n\n @param buf\n   A pointer to buffer contains the formatted MAC address.\n @param size\n   The format buffer size.\n @param eth_addr\n   A pointer to a ether_addr structure."]
    pub fn rte_ether_format_addr(
        buf: *mut ::std::os::raw::c_char,
        size: u16,
        eth_addr: *const rte_ether_addr,
    );
}
extern "C" {
    #[doc = " Convert string with Ethernet address to an ether_addr.\n\n @param str\n   A pointer to buffer contains the formatted MAC address.\n   Accepts either byte or word format separated by colon,\n   hyphen or period.\n\n   The example formats are:\n     XX:XX:XX:XX:XX:XX - Canonical form\n     XX-XX-XX-XX-XX-XX - Windows and IEEE 802\n     XXXX.XXXX.XXXX    - Cisco\n   where XX is a hex digit: 0-9, a-f, or A-F.\n   In the byte format, leading zeros are optional.\n @param eth_addr\n   A pointer to a ether_addr structure.\n @return\n   0 if successful\n   -1 and sets rte_errno if invalid string"]
    pub fn rte_ether_unformat_addr(
        str_: *const ::std::os::raw::c_char,
        eth_addr: *mut rte_ether_addr,
    ) -> ::std::os::raw::c_int;
}
#[doc = " Ethernet header: Contains the destination address, source address\n and frame type."]
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct rte_ether_hdr {
    #[doc = "< Destination address."]
    pub dst_addr: rte_ether_addr,
    #[doc = "< Source address."]
    pub src_addr: rte_ether_addr,
    #[doc = "< Frame type."]
    pub ether_type: rte_be16_t,
}
#[doc = " Ethernet VLAN Header.\n Contains the 16-bit VLAN Tag Control Identifier and the Ethernet type\n of the encapsulated frame."]
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct rte_vlan_hdr {
    #[doc = "< Priority (3) + CFI (1) + Identifier Code (12)"]
    pub vlan_tci: rte_be16_t,
    #[doc = "< Ethernet type of encapsulated frame."]
    pub eth_proto: rte_be16_t,
}
extern "C" {
    pub fn osdep_iface_index_get(name: *const ::std::os::raw::c_char) -> ::std::os::raw::c_int;
}
extern "C" {
    pub fn osdep_iface_mac_get(
        name: *const ::std::os::raw::c_char,
        mac: *mut rte_ether_addr,
    ) -> ::std::os::raw::c_int;
}
pub type __builtin_va_list = [__va_list_tag; 1usize];
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct __va_list_tag {
    pub gp_offset: ::std::os::raw::c_uint,
    pub fp_offset: ::std::os::raw::c_uint,
    pub overflow_arg_area: *mut ::std::os::raw::c_void,
    pub reg_save_area: *mut ::std::os::raw::c_void,
}
#[doc = "< class handle."]
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct rte_class {
    pub _address: u8,
}
